Add file delete retry to testcluster ElasticsearchNode (#89095)          Add retry logic for cleanup / deletion in testcluster's     ElasticsearchNode, to tolerate the asynchronous nature of deletions     on the Windows file-system.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix object equals for SqlQueryRequest's binaryCommunication (#87887)          Co-authored-by: owenniceliu <owenniceliu@tencent.com>||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Handling the master stability health case where there has never been an elected master node (#89137)          If a master-eligible node comes up and has never seen an elected master     node (and assuming that a quorum requires more than one node), then it     ought to report that the master stability health is red because it     cannot form a quorum.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove unused datastream snapshot utility from Metadata (#88535)          This method was introduced to fix datastream snapshots during     concurrent index/datastream changes but was never actually     used because we went with a different approach in the end.     => remove it and its tests||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
[ML] add new trained model deployment cache clear API (#89074)          This adds a new `_ml/trained_models/<model_id>/deployment/cache/_clear` API. This will clear the inference cache on every node where the model is allocated.||||[0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0]||||0||||0||||0
Deduplicate fetching doc-values fields (#89094)          If a docvalues field matches multiple field patterns, then ES will     return the value of that doc-values field multiple times. Like fetching     fields from source, we should deduplicate the matching doc-values     fields.||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 4, 0, 0, 29, 0]||||0||||0||||0
In the field capabilities API, re-add support for `fields` in the request body (#88972)          We previously removed support for `fields` in the request body, to ensure there     was only one way to specify the parameter. We've now decided to undo the     change, since it was disruptive and the request body is actually the best place to     pass variable-length data like `fields`.          This PR restores support for `fields` in the request body. It throws an error     if the parameter is specified both in the URL and the body.          Closes #86875||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 6, 0, 0, 1, 0]||||0||||0||||0
[TSDB] Metric fields in the field caps API (#88695)          To assist the user in configuring the visualizations correctly while leveraging TSDB     functionality, information about TSDB configuration should be exposed via the field     caps API per field.          Especially for metrics fields, it must be clear which fields are metrics and if they belong     to only time-series indexes or mixed time-series and non-time-series indexes.          To further distinguish metric fields when they belong to any of the following indices:          -  Standard (non-time-series) indexes     -  Time series indexes     -  Downsampled time series indexes          This PR modifies the field caps API so that the mapping parameters time_series_dimension     and time_series_dimension are presented only when they are set on fields of time-series indexes.     Those parameters are completely ignored when they are set on standard (non-time-series) indexes.          This PR revisits some of the conventions adopted by #78790||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 18, 0]||||0||||0||||0
[ML] ECS Grok patterns in the _text_structure/find_structure endpoint (#88982)          Also add support for new CATALINA/TOMCAT timestamp formats used by ECS Grok patterns          Relates #77065          Co-authored-by: David Roberts <dave.roberts@elastic.co>||||[0, 0, 0, 0, 7, 15, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 3, 0, 2, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 56, 40, 0, 0, 42, 0]||||0||||0||||0
Avoid expensive call to Span.fromContextOrNull(null) (#89135)          Workaround for #89107||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0]||||0||||0||||0
Override bulk visit methods of exitable point visitor (#82120)          ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix failing test RollupActionIT.testRollupIndex (#89101)          Fixes #88949     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Extract method for finding max task memory in autoscaling decider (#89126)          ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 1, 0]||||0||||0||||0
Merge trivial changes from desired balance feature branch (#89109)          ||||[0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 7, 5, 0, 0, 12, 0]||||0||||0||||0
maybeScheduleNow with delay 0 instead of 1 (#89110)          Replace the 1 millisecond delay to 0 when we want to schedule a     monitoring task now.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
[Transform][CI] add debug logging to find the cause of #88991 (#89080)          add debug logging to find the cause of #88991||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Add verification metadata for dependencies (#88814)          Removing the custom dependency checksum functionality in favor of Gradle build-in dependency verification support.          - Use sha256 in favor of sha1 as sha1 is not considered safe these days.          Closes https://github.com/elastic/elasticsearch/issues/69736||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0]||||0||||0||||0
Adjust wording in frozen tier allocation deciders (#88843)          The allocation deciders for dedicated/non-dedicated     frozen nodes use the "frozen searchable snapshot" terms     for what was renamed later (in #72699) to partially     mounted indices.          Hopefully not controversial, this changes makes the     wording of the deciders more coherent with the current     documentation.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
[ML] Optimize frequent items transaction lookup (#89062)          represent transactions as bitsets for faster lookups when iterating over candidate sets. This PR implements     a lookup table and a subset check based on bits. It uses this lookup table to map transactions to items, this     so-called horizontal representation is used to speedup the lookup that checks if a transaction contains the     candidate item set||||[0, 0, 0, 0, 3, 1, 0, 0, 0, 1, 0, 0, 1, 4, 0, 6, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 7, 4, 11, 14, 0]||||0||||0||||0
Add test in vector tiles with runtime fields (#89044)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Deprecate the _knn_search endpoint (#88828)          This change deprecates the kNN search API in favor of the new 'knn' option     inside the search API. The 'knn' option is now the preferred way of performing     kNN search.          Relates to #87625||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
[ML] Move PyTorch request ID and cache hit indicator to top level (#88901)          This change will facilitate a performance improvement on the C++     side. The request ID and cache hit indicator are the parts that     need to be changed when the C++ process responds to an inference     request. Having them at the top level means we do not need to     parse and manipulate the original response - we can simply cache     the inner object of the response and add the outer fields around     it when serializing it.          Companion to elastic/ml-cpp#2376||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0, 0, 0, 0, 0, 0, 9, 13, 0, 1, 67, 0]||||0||||0||||0
[ML] Include start params in _stats for non-started model deployments (#89091)          Adds the missing start parameters to the _stats API response     for non-started deployments.          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Adjust logging message for adding index block (#85237)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix failing test `RollupActionSingleNodeTests` `testCannotRollupToExistingIndex`  (#89025)          The root cause of this failure was that test testCannotRollupWhileOtherRollupInProgress     would finish before the asynchronously submitted rollup action had not completed. In this     case the test would finish and delete the rollup index, while the rollup process was still trying     to populate or replicate it. It looks like using the ActionListener.NOOP was not a good choice.          Fixes https://github.com/elastic/elasticsearch/issues/88844||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fixing a race condition in CoordinationDiagnosticsServiceIT #89055          This makes sure that the test cluster is stable in CoordinationDiagnosticsServiceIT::testBlockClusterStateProcessingOnOneNode before proceeding with the rest of test.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Provide tracing implementation using OpenTelemetry +  APM agent (#88443)          Part of #84369. Implement the `Tracer` interface by providing a     module that uses OpenTelemetry, along with Elastic's APM     agent for Java.          See the file `TRACING.md` for background on the changes and the     reasoning for some of the implementation decisions.          The configuration mechanism is the most fiddly part of this PR. The     Security Manager permissions required by the APM Java agent make     it prohibitive to start an agent from within Elasticsearch     programmatically, so it must be configured when the ES JVM starts.     That means that the startup CLI needs to assemble the required JVM     options.          To complicate matters further, the APM agent needs a secret token     in order to ship traces to the APM server. We can't use Java system     properties to configure this, since otherwise the secret will be     readable to all code in Elasticsearch. It therefore has to be     configured in a dedicated config file. This in itself is awkward,     since we don't want to leave secrets in config files. Therefore,     we pull the APM secret token from the keystore, write it to a config     file, then delete the config file after ES starts.          There's a further issue with the config file. Any options we set     in the APM agent config file cannot later be reconfigured via system     properties, so we need to make sure that only "static" configuration     goes into the config file.          I generated most of the files under `qa/apm` using an APM test     utility (I can't remember which one now, unfortunately). The goal     is to setup up a complete system so that traces can be captured in     APM server, and the results in Elasticsearch inspected.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 18, 0]||||0||||0||||0
[ML] Mute tests for inference result format change (#89075)          These tests will fail if elastic/ml-cpp#2376 with     them unmuted. #88901 will follow up with the Java     side changes.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Adjust assignment serialization versions after backport (#89071)          ... of #88855||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Improve efficiency of BoundedBreakIteratorScanner fragmentation algorithm (#89041)          As discussed in #73569 the current implementation is too slow in certain scenarios.          The inefficient part of the code can be stated as the following problem:          Given a text (getText()) and a position in this text (offset), find the sentence     boundary before and after the offset, in such a way that the after boundary is     maximal but respects end boundary - start boundary < fragment size.          In case it's impossible to produce an after boundary that respects the said     condition, use the nearest boundary following offset.          The current approach begins by finding the nearest preceding and following boundaries,     and expands the following boundary greedily while it respects the problem restriction. This     is fine asymptotically, but BreakIterator which is used to find each boundary is sometimes     expensive.          This new approach maximizes the after boundary by scanning for the last boundary     preceding the position that would cause the condition to be violated (i.e. knowing start     boundary and offset, how many characters are left before resulting length is fragment size).     If this scan finds the start boundary, it means it's impossible to satisfy the problem     restriction, and we get the first boundary following offset instead (or better, since we     already scanned [offset, targetEndOffset], start from targetEndOffset + 1).||||[0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 10, 0, 6, 3, 0]||||0||||0||||0
[ML] Mute model deployment rolling upgrade tests for backport (#89069)          ... of #88855||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make org.elasticsearch.cluster.routing.RoutingNode#copyShards use Array (#88788)          We used this in three spots, where it copies potentially huge arrays.     One of those spots doesn't need the `copyShards` call at all     and can use the normal iterator as there's no concurrent modfication.          The other two spots can at least just use an array, which will iterate     a little faster than a mutable list and also potentially saves another     round copying the array in the `ArrayList` constructor that the compiler     seems to not be able to eliminate in all cases.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 1, 0]||||0||||0||||0
REST tests and spec for bulk update API keys (#89027)          This PR adds REST API spec and YAML test files for the BulkUpdateApiKey     operation.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Wrap code in new tracing contexts where required (#88920)          Part of #84369. Split out from #88443. This PR wraps parts of the code     in a new tracing context. This is necessary so that a tracing     implementation can use the thread context to propagate tracing headers,     but without the code attempting to set the same key twice in the thread     context, which is illegal. In order to avoid future diff noise, the wrapped     code has mostly been refactored into methods.          Note that in some places we actually clear the tracing context     completely. This is done where the operation to be performed should have     no association with the current trace context. For example, when     creating a new index via a REST request, the resulting background tasks     for the index should not be associated with the REST request in     perpetuity.||||[0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 6, 4, 6, 2, 0]||||0||||0||||0
Refactor authentication handling for grant actions (#88944)          This PR establishes a cleaner contract between `TransportGrantAction`     and its sub-classes: it instruments checking grant authentication     instead of requiring this of sub-classes, and allows these to override     a handler method for successfully granted authentication.          Closes #88636||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 4, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 13, 0, 0, 0, 2, 0]||||0||||0||||0
[ML] Previously assigned models should get at least one allocation (#88855)          When for some reason ML nodes are replaced (cluster resize, upgrade, etc.),     it is possible that some models cannot be allocated at all. Then, while     the cluster is temporarily undersized, all cores are given for allocations     of the models that have survived. If those ML nodes return later, there may     be model deployments that were previously allocated that now do not get any     allocations. The reason is that our planner will try to preserve all current     allocations.          Operationally, this is not what serves best our users. Instead, as we are     already in a cluster that does not have enough resources to fully allocate     all model deployments, we should try to give at least one allocation to each     model that has previously been allocated.          In order to know a model has previously been allocated, this commit adds a field     to `TrainedModelAssignment` called `max_assigned_allocations` which records the     max number of allocations a deployment has received in its life. We can then use     this to establish whether a deployment has ever been allocated.          Finally, we modify the `AssignmentPlanner` so that after computing a plan we     check whether the plan gives at least one allocation to all previously allocated models.     If not, we then compute a plan that tries to give at least one allocation to each     previously allocated model. We can solve this just using bin-packing. Having that     plan we can invoke the planner one more time to optimize the rest of the allocations     whilst preserving the single allocations for previously allocated models.          ||||[0, 0, 0, 0, 15, 3, 2, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 5, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 17, 2, 0, 75, 0]||||0||||0||||0
Rename ignoredIndexSettings to ignoreIndexSettings in MountSearchableSnapshotRequest (#79604)          Relates to #75982, #88987 and #89061          Co-authored-by: Tanguy Leroux <tlrx.dev@gmail.com>     Co-authored-by: gaobinlong <bellengao@tencent.com>||||[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0]||||0||||0||||0
Health API - Monitoring local disk health (#88390)          This PR introduces the local health monitoring functionality needed for     #84811 . The monitor uses the `NodeService` to get the disk usage stats     and determines the node's disk health.          When a change in the disk's is detected or when the health node changes,     this class would be responsible to send the node's health to the health     node. Currently this is simulated with a method that just logs the     current health.          The monitor keeps the last reported health, this way, if something fails     on the next check it will try to resend the new health state.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Refactor WildcardExpressionResolver to better track usages of indices lookup (#89000)          This is a pure refactoring of the WildcardExpressionResolver.     The objective is to restrict access to the indices lookup through the context parameter only.     Eventually, Security is going to plug into the context and only show a restricted view of the     indices lookup, particular to the user context.||||[0, 0, 0, 0, 1, 0, 4, 2, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 9, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 18, 17, 1, 1, 13, 0]||||0||||0||||0
[Transform] improve error handling in state persistence (#88910)          transform persists the internal state of a transform (e.g. the data cursor) in state document.     This change improves the error handling and fixes the problem described in #88905. A transform     can now recover from this problem.          fixes #88905||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Further attempt at capturing reaper error logs     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 0]||||0||||0||||0
Support source fallback for double, float, and half_float field types (#89010)          This change adds a SourceValueFetcherSortedDoubleIndexFieldData to support double doc values types for source fallback. This also adds support for double, float and half_float field types.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0]||||0||||0||||0
Preemptively initialize routing nodes and indices lookup on all node types (#89032)          Follow up to #89005 running the initialization as soon as possible on non-master     nodes as well.     ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] fix NLP inference_config bwc serialization tests (#89011)          The tests were failing because of span not being nulled out for question_answering and text_similarity tasks.          But, this change also attempts to make it more future proof so that if changes occur to the nlp task or tokenization configurations it will cause a failure more quickly and require handling the bwc testing.          closes: #89008||||[0, 0, 0, 0, 10, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 18, 10, 0, 1, 8, 0]||||0||||0||||0
Wrap ML model loading task in new tracing context (#89024)          Part of #84369.          ML uses the task framework to register a tasks for each loaded model.     These tasks are not executed in the usual sense, and it does not make     sense to trace them using APM. Therefore, make it possible to register     a task without also starting tracing.||||[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 1, 0, 0, 1, 0]||||0||||0||||0
Wrap async search action logic in a new trace context (#88937)          Part of #84369. Split out from #88443. This PR wraps parts logic in     `TransportSubmitAsyncSearchAction` in a new tracing context. This is     necessary so that a tracing implementation can use the thread context     to propagate tracing headers, but without the code attempting to set the     same key twice in the thread context, which is illegal.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0]||||0||||0||||0
Ensure tests don't use flat polygons (#89002)          * Ensure tests don't use flat polygons          Polygons with colinear points cannot be tessellated.          * Fixed test error message to not be box specific||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 0]||||0||||0||||0
Mute testBlockClusterStateProcessingOnOneNode (#89038)          Related to: #89015||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make it explicit that test expects no rebalancing (#89028)          This is required in case new shards allocator might be more proactive with rebalancing.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 5, 0]||||0||||0||||0
Wrap async ql task execution in new tracing context (#89029)          Part of #84369. Split out from #88443. This PR wraps parts logic in     `AsyncTaskManagementService` in a new tracing context. This is     necessary so that a tracing implementation can use the thread context     to propagate tracing headers, but without the code attempting to set the     same key twice in the thread context, which is illegal.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0]||||0||||0||||0
Audit log bulk update of API keys (#88942)          This PR adds a new audit trail event for when API keys are updated in     bulk.          Relates: #88758||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Preemptively compute RoutingNodes and the indices lookup during publication (#89005)          Computing routing nodes and the indices lookup takes considerable time     for large states. Both are needed during cluster state application and     Prior to this change would be computed on the applier thread in all cases.     By running the creation of both objects concurrently to publication, the     many shards benchmark sees a 10%+ reduction in the bootstrap time to     50k indices.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 13, 2, 0, 0, 0]||||0||||0||||0
Wrap enrich execute action in new tracing context (#89021)          Part of #84369. Split out from #88443. This PR wraps parts logic in     `InternalExecutePolicyAction` in a new tracing context. This is     necessary so that a tracing implementation can use the thread context     to propagate tracing headers, but without the code attempting to set the     same key twice in the thread context, which is illegal.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0]||||0||||0||||0
Make it explicit that test expects no rebalancing. (#88993)          This is required in case new shards allocator might be more proactive with     rebalancing.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Reject unknown request body fields in Mount API (#88987)          The parser used to parse Mount API requests is configured to     ignore unknown fields. I suspect we made it this way when it     was created because we were expecting to change the     request's body in the future, but that never happened.          This leniency confuses users (#75982) so we think it is better     to simply reject requests with unknown fields starting v8.5.0.          Because the High Level REST Client has a bug (to be fixed in #79604)     that injects a wrong ignored_index_settings we decided to just ignore     and not reject that one on purpose.          Closes #75982||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] mute tests for issue #89008 (#89009)          related #89008||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix compilation in the rescore plugin (#89004)          Add source fallback operation when looking up a the factor field added in #88735          Resolves #88985||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Eliminating initial delay of CoordinationDiagnosticsService#beginPollingClusterFormationInfo for integration tests (#89001)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Extract least/most available disk space DiskUsage (#88996)          ||||[0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 2, 3, 0, 15, 0]||||0||||0||||0
Update version serialization for CCR backport and re-enable BWC tests (#88998)          Updates versions for backport (#88995) of original fix (#88875)          Relates to #88997||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add `synthetic_source` support to `aggregate_metric_double` fields (#88909)          This PR implements synthetic_source support to the aggregate_metric_double     field type          Relates to #86603     ||||[0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 1, 5, 0]||||0||||0||||0
Save loop over all local shards in IndicesClusterService.applyClusterState (#88210)          We can save another two loops here by checking for shards to fail in the same loop that updates or creates shards.     Also, we only need to loop over all indices services locally once for deleting indices as a whole or just shards     out of existing indices.||||[0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 5, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 20, 0, 1, 1, 0]||||0||||0||||0
Support source fallback for byte, short, and long fields (#88954)          This change adds source fallback support for byte, short, and long fields. These use the already     existing class SourceValueFetcherSortedNumericIndexFieldData.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix renaming data streams with CCR replication (#88875)          This commit fixes the situation where a user wants to use CCR to replicate indices that are part of     a data stream while renaming the data stream. For example, assume a user has an auto-follow request     that looks like this:          ```     PUT /_ccr/auto_follow/my-auto-follow-pattern     {     "remote_cluster" : "other-cluster",     "leader_index_patterns" : ["logs-*"],     "follow_index_pattern" : "{{leader_index}}_copy"     }     ```          And then the data stream `logs-mysql-error` was created, creating the backing index     `.ds-logs-mysql-error-2022-07-29-000001`.          Prior to this commit, replicating this data stream means that the backing index would be renamed to     `.ds-logs-mysql-error-2022-07-29-000001_copy` and the data stream would *not* be renamed. This     caused a check to trip in `TransportPutLifecycleAction` asserting that a backing index was not     renamed for a data stream during following.          After this commit, there are a couple of changes:          First, the data stream will also be renamed. This means that the `logs-mysql-error` becomes     `logs-mysql-error_copy` when created on the follower cluster. Because of the way that CCR works,     this means we need to support renaming a data stream for a regular "create follower" request, so a     new parameter has been added: `data_stream_name`. It works like this:          ```     PUT /mynewindex/_ccr/follow     {     "remote_cluster": "other-cluster",     "leader_index": "myotherindex",     "data_stream_name": "new_ds"     }     ```          Second, the backing index for a data stream must be renamed in a way that does not break the parsing     of a data stream backing pattern, whereas previously the index     `.ds-logs-mysql-error-2022-07-29-000001` would be renamed to     `.ds-logs-mysql-error-2022-07-29-000001_copy` (an illegal name since it doesn't end with the     rollover digit), after this commit it will be renamed to     `.ds-logs-mysql-error_copy-2022-07-29-000001` to match the renamed data stream. This means that for     the given `follow_index_pattern` of `{{leader_index}}_copy` the index changes look like:          | Leader Cluster | Follower Cluster |     |--------------|-----------|     | `logs-mysql-error` (data stream) | `logs-mysql-error_copy` (data stream) |     | `.ds-logs-mysql-error-2022-07-29-000001`      | `.ds-logs-mysql-error_copy-2022-07-29-000001` |          Which internally means the auto-follow request turned into the create follower request of:          ```     PUT /.ds-logs-mysql-error_copy-2022-07-29-000001/_ccr/follow     {     "remote_cluster": "other-cluster",     "leader_index": ".ds-logs-mysql-error-2022-07-29-000001",     "data_stream_name": "logs-mysql-error_copy"     }     ```          Relates to https://github.com/elastic/elasticsearch/pull/84940 (cherry-picked the commit for a test)     Relates to https://github.com/elastic/elasticsearch/pull/61993 (where data stream support was first introduced for CCR)     Resolves https://github.com/elastic/elasticsearch/issues/81751||||[0, 0, 0, 0, 5, 5, 0, 2, 0, 0, 0, 1, 12, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 20, 0, 1, 11, 0]||||0||||0||||0
Fix race conditions in master stability polling (#88874)          This fixes some possible race conditions in the cluster formation polling of the stable master code.     It also prevents the list of tasks from growing indefinitely.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] address potential bug where trained models get stuck in starting after being allocated to node (#88945)          When a model is starting, it has been rarely observed that it will lock up while trying to restore the model objects to the native process.          This would manifest as a trained model being stuck in "starting" while also being assigned to a node. So, there is a native process started and task available on the assigned nodes, but the model state never gets out of "starting".||||[0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 32, 0, 0, 3, 0]||||0||||0||||0
Avoid expensive loop in indicesDeletedFromClusterState() when possible (#88986)          The loop over all indices here gets very expensive for large states, we     can avoid it often when metadata changes but not the indices maps.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]||||0||||0||||0
[ML] Frequent Items: use a bitset for deduplication (#88943)          Speedup frequent_items by using bitsets instead of lists of longs. With this item sets     can be faster de-duplicated. A bit is set according to the order of top items (by count).||||[0, 0, 0, 0, 8, 7, 0, 1, 0, 0, 0, 1, 5, 26, 2, 8, 0, 0, 0, 1, 0, 4, 1, 3, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 6, 2, 0, 0, 0, 2, 0, 0, 31, 127, 0, 183, 69, 0]||||0||||0||||0
Remove calls to deprecated xcontent method (#84733)          This removes many calls to the last remaining `createParser` method that     I deprecated in #79814, migrating callers to one of the new methods that     it created.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 7, 0]||||0||||0||||0
synthetic source: fix scaled_float rounding (#88916)          There were some cases where synthetic source wasn't properly rounding in     round trips. `0.15527719259262085` with a scaling factor of     `2.4206374697469164E16` was round tripping to `0.15527719259262088`     which then round trips up to `0.0.1552771925926209`, rounding the wrong     direction! This fixes the round tripping in this case through ever more     paranoid double checking and nudging.          Closes #88854||||[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 5, 0, 3, 2, 0]||||0||||0||||0
Port tests for `date_range` (#88958)          This ports some of the tests for `date_range` from a high overhead     `IntegTestCase` to a lower overhead `AggregatorTestCase`.     `AggregatorTestCase` is also lower level so it can find more fun things     like memory leaks. And it enables values source type testing for     `date_range`.          Inspired by #55502 by andy.bristol@elastic.co||||[0, 0, 0, 0, 6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
[ML] add new text_similarity nlp task (#88439)          text_similarity is a cross-encoding task that compares two text inputs at inference time.          It can be used for cross-encoding re-ranking     ```     POST _ml/trained_models/cross-encoder__ms-marco-tinybert-l-2-v2/_infer     {     "docs":[{ "text_field": "Berlin has a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers."}, {"text_field": "New York City is famous for the Metropolitan Museum of Art."}],     "inference_config": {     "text_similarity": {     "text": "How many people live in Berlin?"     }     }     }     ```          With results:     ```     {     "inference_results": [     {     "predicted_value": 7.235751628875732     },     {     "predicted_value": -11.562295913696289     }     ]     }     ```          Or with just raw text similarity. Here is an example for check if two questions are very similar:     ```     POST _ml/trained_models/cross-encoder__quora-distilroberta-base/_infer     {     "docs":[{ "text_field": "what is your quest?"}, { "text_field": "what is your favorite color?"}, { "text_field": "is the swallow african or european?"}, { "text_field": "what is the airspeed velocity of a swallow carrying coconuts?"}, { "text_field": "how fast is an unladen swallow?"}],     "inference_config": {     "text_similarity": {     "text": "what is the airspeed velocity of an unladen swallow?"     }     }     }     ```     With results:     ```     {     "inference_results": [     {     "predicted_value": -8.312414169311523     },     {     "predicted_value": -8.239330291748047     },     {     "predicted_value": -8.256011009216309     },     {     "predicted_value": -4.1945390701293945     },     {     "predicted_value": -3.294121742248535     }     ]     }     ```||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 0, 0, 3, 0]||||0||||0||||0
Support bulk updates of API keys (#88856)          This PR adds a new API route to support bulk updates of API keys:          `POST _security/api_key/_bulk_update`          The route takes a list of IDs (`ids`) of API keys to update, along     with the same request parameters as the single operation route:          - `role_descriptors` - The list of role descriptors specified for the     key. This is one of the two parts that determines an API key’s     privileges.     - `metadata_flattened` - The searchable metadata associated     to an API key          Analogously to the single operation route, a call to `_bulk_update`     automatically updates the `limited_by_role_descriptors`, `creator`, and     `version` fields for each API key.          The implementation ports the single API key update operation to use the     new bulk functionality under the hood, translating as necessary at the     transport layer.          Relates: #88758||||[0, 0, 0, 0, 9, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 3, 1, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0, 0, 16, 18, 0, 1, 10, 0]||||0||||0||||0
Remove `getTestName()` from the index name (#88941)          This PR removes the test name from the source index name and replaces it     with a 14 char long random alphanumeric.          In the past, we had chosen to include the test name in the index name so that     there are no naming conflicts between indexes of different tests. However, some     times test names include invalid characters that make index creation fail.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove test only code from AllocationService (#88889)          ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27, 0]||||0||||0||||0
Simplify allocation service (#88850)          This pr simplifies allocation service by extracting common code to a method.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 0, 6, 0]||||0||||0||||0
Improve EQL Sequence circuit breaker precision (#88538)          Fixes #88300||||[0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 4, 0]||||0||||0||||0
Fix PluginsServiceTests on Windows (#88971)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Ensure that the FileSettingService closes the config file input stream (#88953)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]||||0||||0||||0
Add deprecation message for deprecated plugin APIs (#88961)          Plugin APIs are defined by a set of interfaces from server. Many of     these APIs are actually implementation details of the system. As we move     these implementation details to use different hook mechanisms so that     internals are only implementable by builtin components, the existing     plugin APIs need to be deprecated. Java provides a means to indicate     deprecation - through the `@Deprecated` annotation. But that annotation     is only seen when compiling a plugin implementing deprecated hooks, and     only then if deprecation warnings are not disabled.          This commit adds an introspection step to plugin initialization which     inspects each loaded plugin and looks for any APIs marked with the     @Deprecated annotation which are overridden by the plugin. If any are     found, deprecation log messages are then emitted to the deprecation log.||||[0, 0, 0, 0, 4, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 14, 1, 0, 0, 5, 0]||||0||||0||||0
[TEST] Reliable settings.json update in FileSettingsIT (#88959)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Deprecate overriding DiscoveryPlugin internals (#88925)          DiscoveryPlugin allows extending getJoinValidator and     getElectionStrategies. These are implementation details of the system.     This commit deprecates these methods so that plugin authors are     discouraged from overriding them.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix slow assertion running in production in RoutingNodes (#88951)          This needs to be in a separate method, it's currently running in production     and uses significant CPU time.          Broken in #88794||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]||||0||||0||||0
Deprecate network plugins (#88924)          Network plugins provide network implementations. In the past this has     been used for alternatives to netty based networking, using the JDK's     nio. However, nio has now been removed, and it is inadvisable for a     plugin to implement this low level part of the system.     Therefore, this commit marks the NetworkPlugin interface as deprecated.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Bring back lost optimization to building metadata from a diff (#88950)          This was lost again due to another merge conflict.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Ensure that the extended socket options TCP_KEEPXXX are available (#88935)          ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 13, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 21, 7, 0, 15, 20, 0]||||0||||0||||0
Make Settings Diffable (#88815)          Making settings diffable so that index metadata diffs     are smaller whenever the metadata changes without a setting change     as well as to make index setting updates over a wider number of     indices faster.          This saves about 3% of CPU time on master and about half that on data nodes     that is just burnt for writing setting strings     when bootstrapping many shards benchmarks benchmarks to 50k indices.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 0]||||0||||0||||0
[ML] add sentence-piece unigram tokenizer (#88858)          Add internal unigram tokenizer.          This tokenizer is the same that XLM-Roberta utilizes, along with many other cross-lingual models and tasks.          This does not fully integrate (adding configuration, integrating into nlp tasks, etc.). But instead is just the internal tokenization and some tests showing how it runs with a precompiled charsmap.||||[0, 0, 0, 0, 7, 2, 1, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 8, 18, 0, 3, 18, 0]||||0||||0||||0
[ML] fix BERT and MPNet tokenization bug when handling unicode accents (#88907)          When handling unicode accents, it may have been that BERT tokenizations removed the incorrect characters. This would result in an exceptionally strange result and possibly an error.          closes #88900||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]||||0||||0||||0
Speed up operations on BlobStoreIndexShardSnapshots (#88912)          This fixes a couple of slow points in `BlobStoreIndexShardSnapshots`,     which become performance critical when working with large repositories.          1. Fix `physicalFiles` containing the same `FileInfo` instances repeatedly for every     snapshot that holds the file. Without this fix the map can hold lists as long as the     number of snapshots for the shard for files common to all snapshots of the shard.     Also, only lazy build the map since it's only used during snapshotting and internalize     the logic into `BlobStoreIndexShardSnapshots` so we don't have to bother with wrapping     as unmodifiable.     2. Add efficient copy constructors for all 3 operations on the shard to avoid     expensive looping over all snapshots and their files in many cases.     3. Use list instead of redundant map in deserialization, we weren't using the map     for any deduplication anyways and are safe here thanks to Jackson's duplicate name     detection          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 0, 0, 1, 3, 0]||||0||||0||||0
Add generateStubReleaseNotes task (#88933)          When we feature freeze Elasticsearch, we need to create stub     documentation for the next version. This turns out to be as simple as     running the usual `generateReleaseNotes` task without any inputs.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0]||||0||||0||||0
Script: Reindex & UpdateByQuery Metadata (#88665)          Adds metadata classes for Reindex and UpdateByQuery contexts.          For Reindex metadata:     * _index can't be null     * _id, _routing and _version are writable and nullable     * _now is read-only     * op is read-write must be 'noop', 'index' or 'delete'          Reindex metadata keeps the originx value for _index, _id, _routing and _version     so that `Reindexer` can see if they've changed.          If _version is null in the ctx map, or, equivalently, the augmentation     `setVersionToInternal()` was called by the script, `Reindexer` sets document     versioning to internal.  If `_version` is `null` in the ctx map, `getVersion`     returns `Long.MIN_VALUE`.          For UpdateByQuery metadata:     * _index, _id, _version, _routing are all read-only     * _routing is also nullable     * _now is read-only     * op is read-write and one of 'index', 'noop', 'delete'          Closes: #86472||||[0, 0, 0, 0, 6, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 5, 0, 1, 2, 3, 0, 0, 0, 0, 0, 0, 4, 5, 0, 0, 0, 0, 0, 0, 8, 7, 0, 1, 15, 0]||||0||||0||||0
Remove unused plugins dir var from server CLI (#88917)          Split out of #88443. Remove the now-unused plugins directory variable from the     server CLI code.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 0]||||0||||0||||0
Use tracing API in TaskManager (#88885)          Split out from #88443. Part of #84369. Use the tracing API that was     added in #87921 in TaskManager. This won't actually do anything until we     provide a tracer with an actual implemenation.||||[0, 0, 0, 0, 3, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 6, 1, 6, 4, 0]||||0||||0||||0
Add source fallback for keyword fields using operation (#88735)          This change adds an operation parameter to FieldDataContext that allows us to specialize the field data that are returned from fielddataBuilder in MappedFieldType. Keyword, integer, and geo point field types now support source fallback where we build a doc values wrapper using source if doc values doesn't exist for this field under the operation SCRIPT. This allows us to have source fallback in scripting for the scripting fields API.||||[0, 0, 0, 0, 4, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 4, 22, 0, 4, 77, 0]||||0||||0||||0
Bump versions after 8.3.3 release     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Speedup BalanceUnbalancedClusterTests (#88794)          This commit speeds up the above tests (and probably many others) by changing how     we assert the invariant. Previously invariant was checked by rebuilding     internal collections from scratch and comparing them against ones already     present in the object after every single modification twice. This commit     verifies the invariant once after all bulk changes.     ||||[0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 11, 2, 0, 4, 0]||||0||||0||||0
Preventing exceptions on node shutdown in integration tests (#88827)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Mute RollupActionSingleNodeTests#testRollupDatastream (#88891)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix SqlSearchIT testAllTypesWithRequestToOldNodes (#88866) (#88883)          Resolves #88866||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Log more details in TaskAssertions (#88864)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Make Tuple a record (#88280)          Tuple is used extensively across the ES codebase and can be effectively represent as a Java record.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Script: Rename TIMESTAMP constant NOW in Metadata (#88870)          The value is `_now` and there was a previous metadata     value `_timestamp` (see test removal in #88733) so the     name is confusing.          Also renames the method `getTimestamp()` to `getNow()`     to reflect the change.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 5, 0]||||0||||0||||0
Script: Protected _source inside update scripts (#88733)          CtxMap delegates all metadata keys to it's `Metadata` container and     all other keys to it's source map.  In most write contexts (update,     update by query, reindex), the source map should only contain one     key, `_source`, which has a `Map<String, Object>`.          This change adds validations to writes to the source map that rejects     insertion of invalid keys, illegal removal of the `_source` key, and     illegally overwriting the `_source` mapping with the wrong type.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Split x-pack testing into multiple CI jobs (#88697)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Format runtime geo_points (#85449)          This formats the result of the `fields` section of the `_search` API for     runtime `geo_point` fields using the `format` parameter like we do for     non-runtime `geo_point` fields. This changes the default format for     those fields from `lat, lon` to `geojson` with the option to get `wkt`     or any other format we support.          The fix does so by preserving the `double, double` nature of the     `geo_point` rather than encoding it immediately in the script. Callers can     use the results. The field fetchers use the `double, double` natively,     preserving as much precision as possible. The queries quantize the points     exactly like lucene indexing does. And like the script did before this Pr.          Closes #85245     ||||[0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 4, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 7, 0, 0, 16, 0]||||0||||0||||0
Mute failing BWC tests     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Adding logic to master_is_stable indicator to check for discovery problems (#88020)          ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 6, 0]||||0||||0||||0
Refactor IndicesPermission authorize method (#88662)          This commit is separating authorization check from computation of     index access control. The change is simply a preparation for allowing     the access control to be computed lazily.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Bump to version 8.5.0     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] fix minor tokenization bug when using fill_mask tasks with roberta tokenizer (#88825)          Depending on where your <mask> resides when using byte-part encoding (e.g. roberta), it could be split out erroneously.          This commit fixes that bug.          NOTE, this bug existed before: #88737||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Add Checkstyle rule for broken switch cases (#88739)          We use `between(x, y)` calls with `switch` statements in tests to     randomize test behaviour. However, some usages define `case` statements     that can never execute, because the `case` value is outside the range     defined by the `between` call.          Write a rule that inspects the switches and the cases, and fails on the     broken cases. This rule checks `between`, `randomIntBetween` and     `randomInt`.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix errors in geo test introduced during refactoring (#88722)          ||||[0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 2, 0, 0]||||0||||0||||0
Fix queued snapshot assignments after partial snapshot fails due to delete (#88470)          We can't just assume that snapshot after snapshot is assigned right,     we must re-compute the right node or whether or not the shard even     exists still.          closes #86724     ||||[0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 1, 0, 0, 4, 0]||||0||||0||||0
Fix SearchableSnapshotsPersistentCacheIntegTests.testPersistentCacheCleanUpAfterRelocation (#88819)          This test failed twice in the last year,     (always on 7.17 branch) and I suspect that     10 seconds are not enough for the persistent     cache to process cluster state updates and     deletes docs. This change gives a bit more     time to the test. It also uses IndexWriter     getDocStats() method to have more accurate     number of docs that includes deletions.          Closes #86060||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
mute CartesianShapeQueryTests#testQueryRandomGeoCollection (#88832)          relates https://github.com/elastic/elasticsearch/issues/88682||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Fix BasicDistributedJobsIT.testMaxConcurrentJobAllocations (#88820)          This test contained a pointless fork which used to run a     synchronized method "simultaneously" in two threads.     After #88710 the parallel threads really did work at the     same time which caused the test to fail (because sometimes     both threads stop the same ML node).          This change stops the ML nodes one after the other, which     was effectively what was happening before #88710.          Fixes #88810||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix EmbeddedImplClassLoaderTests on Windows (#88813)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add stable indicator for plugin descriptor (#88823)          A forgotten piece of https://github.com/elastic/elasticsearch/pull/88731     is whether a plugin descriptor in memory came from a stable or internal     descriptor. This commit adds a flag for that. Note that this is implied     by the file that was loaded, so no new property is needed.     ||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 14, 0]||||0||||0||||0
Script: UpdateByQuery can read doc version if requested (#88740)          Allow UpdateByQuery to read the doc version if set in the request via     `version=true`.          If `version=true` is unset or false, the `ctx._version` is `-1`     indicating internal versioning via seq.          Fixes: #55745||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
[ML] Add inference cache hit count to inference node stats (#88807)          The inference node stats for deployed PyTorch inference     models now contain two new fields: `inference_cache_hit_count`     and `inference_cache_hit_count_last_minute`.          These indicate how many inferences on that node were served     from the C++-side response cache that was added in     https://github.com/elastic/ml-cpp/pull/2305. Cache hits     occur when exactly the same inference request is sent to the     same node more than once.          The `average_inference_time_ms` and     `average_inference_time_ms_last_minute` fields now refer to     the time taken to do the cache lookup, plus, if necessary,     the time to do the inference. We would expect average inference     time to be vastly reduced in situations where the cache hit     rate is high.||||[0, 0, 0, 0, 2, 3, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 16, 1, 1, 44, 0]||||0||||0||||0
[TSDB] Exclude `index.block.write` setting when creating rollup index (#88812)          PR #88565 modified the rollup action so that it copies all index settings from the source     to the rollup index. However, the rollup action expilitly requires that the source index has     the index.block.write: true.          Since the rollup index must be writeable when it is created, this PR excludes the index.block.write i     ndex setting when creating the rollup index.          The index.block.write index setting is explictly set to true at the end of the rollup action (step 4).||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix conflict between #83345 and #87269     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add min_* conditions to rollover (#83345)          ||||[0, 0, 0, 0, 37, 31, 2, 12, 0, 0, 0, 0, 1, 0, 0, 13, 1, 0, 1, 2, 0, 0, 0, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 10, 137, 3, 18, 52, 0]||||0||||0||||0
TSDB: Implement Downsampling ILM Action for time-series indices (#87269)          This PR adds support for an ILM action that downsamples a time-series index     by invoking the _rollup endpoint (#85708)          A policy that includes the rollup action will look like the following          PUT _ilm/policy/my_policy     {     "policy": {     "phases": {     "warm": {     "actions": {     "rollup": {     "fixed_interval": "24h"     }     }     }     }     }     }          Relates to #74660     Fixes #68609||||[0, 0, 0, 0, 9, 8, 1, 1, 0, 0, 0, 1, 9, 0, 0, 0, 0, 0, 0, 3, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 8, 0, 0, 0, 0, 0, 0, 18, 37, 2, 3, 20, 0]||||0||||0||||0
Permit AccessDeniedException while listing blobs (#88802)          On Windows it's possible to get an `AccessDeniedException` while listing     blobs in the presence of concurrent deletions. Today this causes things     like a snapshot delete to fail, but we should accept the exception and     move on.          Closes #88716||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 6, 0, 0, 0, 0]||||0||||0||||0
Fix NPE when checking if the last snapshot was success (#88811)          This fixes a NPE when checking the recorded failure snapshot as the     start timestamp in this case is always null.     This also moves away from checking timestamps to determin if the latest     snapshot is a success as we currently use wall-clocks for the start/end     timestamps we record and they're subject to drifts.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Support kNN vectors in disk usage action (#88785)          This change adds support for kNN vector fields to the `_disk_usage` API. The     strategy:     * Iterate the vector values (using the same strategy as for doc values) to     estimate the vector data size     * Run some random vector searches to estimate the vector index size          Co-authored-by: Yannick Welsch <yannick@welsch.lu>          Closes #84801||||[0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 1, 0]||||0||||0||||0
Update indices permissions to Enterprise Search service account (#88703)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 1, 0]||||0||||0||||0
Add FieldDataContext (#88779)          MappedFieldType#fieldDataBuilder() currently takes two parameters, a fully qualified     index name and a supplier for a SearchLookup. We expect to add more parameters here     as we add support for loading fielddata from source. Rather than telescoping the     parameter list, this commit instead introduces a new FieldDataContext carrier object     which will allow us to add to these context parameters more easily.||||[0, 0, 0, 0, 36, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 34, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 31, 0]||||0||||0||||0
TSDB: Rename some methods (#88790)          This renames a couple of methods on `IndexMode` to be more clear and     adds some javadoc.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0]||||0||||0||||0
Remove Blocks when disk threshold monitoring is disabled (#87841)          This change ensures that existing read_only_allow_delete blocks that     are placed on indices when the flood_stage watermark threshold is     exceeded, are removed when the disk threshold monitoring is disabled.          This is done by changing how InternalClusterInfoService behaves when     disabled. With this change, it will keep calling the registered     listeners periodically, but with an empty ClusterInfo.          Closes #86383||||[0, 0, 0, 0, 3, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 3, 0]||||0||||0||||0
User Profile - Enforce stricter validation for literal username (#88792)          When a security domain is configured to use literal username for user     profiles. The username becomes part of the Profile UID. Because this UID     is then used in many places, it is desirable to have stricter validation     rule for the username. For example, comma should not be allowed because     it clashes with the common way to separate multiple strings.          This PR tighten the validation to only allow alphanumeric chars for     usernames for literal username mode.          Note that the default auto-generation mode for profile UID is     recommended in almost all cases. So this change should not be a concern     for end-users. In fact, this chagne brings the allowed characters for     literal username close to what auto-generation (base64) allows.          Relates: #86952||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Fix racing when loading new JWKs from multiple threads (#88753)          This PR ensures the mutation of JWKs is done in a single thread and     visible to all other threads, which in turn ensures validation to be     correctly performed concurrently.          Relates: #88023||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Fix test failure with double operation precision (#88803)          Fixes #88791||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 2, 0]||||0||||0||||0
Serialize ID last for UpdateApiKeyRequest (#88805)          This PR changes the order in which fields are read and written for     UpdateApiKeyRequest to better accommodate generalization for bulk     updates. Fields other than id will be shared between single operation     and bulk update requests and may therefore be extracted into a base     class; unlike constructor parameters, the order in which we read/write     fields matters for inheritance.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0]||||0||||0||||0
Relax assertion about retry count for S3 repos (#88801)          In #88015 we made it so that downloads from S3 would sometimes retry     more than the configured limit, if each attempt seemed to be making     meaningful progress. This causes the failure of some assertions that the     number of retries was exactly as expected. This commit weakens those     assertions for S3 repositories.          Closes #88784 Closes #88666||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
[ML] add a frequent items aggregation (#83055)          add an aggregation called frequent_items, a bucket aggregation which finds frequent item sets. It is a form of association rules mining that identifies items that often occur together. It also helps you to discover relationships between different data points (items).          For more information about usage have a look at #86037.          This implements frequent items using an algorithm called eclat.||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Support "dry run" mode for updating Desired Nodes (#88305)          Add the dry_run query parameter to support simulating of updating of desired nodes. The update request will be validated, but no cluster state updates will be performed. In order to indicate that the response was a result of a dry run, we add the dry_run run field to the JSON representation of a response.          See #82975||||[0, 0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 11, 0, 0, 27, 0]||||0||||0||||0
File Settings Service (#88329)          Adds a file watcher service for applying Elasticsearch     settings though a file. The saved cluster state through this     method is immutable through the REST API.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 0, 0, 14, 0]||||0||||0||||0
Add support for reading stable plugin descriptors (#88731)          The new stable plugin api will have a slightly different descriptor file     format. This commit prepares for stable plugins by adding support for     reading those new files. The basic info for a plugin is the same like     name and version info. Other stuff like classname are not necessary. The     one additional property specific to the new plugins is "modular", which     indicates whether the jars of the plugin should be loaded as named     modules (this is akin to setting the module path when running java).||||[0, 0, 0, 2, 15, 3, 1, 4, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 60, 31, 0, 0, 33, 0]||||0||||0||||0
Rename AbstractKeywordDocValuesField to BaseKeywordDocValuesField and make it abstract (#88778)          * Make AbstractKeywordDocValuesField abstract     * AbstractKeywordDocValuesField -> BaseKeywordDocValuesField     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Mute DiskThresholdSettingsTests.testMinimumTotalSizeForBelowLowWatermark     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Check buffer too short when decompressing with deflate (#88786)          This commit checks for an edge case in decompression with deflate where     the input is shorter than the deflate header size. Before this commit     a slice error would occur with a negative bound. With this commit an IOException is thrown.          closes #88471||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]||||0||||0||||0
Introduce tracing interfaces (#87921)          Part of #84369. Split out from #87696. Introduce tracing interfaces in     advance of adding APM support to Elasticsearch. The only implementation     at this point is a no-op class.||||[0, 0, 0, 0, 9, 8, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 5, 0, 2, 0, 55, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 6, 15, 0, 1, 85, 0]||||0||||0||||0
Add health user action for unhealthy SLM policy failure counts (#88523)          This PR adds a user action to the SLM health indicator which checks each SLM policy's invocations     since last success field and reports degraded health (YELLOW) in the event that any policy is at or     above the failure threshold (default is 5 failures in a row).||||[0, 0, 0, 0, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 15, 0, 0, 4, 0]||||0||||0||||0
Removing the notion of components from the health API (#88663)          This commit removes the notion of components from the health API. They are gone from being     a top-level field in the response, and indicators is promoted into its place.||||[0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 17, 1, 0, 8, 2, 0, 0, 0, 1, 0, 2, 3, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 10, 5, 0, 0, 0, 1, 0, 0, 76, 10, 5, 0, 74, 0]||||0||||0||||0
Expanding switch statement to cover all cases (#88772)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Implement logic for storing fields that are neither dimensions nor metrics (aka tags) (#87929)          For label fields (fields that are not dimensions nor metrics)     we just propagate the latest value into the rollup index, the     same that we do for a counter metric.||||[0, 0, 0, 0, 5, 2, 1, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 1, 0, 1, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 18, 15, 1, 0, 12, 0]||||0||||0||||0
Fix ReactiveStorageIT#testScaleWhileShrinking (#88630)          This commit fixes ReactiveStorageIT#testScaleWhileShrinking, the     TestFileStore missed handling an exception while the total space     was calculated. This made the get node stats to fail therefore     the actual capacity was computed incorrectly. In addition to that,     when the shards are colocated, the index files that were part of     the other node take a while to get deleted. This made impossible     to allocate the shard anywhere, therefore the test failed in these     cases.          Closes #88430||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 1, 0, 0]||||0||||0||||0
Add package cache to EmbeddedImplClassLoader (#88537)          The initial implementation of the embedded class loader took a brute     force approach to supporting multi-release JARs - iterating over all     possible release versions when searching for classes and resources. This     change improves upon that approach by deriving and caching package and     version specific maps, so class and resource loading can go directly to     the class and resource bytes, respectively, rather than searching.          It's hard to get empirical numbers to quanify just how much this change     improves the performance of classes loaded by this loader, and there is     typically only a couple of hundred classes loaded, but the initial cli     seems observably much quicker, while the server startup has improved     just a bit (at least on my machine).||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Log API key update failures  (#88766)          This PR adds TRACE-level logging for failures of API key updates.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
assert that buildExceptions is called correctly (#88698)          assert that buildExceptions is called correctly          relates #88203     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]||||0||||0||||0
[ML] refactor some nlp tokenizer internals (#88737)          ||||[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 43, 4, 0, 22, 1, 0]||||0||||0||||0
Fix incorrect switch statements (#88757)          Fixes aggregation tests that contain switch statements with branches that will never execute.     The tests use a between(x, y) switch expression, but there are case values that are outside     the randomised range.          Fixes #88745     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Rebalance model assignments when outdated assignments exist (#88761)          When a cluster has been updated from a version prior to the version     when distributed model allocation was introduced (8.4), there is     a possibility that after the full cluster has been upgraded there     still are assignments with routing entries that have `current_allocations`     and `target_allocations` equal to `0`. Those are outdated and we     should trigger a rebalance in order to apply the new distributed     model allocation.          This commit detects that and ensures a rebalance is done in such     scenario.          In addition, this fixes a bug where previous routing entries on     nodes where the planner does not assign any allocations for a model     would stick around.||||[0, 0, 0, 0, 8, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6, 5, 2, 1, 0]||||0||||0||||0
Increase `http.max_header_size` default to 16kb (#88725)          Our current default for the http.max_header_size setting is 8kb. This     is lower than the current default for Kibana (16kb in 8.x), and the ESS     proxy (1mb based on the Go http library default). To align with the     current convention of other Elastic components, this PR increases the     ES header size setting default to 16kb.          Closes #88501||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Change HealthMetadata to ClusterState.Custom (#88736)          Metadata.Custom persists across a full cluster restart which is unnecessary for HealthMetadata since the master will always reset the health metadata upon election. For this reason ClusterState.Custom is more suitable.          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0]||||0||||0||||0
Cache available tier names on DiscoveryNode and DiscoveryNodes (#88436)          We burn almost 2% of the runtime in many-shards benchmark bootstrapping on looping     through the roles just to compare names for the data tier allocation decider.     This change makes that step a lot cheaper by caching the role names in sets     that only need to be build rarely.     ||||[0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 4, 12, 0, 0, 5, 0]||||0||||0||||0
Remove help_url,rename summary to symptom, and user_actions to diagnosis  (#88553)          Remove help_url,rename summary->symptom,user_actions->diagnosis     Separate the diagnosis `message` field in `cause` and `action`     Co-authored-by: Mary Gouseti <mgouseti@gmail.com>||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 6, 5, 0, 0, 0, 1, 0, 0, 13, 7, 0, 0, 71, 0]||||0||||0||||0
TSDB: Downsampling copies all settings from source to rollup index (#88565)          This PR modified the rollup action so that all index settings are copied from     the source index to the rollup index.          Relates to #85708     ||||[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 14, 0, 1, 2, 0]||||0||||0||||0
Pull alpine image in a retry in Docker tests (#88654)          Closes #88651. When using an `alpine` image to perform container     fiddling, first explicitly pull the image and do so in a loop, in an     attempt to make things more robust.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Replace `stopRandomNode` call with more generic calls (#88710)          `stopRandomNode` with predicate is rather specific call. This change replaces it     with more generic `stopNode` and `getNodeNameThat`.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]||||0||||0||||0
Clean up FsRepositoryTests (#88723)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 8, 2, 0, 14, 0]||||0||||0||||0
Fix erroneous switch/cases in ILM tests (#88748)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Fix switch in KeywordFieldMapperTests (#88747)          Closes #88746||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
If signature validation fails, reload JWKs and retry if new JWKs are found (#88023)          Co-authored-by: Niels Dewulf||||[9, 0, 0, 0, 4, 1, 1, 1, 1, 1, 0, 4, 11, 1, 0, 6, 0, 0, 0, 2, 0, 1, 5, 9, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 27, 13, 0, 2, 23, 0]||||0||||0||||0
Fix KnnSearchBuilderTests#testEqualsAndHashcode failures          The KnnSearchBuilder constructor validates that k is always less than num_cands.     But the mutateInstance method could increase k past num_cands. Now we construct     the instance with a larger num_cands to make sure this never happens.          Closes #88734.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Convert disk watermarks to RelativeByteSizeValues (#88719)          * Convert disk watermarks to RelativeByteSizeValues          Similar to the existing watermark setting for the frozen tier.          Pre-requisite for PR 88639 that plans to introduce max headroom     settings for the disk watermarks, similar to the frozen tier max     headroom setting.          * Add changelog          * Revert 20gb to 20GB          * Make formatNoTrailingZerosPercent non static          * ByteSizeValue.MINUS_ONE          * Remove getMinimumTotalSizeForBelowWatermark          * Remove comment          * Fix minor stuff          * Make parsing of RelativeByteSizeValue faster          Mimicks older definitelyNotPercentage function          * Remove Locale from Strings.format          * More MINUS_ONE||||[0, 1, 0, 0, 11, 3, 4, 0, 2, 3, 1, 1, 3, 0, 1, 8, 0, 0, 1, 1, 4, 4, 2, 11, 0, 1, 0, 1, 0, 0, 0, 1, 1, 2, 21, 8, 0, 0, 0, 0, 0, 0, 46, 28, 4, 2, 50, 1]||||0||||0||||0
Use status code 500 for errors if no shard failed (#88551)          If there is no shard failure we would like to use a generic     Internal Server Error other than a Service Unavailable.     Moreover, if the cause is known we use a status code that     reflects the cause.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix validation of close_point_in_time request (#88702)          ClosePointInTimeRequest#validate should return a validation error for an     invalid pit_id, but it throws an IAE instead. This mistake prevents     close_point_in_time tasks of requests with empty pit_id from being removed.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 12, 0, 2, 1, 0]||||0||||0||||0
[TEST] Add mock plugins service loadServiceProviders (#88690)          ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix javadoc typo in ESClientYamlSuiteTestCase          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Integrate ANN into _search endpoint (#88694)          This PR adds a new `knn` option to the `_search` API to support ANN search.     It's powered by the same Lucene ANN capabilities as the old `_knn_search`     endpoint. The `knn` option can be combined with other search features like     queries and aggregations.          Addresses #87625||||[0, 0, 0, 0, 11, 4, 0, 1, 0, 0, 0, 0, 2, 0, 0, 14, 1, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 2, 17, 20, 0]||||0||||0||||0
Use origin for the client when running _features/_reset (#88622)          Co-authored-by: Gordon Brown <arcsech@gmail.com>||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 4, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 9, 0, 0, 4, 0]||||0||||0||||0
Use a record class for ShardSnapshotMetaDeleteResult (#88721)          ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Avoid capturing SnapshotsInProgress$Entry in queue (#88707)          Today each time there's shards to snapshot we enqueue a lambda which     captures the current `SnapshotsInProgress$Entry`. This is a pretty     heavyweight object, possibly several MB in size, most of which is not     necessary to capture, and with concurrent snapshots across thousands of     shards we may enqueue many hundreds of slightly different such objects.     With this commit we compute a more efficient representation of the work     to be done by each task in the queue instead.          Relates #77466||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 9, 3, 1, 0, 0]||||0||||0||||0
TSDB: Improve RollupShardIndexer performance (#88539)          Improve RollupShardIndexer by reducing the calls to BytesRef.deepCopyOf(tsid)||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Speed up DocumentParser.innerParseObject (#88715)          Making this a little smaller so it inlines more often and more importantly     avoid getting the current field name redundantly before entering the loop which     is not free when the parser is a `DotExpandingXContentParser`.     This change gives a significant boost to `BeatsMapperBenchmark.benchmarkParseKeywordFields`.          Results below are pretty stable, running with a large number of iterations.          before:          ```     Result "org.elasticsearch.benchmark.index.mapper.BeatsMapperBenchmark.benchmarkParseKeywordFields":     9039.270 ±(99.9%) 28.001 ns/op [Average]     (min, avg, max) = (9008.778, 9039.270, 9062.246), stdev = 18.521     CI (99.9%): [9011.269, 9067.271] (assumes normal distribution)     ```          after:          ```     Result "org.elasticsearch.benchmark.index.mapper.BeatsMapperBenchmark.benchmarkParseKeywordFields":     8645.649 ±(99.9%) 53.677 ns/op [Average]     (min, avg, max) = (8568.319, 8645.649, 8688.210), stdev = 35.504     CI (99.9%): [8591.972, 8699.327] (assumes normal distribution)     ```||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Mute GeoDistanceQueryBuilderGeoShapeTests#testToQuery (#88714)          relates https://github.com/elastic/elasticsearch/issues/88712||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Mute GeoBoundingBoxQueryBuilderGeoShapeTests#testToQuery (#88713)          relates to https://github.com/elastic/elasticsearch/issues/88711||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Include `metadata` in audit log for API key events (#88642)          This PR adds audit logging for API key metadata, when an API key is     created, granted, or updated.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Upgrade to lucene snapshot lucene-9.3.0-snapshot-b8d1fcfd0ec (#88706)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0]||||0||||0||||0
Reintroduce the ability to configure S3 repository credentials in cluster state (#88652)          Revert of #46147, we want to keep this functionality around for a little longer.||||[0, 0, 0, 1, 6, 4, 0, 5, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 5, 2, 0]||||0||||0||||0
Simplify node stopping call (#88547)          There is no need to use stopRandomNode/namePredicate combination to stop a node by its name.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 57, 0]||||0||||0||||0
move geo_shape query builder tests to spatial module (#88588)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0]||||0||||0||||0
ensure transform has done something before stop gets called with (#88696)          ensure transform has done something before stop gets called with wait_for_checkpoint=true          fixes #79621     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] disallow autoscaling downscaling in two trained model assignment scenarios (#88623)          With 8.4, trained model assignments now take CPU into consideration. This changes our calculation for scaling down until we fully support autoscaling according to CPU requirements.          We shouldn't allow scaling down if there is ANY model assignment that isn't fully allocated (meaning, not enough CPUs)     We don't allow scaling down unless model assignments require less than half of the current scale's CPU count.     Point 2 is a place holder. Fix 1 will be a requirement even in the future with vCPU autoscaling.||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 4, 0]||||0||||0||||0
Adding the ability to register a PeerFinderListener to Coordinator (#88626)          This commit adds the ability to register a PeerFinderListener with Coordinator. The listener has an     onFoundPeersUpdated that is called whenever the collection of peers changes (whether added to     or removed from).||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Muting InternalCategorizationAggregationTests testReduceRandom (#88685)          Due to https://github.com/elastic/elasticsearch/issues/87240||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix double rounding errors for disk usage (#88683)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 5, 0, 15, 0]||||0||||0||||0
Replace health request with a state observer. (#88641)          This was using health request assuming yellow index is one with all primaries     initialized. This is not true as newly created index remain yellow when     primaries allocation is throttled. This was discovered while working on a new     shards allocator.||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 4, 1, 0, 3, 0]||||0||||0||||0
[ML] Fail model deployment if all allocations cannot be provided (#88656)          When we cannot scale up (autoscaling is disabled) we should fail     requests to start a trained model deployment whose allocations     cannot be provided.          ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 7, 0, 1, 1, 0]||||0||||0||||0
Adding cardinality support for random_sampler agg (#86838)          This adds support for the `cardinality` aggregation within a random_sampler.          This usecase is helpful in determining the ratio of unique values compared to the count of total documents within the sampled set.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use custom task instead of generic AckedClusterStateUpdateTask (#88643)          Use custom task instead of generic AckedClusterStateUpdateTask that is not     intended to be used with batching.||||[0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 18, 0, 0, 0, 3, 0]||||0||||0||||0
Reinstate test cluster throttling behavior (#88664)          Co-authored-by: Elastic Machine <elasticmachine@users.noreply.github.com>||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 1, 0, 0]||||0||||0||||0
Mute testReadBlobWithPrematureConnectionClose     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Simplify plugin descriptor tests (#88659)          The plugin descriptor tests are extremely verbose, always specifying all     of the plugin properties to write to a descriptor file. Yet most of the     time only one property needs to be tested. This commit simplifies these     tests by having a set of template descriptor properties, and a helper     method to write and read those properties, allowing additional     properties to override those in the template.||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 8, 0, 1, 11, 0]||||0||||0||||0
[ML] make deployment infer requests fully cancellable (#88649)          When an infer request is made, it may or may not be queued for later execution. If the caller making the inference request stops listening for the result, we should not execute action.          This commit allows for infer requests made to deployed models to be cancelled even after they are queued for inference.          Related to: #88009||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 12, 0]||||0||||0||||0
Fix testCorruptionOnNetworkLayer (#88644)          `POST _cluster/reroute?retry_failed` doesn't reset the failure counter     on any `INITIALIZING` shards, and waiting for no `INITIALIZING` shards     isn't quite enough to ensure that we've finished all possible retries     because there could instead be an ongoing async fetch.          This commit fixes this using a `ClusterStateObserver` to observe the     retry counter instead of using the cluster health action.          Relates #88314     Closes #88615||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 1, 0]||||0||||0||||0
Move synthetic source from behind the TSDB feature flag (#88645)          To date, synthetic source has only been available in snapshot builds. This     commit makes the mode parameter on the _source mapper public, meaning     that synthetic source will be available in 8.4.0.          Note that the force_synthetic_source parameter on search, get and mget     remains protected by the TSDB feature flag.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0]||||0||||0||||0
[Transform] handle update error correctly (#88619)          If updating a transform fails a bug prevents reporting the error correctly          relates #88434||||[0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 1, 0]||||0||||0||||0
Fix multi-value handling in composite agg (#88638)          Multi-valued number fields are handled differently by the composite terms agg in comparison to the regular terms agg.     In particular, we use set semantics when grouping on multi-valued numeric fields using terms / multi-terms aggs while     we don't do the same for composite terms aggs. This commit fixes composite aggs to use the same set semantics as     well.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Make NodeTaskRequest tasks cancellable (#88621)          We pass the actionTask to the subsequent task action so that the task action can be cancelled if the upstream tasks are cancelled.          But, the actionTask passed is created by the `NodeTaskRequest`, which isn't cancellable.          This commit addresses this discrepancy and allows for down stream task actions to be cancelled if the upstream http connections are closed.          Related to: https://github.com/elastic/elasticsearch/pull/88081||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Consolidate user role resolution for API keys (#88542)          This refactor extracts the user role resolution logic for API keys from     ApiKeyGenerator. It plugs the shared resolver class into API key     creation and update handling. It also removes ApiKeyGenerator since     the class is now trivial. A new REST base handler for API key-related     REST actions ensures that the API key service is enabled before we     perform role resolution, which was the only other responsibility left     to ApiKeyGenerator.||||[0, 0, 0, 0, 0, 6, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 8, 1, 0, 13, 0]||||0||||0||||0
Fix Azure repository tests randomly taking many minutes (#88559)          If we run into a seed that causes many fake exceptions and thus retries,     a 100ms retry interval will add up to minutes of test time for tests like     `testLargeBlobCountDeletion` that trigger thousands of requests.     There's no reason not to speed this up by 10x via more aggressive retry     timings as far as I can see so I reduced the timings to avoid randomly     blocked tests.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Remove random runner from build tools (internal) tests (#88577)          This removes unrequited overhead for writing build tool and build tool internal tests and mechanically ports all junit3 tests to junit4.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0]||||0||||0||||0
Propagate alias filters to significance aggs filters (#88221)          Propagate alias filters to significance aggs filters          If we have an alias filter, use it as part of the background filter on a     signficant terms agg. Previously, alias filters did not apply to background     filters so this will change bg_count results for some significant terms aggs     using background filter.          Closes #81585||||[0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 10, 0, 0, 9, 0]||||0||||0||||0
Script: Metadata for update context (#88333)          Adds the `metadata()` API call and a Metadata class for the Update context.          There are different metadata available in the update context depending     on whether it is an update or an insert (via upsert).          For update, scripts can read `index`, `id`, `routing`, `version` and `timestamp`.          For insert, scripts can read `index`, `id` and `timestamp`.          Scripts can always read and write the `op` but the available ops are different.          Updates allow 'noop', 'index' and 'delete'.     Inserts allow 'noop' and 'create'.          Refs: #86472||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0]||||0||||0||||0
Enable synthetic source support on constant keyword fields (#88603)          This commit implements synthetic source support on constant keyword fields,     which will now always emit their value as part of the retrieved source.||||[0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0]||||0||||0||||0
[ML] fix ml API cancellation when http connection is closed (#88616)          API cancellation was erroneously using the node-name for the parent task     id. Task ids are constructed via the node ID, not name.          This fixes that bug.          related to:   - https://github.com/elastic/elasticsearch/pull/88030  -     https://github.com/elastic/elasticsearch/pull/88142  -     https://github.com/elastic/elasticsearch/pull/88009||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 0]||||0||||0||||0
Ensure new privs in API key update test (#88602)          This PR ensures that we pick new cluster privileges when making a     non-noop API key update in tests for auto updating user fields.          Closes #88596.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Weaken assertion in TransportService#doStop (#88601)          We may concurrently register a handler for a (closed) connection to a     remote node while stopping. Such a handler will be completed immediately     on the sending path if not picked up in `doStop`, but sometimes it's     picked up in `doStop` anyway. This commit weakens the assertion to     account for this case too.          Closes #88112 Closes #88459 Closes #88597||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix docker positional params (take 2) (#88584)          As part of #50277, we removed the `TAKE_FILE_OWNERSHIP` option from the     Docker entrypoint script and the associated chroot calls, and instead     just defaulted to running the image as `elasticsearch` instead of     `root`.          However, we didn't check that it was still possible to pass CLI options     to Elasticsearch via CLI arguments, and broke this by mistake. This is     probably an uncommon pattern, versus environment variables or a config     file.  Nevertheless, it is supposed to be possible and is mentioned in     the documentation.          Fix the problem by suppling the missing positional params when calling     Elasticsearch, and add a test case so that we don't break it again.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Update to to Gradle wrapper 7.5 (#85141)          This updates the gradle wrapper to a 7.5          Fixes #85123||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Reduce boilerplate in plugins utils tests (#88593)          Tests for PluginsUtils need to create many different plugin descriptors.     But the vast majority of these just need a plugin name and dependencies.     This commit adds a utility method to simplify these tests.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 19, 0, 0, 6, 0]||||0||||0||||0
Deduplicate mappings in persisted cluster state (#88479)          ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add issuer to GET _ssl/certificates (#88445)          This commit adds the certificate issuer to the values returned by _ssl/certificates||||[0, 0, 0, 0, 3, 3, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 11, 0, 0, 6, 0]||||0||||0||||0
Disable URL connection caching in SPIClassIterator (#88586)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0]||||0||||0||||0
[ML] add new cache_size parameter to trained_model deployments API (#88450)          With: https://github.com/elastic/ml-cpp/pull/2305 we now support caching pytorch inference responses per node per model.          By default, the cache will be the same size has the model on disk size. This is because our current best estimate for memory used (for deploying) is 2*model_size + constant_overhead.          This is due to the model having to be loaded in memory twice when serializing to the native process.          But, once the model is in memory and accepting requests, its actual memory usage is reduced vs. what we have "reserved" for it within the node.          Consequently, having a cache layer that takes advantage of that unused (but reserved) memory is effectively free. When used in production, especially in search scenarios, caching inference results is critical for decreasing latency.||||[0, 0, 0, 0, 6, 7, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 33, 0, 0, 36, 0]||||0||||0||||0
Add 'mode' option to `_source` field mapper (#88211)          Currently we have two parameters that control how the source of a document     is stored, `enabled` and `synthetic`, both booleans. However, there are only     three possible combinations of these, with `enabled:false` and `synthetic:true`     being disallowed. To make this easier to reason about, this commit replaces     the `enabled` parameter with a new `mode` parameter, which can take the values     `stored`, `synthetic` and `disabled`. The `mode` parameter cannot be set     in combination with `enabled`, and we will subsequently move towards     deprecating `enabled` entirely.||||[0, 0, 0, 0, 2, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 13, 0, 0, 5, 0]||||0||||0||||0
Remove geo_shape dependency on FieldFilterMapperPluginTests (#88583)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Rebalance model allocations when an ML job is stopped (#88323)          When ML jobs get stopped (ie. anomaly detection, data frame analytics, etc.)     it could be that memory has been freed up and that we can now assign allocations     for a model deployment.          This commit adds to the `TrainedModelAssignmentClusterService` so that when     a cluster state update is observed we also look whether a persistent task     associated to an ML job has been stopped. If so, we trigger rebalance.||||[0, 0, 0, 0, 9, 0, 1, 0, 0, 0, 0, 4, 1, 0, 1, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 33, 4, 0, 0, 24, 0]||||0||||0||||0
Revert "Fix passing positional args to ES in Docker (#88502)"          This reverts commit 9f4b32a20a776ff6c888e0534f176559c63be700.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Move geo_shape query string test to the spatial module (#88556)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Move geo_shape percolator test to the spatial module (#88554)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0]||||0||||0||||0
Remove Collector implementation from BucketCollector (#88444)          BucketCollector has now a method called #asCollector that returns the current BucketCollector wrapped as a     Lucene Collector.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 0]||||0||||0||||0
Move geo_shape disk usage test to the spatial module (#88555)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]||||0||||0||||0
Remove duplicate definition of checkstyle version in use (#88339)          We only rely on the checkstyle version in the buildLibs.toml gradle version catalogue with this change.     Also added some hints for gradle best practices.          This is an aftermath of #88283||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0]||||0||||0||||0
Setup periodic snyk monitoring per branch (#88522)          Adds a new ci Jenkins job configuration for running snyk dependency monitoring on a daily basis. We setup a service account in snyk and resolve the api token for publishing in vault.          Related to #87620||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Always close directory streams (#88560)               ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 3, 3, 0]||||0||||0||||0
Reserved cluster state service (#88527)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add transport action immutable state checks (#88491)          ||||[0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]||||0||||0||||0
Polling cluster formation state for master-is-stable health indicator (#88397)          This change polls all known master-eligible nodes for cluster formation information in the event     that the existing master node goes null. This is so that the information is available to the health     API when it is needed.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]||||0||||0||||0
[Transform] Finetune Schedule to be less noisy on retry and retry slower (#88531)          reduce amount of log and audits if the same failure happens in a row     and change the mininimum wait time for retrying to 5s||||[0, 0, 0, 0, 4, 4, 1, 1, 1, 0, 0, 3, 3, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 7, 14, 1, 0, 28, 0]||||0||||0||||0
Updatable API keys - auto-update legacy RDs (#88514)          API keys created in 7.x may have legacy superuser user role     descriptors. In 8.x this is handled by translating these to 8.x     superuser role descriptors when they are read. Instead, we can     automatically update them (once) when an API key is first updated. This     PR tweaks our noop detection logic to enable this.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix typo in TransportForceMergeAction and TransportClearIndicesCacheA… (#88064)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fixed NullPointerException on bulk request (#88358)          Java's `ArrayList.toArray()` returns provided array when collection is empty.     Here is created a one-element array which contains null element.     Thus, returned `BulkResponse` may contains a null element as `BulkItemResponse`.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Avoid needless index metadata builders during reroute (#88506)          This set of changes makes `org.elasticsearch.cluster.routing.allocation.IndexMetadataUpdater#applyChanges` essentially free even in clusters of O(100k) indices compared to using a disproportionately increasing amount of CPU as the cluster grows (about 1% of CPU time while bootstrapping many shards at 25k indices benchmarks and increasing from there).     It also appears to have additional benefits end-to-end in those benchmarks, likely as a result of making diffing metadata cheaper by retaining more instance equality across the board.          relates #77466||||[0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 30, 28, 0, 0, 4, 0]||||0||||0||||0
Set metadata on request in API key noop test (#88507)          This PR fixes API key integration test setup for noops. In the noop     test, we use the initial update request as a reference to choose     suitable values to force non-noop updates, including metadata. However,     metadata can be null on the initial request, meaning that the     underlying API key will retain the metadata it was assigned on     creation. This can lead to test failure when the metadata on the     initial request is null, and the subsequent metadata update matches     the metadata chosen at API key creation time.          Closes #88503.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix passing positional args to ES in Docker (#88502)          As part of #50277, we removed the `TAKE_FILE_OWNERSHIP` option from the     Docker entrypoint script and the associated chroot calls, and instead     just defaulted to running the image as `elasticsearch` instead of     `root`.          However, we didn't check that it was still possible to pass CLI options     to Elasticsearch via CLI arguments, and broke this by mistake. This is     probably an uncommon pattern, versus environment variables or a config     file.  Nevertheless, it is supposed to be possible and is mentioned in     the documentation.          Fix the problem by suppling the missing positional params when calling     Elasticsearch, and add a test case so that we don't break it again.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Support cartesian shape with doc values (#88487)          Shape field type generated doc values by default now.||||[0, 0, 0, 0, 21, 8, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 5, 0, 12, 0, 1, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 2, 0, 0, 13, 34, 0, 1, 77, 0]||||0||||0||||0
Promote usage of Subjects in Authentication class (#88494)          This PR is a follow-up of #86246 to further clean up the Authentication     class by: * Promote usage of the Subject class. The User field and a few     other   related fields are now removed from Authentication. Relevant     methods   have their implementation replaced by using Subjects and same     behaviours are retained. * Remove the temporary internal RunAsUser     class. Its essence is about   wire serialisation which is now merged     into Authentication itself. * Simplify serialisation of regular User     object. All the complexities of   handling inner user is now completely     within the Authentication class   itself. * Consolidate assertions in     different places into a single method that   is called in constructors.     Also removed a few assertions because there   is no RunAsUser class     anymore and a User object is just a simple user.          Relates: #86246 Relates: #86544          Resolves: #80117||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 6, 1, 0, 7, 0]||||0||||0||||0
Add CCx 2.0 feature flag (#88451)          ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Implement count for wrapped Weight in ContextIndexSearcher (#88396)          Implements Weight#count() for wrapped Weights that don't change matching documents.          Relatess #88284||||[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 7, 1, 8, 0]||||0||||0||||0
Script: Ingest Metadata and CtxMap (#88458)          Create a `Metadata` superclass for ingest and update contexts.          Create a `CtxMap` superclass for `ctx` backwards compatibility in ingest and update contexts.  `script.CtxMap` was moved from `ingest.IngestSourceAndMetadata`          `CtxMap` takes a `Metadata` subclass and validates update via the `FieldProperty`s passed in.          `Metadata` provides typed getters and setters and implements a `Map`-like interface, making it easy for a class containing `CtxMap` to implement the full `Map` interface.          The `FieldProperty` record that configures how to validate fields. Fields have a `type`, are `writeable` or read-only, and `nullable` or not and may have an additional validation useful for Set/Enum validation.||||[0, 0, 0, 3, 11, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 6, 0, 0, 7, 0]||||0||||0||||0
Rename immutable cluster state to reserved cluster state (#88481)          ||||[0, 0, 0, 0, 1, 0, 0, 0, 5, 5, 0, 0, 0, 0, 0, 3, 0, 0, 0, 7, 0, 6, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 27, 0]||||0||||0||||0
Watcher: Add test of date math with ctx.execution_time (#88466)          Add one test to confirm the below watcher compare condition is always     met.          ```     "condition": {     "compare": {     "ctx.execution_time": {     "gte": "<{now-5m}>"     }     }     }     ```          Refs: #88408 #88467||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Speed up creating new IndexMetaDataGenerations without removed snapshots (#88344)          * Pre-collect all new blobUuids to a set before removing stale identifiers. This avoids iterating over the lookup map and its each entry's map for every identifier (which results in cubic time complexity!).     * Avoid creating copies of maps just to stale data, instead populate them on the go.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 7, 0, 0, 2, 0]||||0||||0||||0
[ML] performance improvement for precompiled normalization (#87709)          This is a performance improvement for the precompiled normalizer. It no longer requires the graphemes to be sub-strings and relies on code-point counts between grapheme boundaries for normalization.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 20, 0, 7, 8, 0]||||0||||0||||0
Refactor json parsing in immutable handlers (#88492)          ||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 3, 0, 3, 1, 0]||||0||||0||||0
[ML] indicate overall deployment failure if all node routes are failed (#88378)          If all node routes are failed, we should indicate that the whole deployment is failed through its assignment state.          The failures could be due to multiple reasons, so for detailed information, the individual node routing reasons should be investigated.||||[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0]||||0||||0||||0
[ML] Add exception detail to auditor failure to install template (#88498)          While looking at a different issue I noticed cases of the     ML auditor failing to install its template. Unfortunately     this log message didn't include the exception, so it was     not possible to say for sure why this happened. This PR     adds the exception.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Fix lost optimization from merge conflict in building metadata from diff (#88497)          The flag value was lost due to a merge mistake, bringing it back.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Recalculate balance using up-to date weights when THROTTLE (#88385)          Fix a bug when a shard could be re-balanced using outdated node weights in case     2 or more simulated shards movements happens in a row for a single index.     ||||[0, 0, 0, 0, 4, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 5, 3, 0]||||0||||0||||0
Simplify map copying (#88432)          This commit introduces a method that simplifies creating a map deep copy||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 5, 0]||||0||||0||||0
Make DiffableUtils.diff implementation agnostic (#88403)          DiffableUtils has methods for reading and creating diffs of maps. The     two implementation types, a JDK Map or ImmutableOpenMap, have different     methods and implementations. However, the format of the diff is always     the same, so the diff creation can be shared. This commit creates an     internal MapBuilder abstraction to allow both Map and ImmutableOpenMap     to produce diffs from the same MapDiff implementation.          relates #86239||||[0, 0, 0, 2, 3, 1, 1, 4, 0, 0, 1, 0, 0, 0, 0, 0, 4, 2, 0, 1, 1, 1, 0, 2, 1, 0, 7, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 4, 0, 0, 2, 28, 0, 0, 6, 2]||||0||||0||||0
Ingest: Start separating Metadata from IngestSourceAndMetadata (#88401)          Pull out the implementation of `Metadata` from `IngestSourceAndMetadata`.          `Metadata` will become a base class extended by the update contexts: ingest, update, update by query and reindex.          `Metadata` implements a map-like interface, making it easy for a class containing `Metadata` to implement the full `Map` interface.||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 10, 14, 0, 4, 75, 0]||||0||||0||||0
Move runtime fields base scripts out of scripting fields api package. (#88488)          Two runtime fields script classes were placed into the package for the scripting fields api. These have     been moved to the script package where the rest of the runtime fields script classes live. This is a     purely mechanical change.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Enable TRACE Logging for test and increase timeout (#88477)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0]||||0||||0||||0
Mute ReactiveStorageIT#testScaleDuringSplitOrClone (#88480)          Relates to https://github.com/elastic/elasticsearch/issues/88478.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Track the count of failed invocations since last successful policy snapshot (#88398)          Add tracking for the number of invocations that have passed between a successful SLM snapshot     and the most recent failure. These stats would be helpful for reporting on SLM policy health.||||[0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 4, 0]||||0||||0||||0
Avoid noisy exceptions on data nodes when aborting snapshots (#88476)          Currently, an abort (especially when triggered an index delete) can     manifest as either an aborted snapshot exception, a missing index exception or     an NPE. The latter two show up as noise in logs.     This change catches effectively all of these cleanly as aborted snapshot     exceptions so they don't get logged as warnings and avoids the NPE if     a shard was removed from the index service concurrently by using the     API that throws on missing shards to look it up.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0]||||0||||0||||0
Fix ReactiveStorageDeciderServiceTests testNodeSizeForDataBelowLowWatermark (#88452)          Fix this test unexpectedly being off by one by increasing the accuracy of the fp division     (better to have a larger dividend and divisor) a little. I could easily reproduce the failure     without the fix but with it, the test cases we use at least run accurate with the change.          closes #88433||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
INFO logging of snapshot restore and completion (#88257)          But DEBUG (silent) logging of snapshot restore/completion when     done in the context of CCR or searchable snapshots.||||[0, 0, 0, 0, 3, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 10, 0]||||0||||0||||0
Updatable API keys - noop check (#88346)          This PR adds a noop check for API key updates. If we detect a noop     update, i.e., an update that does not result in any changes to the     existing doc, we skip the index step and return updated = false in     the response.          This PR also extends test coverage around various corner cases.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 7, 0]||||0||||0||||0
Use consistent shard map type in IndexService (#88465)          It's faster and easier to reason about if we always have     an immutable collections map here and not have the type depend     on what the last operation on the index service was.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 2, 0]||||0||||0||||0
Stop registering TestGeoShapeFieldMapperPlugin in ESIntegTestCase (#88460)          Instead of registering the plugin by default, implementations that need it are responsible on registering the plugin.||||[0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0]||||0||||0||||0
TSDB: RollupShardIndexer logging improvements (#88416)          1. Add trace log guards to avoid high cost method     2. Log the time it took to rollup a shard||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Audit API key ID when create or grant API keys (#88456)          The API key ID generation is handled by the Request class since #63221.     This makes it possible to audit it when creating or granting API keys.     This PR makes the necessary changes for it to happen.          Relates: #63221||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Bound random negative size test in SearchSourceBuilderTests#testNegativeSizeErrors (#88457)          -1 is handled differently by the xcontent code path so this test will fail when `randomIntBetween` lands on -1.          To fix, we add another integer for the xcontent test which starts at -2.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Updatable API keys - logging audit trail event (#88276)          This PR adds a new audit trail event for when API keys are updated.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Polish reworked LoggedExec task (#88424)          Some polishing of reworked LoggedExec task||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 3, 0, 1, 0, 0]||||0||||0||||0
Pass IndexMetadata to AllocationDecider.can_remain (#88453)          We need the metadata in a number of allocation deciders and pass it to other allocation methods.     Passing it here avoids redundant lookups across deciders.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 1, 36, 0]||||0||||0||||0
[TSDB] Cache rollup bucket timestamp to reduce rounding cost (#88420)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Correct some typos/mistakes in comments/docs (#88446)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make ClusterInfo use immutable maps in all cases (#88447)          This class's maps are used very hot in the disk threshold allocation     decider. Moving them from hppc maps to unmodifiable map wrapping     `HashMap` has led to a measurable slowdown in the many-shards benchmark     bootstrapping. Lets use immutable map copies here exclusively to make     performance outright better and more predictable via a single implementation.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 0]||||0||||0||||0
Reduce map lookups (#88418)          This change replcase 2 hash map operations with a single one and a null     check.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Don't index geo_shape field in AbstractBuilderTestCase (#88437)          This commit stops adding the geo_shape field mapper by default and adds the mapper only when it is needed.||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Remove usages of TestGeoShapeFieldMapperPlugin from enrich module (#88440)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix test memory leak (#88362)          ||||[0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0]||||0||||0||||0
Improve error when sorting on incompatible types (#88399)          Currently when sorting on incompatible types, we get     class_cast_exception error (code 500). This patch improves     the error to explain that the problem is because     of incompatible sort types for the field across     different shards and returns user error (code 400).          Closes #73146||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove usages of BucketCollector#getLeafCollector(LeafReaderContext) (#88414)          The method BucketCollector#getLeafCollector(LeafReaderContext) should be removed in favour of     BucketCollector#getLeafCollector(AggregationExecutionContext)||||[0, 0, 0, 0, 2, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 36, 0]||||0||||0||||0
Mute ReactiveStorageIT::testScaleWhileShrinking (#88431)          For #88430||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix RealmIdentifier XContent parser (#88410)          RealmIdentifier's constructor has type before name. But the parser had     it reserved. This PR fixes the parser to have the same argument order as     the constructor. It also adds relevant tests.          Since the parser is only used internally for the User Profile feature     which is not official released yet. This fix is a non-issue.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make LoggedExec gradle task configuration cache compatible (#87621)          This changes the LoggedExec task to be configuration cache compatible. We changed the implementation     to use `ExecOperations` instead of extending `Exec` task. As double checked with the Gradle team this task     is not planned to be made configuration cache compatible out of the box anytime soon.          This is part of the effort on https://github.com/elastic/elasticsearch/issues/57918||||[0, 0, 0, 1, 14, 4, 1, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 13, 6, 0, 0, 7, 0]||||0||||0||||0
Update CorruptedFileIT so that it passes with new allocation strategy (#88314)          New allocation strategy is not going to retry failed shards. Update the     test to not rely on that behavior     ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 16, 0, 2, 13, 0]||||0||||0||||0
Update RareClusterStateIT to work with the new shards allocator (#87922)          ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 7, 1, 0, 1, 0]||||0||||0||||0
Ensure CreateApiKey always creates a new document (#88413)          The OpType of the indexRequest used for creating new API keys does not     have its OpType configured. This means it defaults to OpType.INDEX which     allows it to replace an existing document. This PR fixes it by explicity     set OpType to CREATE so that it always create a new document (or throw     error if ID conflict does happen).          Since API key ID is time-based random base64 UUID, it is unlikely for     this to happen in practice and we are not aware of any related bug     report.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Extract utility for asserting current thread pool (#88383)          It's useful to assert we're running on a particular thread pool. Today     we do this by checking the current thread's name, but the actual     implementation of this check varies quite a bit across the codebase.     Some of them are quite verbose, and others fail to include the     delimeters around the thread name. This commit introduces a utility     method to standardize this kind of assertion.||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 19, 13, 0, 0, 8, 0]||||0||||0||||0
[ML] fix NLP question_answering task when best answer is only one token (#88347)          There are scenarios when question_answering find the best start/end token and they are the same token. An example of this is:          context: "My name is Ben and I live in London" question: "Where do I live?"          The correct answer here is London and its a single token. Without this fix, we will return in London with a lower probability.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Limit test to zoom 25 to avoid rounding errors (#88376)          * Limit test to zoom 25 to avoid rounding errors          We have flaky tests with rare rounding errors at higher precision.     Since the index only really works well to this level, we feel it is     best to simply limit the test.          * Update docs/changelog/88376.yaml          * Delete docs/changelog/88376.yaml||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0]||||0||||0||||0
Use consistent map type in IndicesService (#88369)          Iteration and lookup from this map get quite hot at times for large data nodes.     We shouldn't have different map types here depending on whether or not the latest operation     was an index delete or create on the node.     Also, the wrapped HashMap is slower to iterate than the immutable collections map.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Autoscaling during shrink (#88292)          Fix autoscaling during shrink to disregard pinning to nodes for the total tier size.     Instead signal that we need a minimum node size to hold the entire shrink     operation. This avoids scaling far higher than necessary when cluster     balancing does not allow a shrink to proceed. It is considered a     (separate) balancing issue when a shrink cannot complete with enough     space in the tier.          This changes autoscaling in general for node pinning filters (based on     `_id`, `_name` or `name` filters).          Clone and split also pins to the shards they clone or split, similarly     this is changed to ignore that pinning during autoscaling.          Closes #85480||||[0, 0, 0, 0, 20, 6, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 9, 0, 0, 6, 0]||||0||||0||||0
Add test case for a replace shutdown (#88320)          This test case verifies that the index is going to be moved to the     replacement node even if it could not be allocated anywhere in     the cluster according to the allocation settings.||||[0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 4, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 44, 23, 0, 0, 4, 0]||||0||||0||||0
Replace usages of deprecated specialized field exists queries (#88312)          DocValueFieldExistsQuery, NormsFieldExistsQuery as well as KnnVectorFieldExistsQuery are deprecated in Lucene in favour of FieldExistsQuery which combines the three into a single query.          This commit updates Elasticsearch to no longer rely on such deprecated queries.          see https://issues.apache.org/jira/browse/LUCENE-10436||||[0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 17, 0, 3, 10, 69, 0]||||0||||0||||0
Enforce max values limit only when running a script (#88295)          Runtime fields scripts have a hard maximum number of values that they can emit. This was accidentally inherited by some doc_value based queries that reuse the existing runtime fields infrastructure (in absence of a corresponding already existing lucene doc_value based query) as well as by script-less runtime fields that load from _source.          This limit was introduced to prevent mistakes when writing a script hence when we are loading from either _source or doc_values the same limit should not be enforced. This commit addresses this, and applies the same to the max chars limit for string fields.||||[0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 8, 0]||||0||||0||||0
Support run_as another user when granting API keys (#88335)          Previoulsy, in order to grant an API key to a user, the user's     credentials (either username/password or access token) must be provided.     However, this is not always possible for certain setups, e.g. when all     end-users are proxied by a service user with the run_as feature. This PR     adds run_as support for granting API keys so that the user whose     credentials are provided (in the request body) can run-as another user     for whom the API key will be eventually granted.          The run-as behaviour is stricter in that it reports error if it is not     supported  by the provided authentication, e.g. anonymous, chained     run-as. This is different that used in authenticating requests, where     unsupported run-as is ignored and logged.||||[0, 0, 0, 0, 8, 3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 8, 0]||||0||||0||||0
Add build_flavor back to info api rest response (#88336)          The build_flavor was previously removed since it is no longer relevant;     only the default distribution now exists. However, the removal of build     flavor included removing it from the version information on the info     response for the root path. This API is supposed to be stable, so     removing that key was a compatibility break. This commit adds the     build_flavor back to that API, hardcoded to `default`. Additionally, a     test is added to ensure the key exists going forward, until it can be     properly deprecated.          closes #88318||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Add missing get for totalOutboundConnections (#88234)          - Have you signed the [contributor license agreement](https://www.elastic.co/contributor-agreement)? *YES*     - Have you followed the [contributor guidelines](https://github.com/elastic/elasticsearch/blob/master/CONTRIBUTING.md)? *YES*     - If submitting code, have you built your formula locally prior to submission with `gradle check`? *YES*     - If submitting code, is your pull request against master? Unless there is a good reason otherwise, we prefer pull requests against master and will backport as needed. *YES*     - If submitting code, have you checked that your submission is for an [OS and architecture that we support](https://www.elastic.co/support/matrix#show_os)? *YES*||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
add missing getter (#84912)          - Have you signed the [contributor license agreement](https://www.elastic.co/contributor-agreement)? - **YES**     - Have you followed the [contributor guidelines](https://github.com/elastic/elasticsearch/blob/master/CONTRIBUTING.md)? - **YES**     - If submitting code, have you built your formula locally prior to submission with `gradle check`?     - If submitting code, is your pull request against master? Unless there is a good reason otherwise, we prefer pull requests against master and will backport as needed. - **YES**     - If submitting code, have you checked that your submission is for an [OS and architecture that we support](https://www.elastic.co/support/matrix#show_os)? - **N/A**     - If you are submitting this code for a class then read our [policy](https://github.com/elastic/elasticsearch/blob/master/CONTRIBUTING.md#contributing-as-part-of-a-class) for that. - **NO**||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove unused InternalPlugin interface (#88330)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Health API disk indicator: Publish health metadata in the cluster state (#88175)          For the health API disk indicator, we want to check the free disk space against a set of thresholds. Each node can potential have different thresholds configured but we want to use the same set of thresholds. Following what we already do for allocation disk thresholds, we want all nodes to use the threshold's from master. To achieve this, the elected master publishes their set of thresholds in the cluster state, so all nodes can use them.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0]||||0||||0||||0
Bump versions after 8.3.2 release     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Close resources in testLoadServiceProviders (#88343)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Support updates of API key attributes [REST and transport layer] (#88186)               REST and transport layer implementation to add support for updating     attributes of existing API keys. This allows end-users to modify     privileges and metadata associated with API keys dynamically, without     requiring rolling out new API keys every time there is a change.          The new route supports updates to one API key, given its ID:          PUT /_security/api_key/{id}          The request body consists of optional fields role_descriptors and     metadata. If a request field is absent, the existing value of the     field on the given API key is retained. If a request field is set to     {} it replaces the existing value with {}. Explicit null-values for     request fields are not allowed and will produce a 400.     limited_by_role_descriptors, creator, and version are     automatically updated on every call. Attributes a replaced, not merged.          Only the owner user of an API key can update it. API keys cannot update     themselves, nor can other users (even users with all or     manage_security cluster privileges).          Relates: #87870||||[0, 0, 0, 0, 15, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 21, 11, 0, 0, 6, 0]||||0||||0||||0
Fix performance regression in DataTierAllocationDecider (#88340)          In #87735 we moved to using streams here. This results in a visible     regression in the many shards benchmarks that gets bigger the larger     the cluster is.     Using streams here adds a lot of alloction and indirection but does not     come with any advantages since `DiscoveryNodes` does not implement     `stream` so it's just an indirection on top of the existing iterator     that gets instantiated for every shard and then runs a compartively     short loop over the nodes.          -> move this back to iterator||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 8, 0, 0, 0, 0]||||0||||0||||0
Speed up put index to metadata builder (#88319)          This method is very hot when applying metadata diffs so it's worthwhile     to skip the redundant `get` here when not incrementing the version.||||[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 2, 1, 0]||||0||||0||||0
Update NodeShutdownShardsIT to actually index docs (#88316)          Replace a noop method call with actual document indexing.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0]||||0||||0||||0
Remove tech debt on Aggregations#getLeafCollector (#88230)          Remove #getLeafCollector(LeafReaderContext, LeafBucketCollector) in favour of     #getLeafCollector(ggregationExecutionContext, LeafBucketCollector)     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 72, 70, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 4, 3, 0, 0, 95, 0]||||0||||0||||0
Add setting for tcp_keepalive for oidc back-channel (#87868)          This PR adds a new setting to enable tcp keepalive probes for the     connections used by the oidc back-channel communication. It defaults to     true as tcp keepalive is generally useful for ES.          Relates: #87773||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
[Test] Fix parsing of exception objects (#88198)          The exception parsing logic expects the starting curly bracket already     be consumed. This PR ensures the expectation is met.          Resolves: #88166     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Upgrade to Lucene-9.3.0-snapshot-2d05f5c623e (#88284)          To include LUCENE-10620 - which passes Weight to Collector||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 12, 0]||||0||||0||||0
[ML] add new optional cache_hit field for pytorch results (#88287)          This commit adds the ground work for accepting a `cache_hit` boolean field that indicates if the response was cached or not.          User facing statistics are not updated with cache hit/miss information yet. That will need to be done when that information is actually provided from the native process.          This is related to: https://github.com/elastic/ml-cpp/pull/2305||||[0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 7, 0, 0, 30, 0]||||0||||0||||0
Collapse IndexMode#getConfiguredTimestampRange(...) into IndexMode#getTimestampBound(...) (#88258)          `IndexMode#getConfiguredTimestampRange(...)` functionally overlaps a lot     with `IndexMode#getTimestampBound(...)`. In order to reuse     `IndexMode#getTimestampBound(...)` for the use case     `IndexMode#getConfiguredTimestampRange(...)` is reused a change had to     be made to TimestampBounds.          During query rewrite and in `TimestampFieldMapperService` no     `IndexScopedSettings` is available, so made this an optional parameter.     Only the usage in `IndexSettings` needs this, so that the instance is     updated in the case `index.time_series.end_time` setting is updated. In     the case of query rewrite and in `TimestampFieldMapperService` this     isn't needed,  since the instance is kept around and reused.          Followup from #85162||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 2, 3, 0, 2, 2, 1]||||0||||0||||0
[ML] fixing bwc for trained model deployment inference (#88289)          When the internal objects were renamed, an inappropriate bwc version restriction was put in place.          This commit fixes this by allowing trained model assignment metadata updates to be serialized to nodes > 8.0.0.          This is OK as the object serialization handles its BWC conditions when serializing over the wire.          This closes: #87959||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Use boolean instead of bitwise OR (#88310)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Unmute Lintian test again (#88301)          The most recent problem should be fixed by elastic/ml-cpp#2346          Fixes #88090     Fixes #88252||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make JdkMapDiff return immutable map (#88250)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0]||||0||||0||||0
Save loop over all indices in Metadata Builder (#88302)          No need to run the mapping cleanup in a separate loop. We can just collect     the mappings right away when we loop the indices in the builder.     Also, no need for our own inline copy of `retainAll` actually.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 0]||||0||||0||||0
Pre-size Metadata builder when applying diffs (#88304)          Small but non-trivial speedup for very large cluster states where the indices map     is built one-by-one.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 3, 0]||||0||||0||||0
fix: refresh the rollup index as part of the rollup indexer actions (#86992)          Instead of waiting in the yaml test we refresh once the     indexing operation is complete in the callback. This way     we avoid possible timeout issues which make the test     unstable.          Resolves #81983     Resolves #53412||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 4, 0]||||0||||0||||0
Fix potential circuit breaker leak on InternalGeoGrid (#88273)          During reduce time we are creating a LongObjectPagedHashMap that will not get released if there is an error when     it is getting populated. This commit adds a finally clause so it is always release.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 4, 2, 0]||||0||||0||||0
Print full exception when console is non-interactive (#88297)          The console logger truncates stack traces so a user is not bombarded     with enormouse messages on startup. However, when the output is     redirected to a file, there is no need to avoid large messages, and in     fact it is a hinderance to debugging. This commit adds an internal flag     to the console logging exception convert which disables the truncation     when attached to a non-interactive console.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0]||||0||||0||||0
Remove ImmutableOpenMap from rollupt tests (#88290)          Some tests for rollup were still using ImmutableOpenMap for testing     internal methods, even though those methods were already converted to     Map. This commit changes those tests to use Map.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 14, 0]||||0||||0||||0
Remove ImmutableOpenMap from Engine (#88291)          SegmentStats was changed to use Map, but the method in Engine which     computes files sizes for segment stats was never converted. This commit     removes that final usage from Engine.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 3, 0, 0, 1, 0]||||0||||0||||0
Fix checkstyle version drift and API change (#88283)          Fix checkstyle version drift and API change.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Remove ImmutableOpenMap from most tests (#88285)          This commit removes ImmutableOpenMap from most test cases from server,     where the type is no longer needed because Map is used by the class     being constructed.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 3, 1, 0, 51, 0]||||0||||0||||0
[ML] make more GET and heavier processing APIs cancellable (#88142)          This commit makes the following APIs cancellable:          get datafeeds     get jobs     evaluate data frames     explain data frames     get job model snapshot     preview datafeed     preview data frame     get categories (this can be expensive due to grok parsing)||||[0, 0, 0, 1, 7, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 3, 14, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 19, 0, 0, 76, 0]||||0||||0||||0
Replace bridge methods with filtered methods in Painless (#88100)          The invokedynamic instruction does not perfectly follow the Painless casting model opting to add     bridge methods where necessary to ensure symmetric behavior between compile-time and run-time     casting using boxed types. This change replaces the specialized class loader and bridge methods using     filtered method handles instead. This reduces the overall complexity of runtime casting.||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix RandomSamplerIT#testRandomSamplerHistogram test input (#88191)          Periodically, a single 10 value is included which causes a 3rd histogram bucket to be created with very few values. Meaning sampling wouldn't get any docs that hit that bucket (especially with the randomly included deleted docs).          The failures that I saw had the 10.0 bucket with just one document.          closes: #88108||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
[ML] add deployed native models to inference_stats in trained model stats response (#88187)          This adds a valid `inference_stats` section for deployed native models.          `inference_stats` is effectively a sub-set of the `deployment_stats`. It's a high level view of the overall stats of the model, deployment_stats contains more detailed information around types of errors seen, throughput, etc.||||[0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0]||||0||||0||||0
fix: extract matrix stats using bucket_selector buckets_path (#88271)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add ability to select execution mode for cardinality aggregation (#87704)          Plumbs through a new parameter for the cardinality aggregation, to allow configuring the execution mode.  This can have significant impacts on speed and memory usage.  This PR exposes three collection modes and two heuristics that we can tune going forward.  All of these are treated as hints and can be silently ignored, e.g. if not applicable to the given field type.  I've change the default behavior to optimize for time, which potentially uses more memory.  Users can override this for the old behavior if needed.||||[0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 4, 0]||||0||||0||||0
Skip expensive name collision checks when building metadata from diff (#88266)          We can skip the name collision check here as we can and must assume that the incoming diff     won't be corrupted and gets us the correct next state.     This saves quite a bit of work on data node during state publication because the check gets     expensive for large states.||||[0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 47, 1, 0, 0, 1, 0]||||0||||0||||0
Refactor tasks to improve APM support (#87917)          Part of #84369. Split out from #87696. Rework how some work is executed     by creating child tasks for them, so that when traced by APM, it results     in more meaningful parent and child tasks in the UI. It also improves     how Elasticsearch is modelling the work.||||[0, 0, 0, 0, 5, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 11, 0, 0, 52, 0]||||0||||0||||0
[Transform] unmuting TransformContinuousIT to for debug output. (#88242)          unmute TransformContinuousIT and check that it isn't still indexing when querying||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Adds basic notifications for trained model deployments (#88214)          For specific models:     - deployment started     - deployment stopped          System notifications when rebalance occurrs with reasons:     - model deployment started     - model deployment stopped     - nodes changed     ||||[0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 6, 0, 0, 17, 0]||||0||||0||||0
Implement ILM/settings operator handlers (#88097)          Relates to #86224||||[0, 0, 0, 0, 12, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0]||||0||||0||||0
Use pre-parsed index mode when figuring out timestamp range (#88254)          Use `indexMode` field instead of parsing IndexMode from settings in     order to determine time series timestamp range. Parsing the index mode     isn't necessary, because we read the index mode when IndexMetadata is     constructed, and this just burns unnecessary CPU cycles.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Mute MLModelDeploymentsUpgradeIT (#88251)          Relates #87959||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Revert "Unmute Lintian test (#88228)"          This reverts commit 793dcc7c33200bf5f0e958e2ec7c07a4865e351e.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Dry up index name expression resolving a little (#88244)          Just two simple spots I found while researching something else.||||[0, 0, 0, 0, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 67, 7, 2, 9, 3, 0]||||0||||0||||0
Upgrade to Log4J 2.18.0 (#88237)          ||||[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0]||||0||||0||||0
Unmute Lintian test (#88228)          The fix for the problems identified in #88090 is in     elastic/ml-cpp#2337, so the test can be unmuted now.          Closes #88090||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Skip backing indices with a disjoint range on @timestamp field. (#85162)          Implicitly skip backing indices with a time series range that doesn't     match with a required filter on @timestamp field.          Relates to #74660||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 9, 1, 5, 6, 0]||||0||||0||||0
Use faster maths to project WGS84 to mercator (#88231)          ||||[0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0]||||0||||0||||0
Allow easing testing of java ea versions using gradle java tool chain support (#88188)          This introduces the ability to simply configure a java tool chain for elasticsearch java projects to be used.     If an environment variable `JAVA_TOOLCHAIN_HOME `is declared, this JDK will be used as toolChain in elasticsearch.java projects. If JAVA_RUNTIME_HOME is configured, it takes precedence over JAVA_TOOLCHAIN_HOME     for configuring test cluster runtimes.          This should make testing our build with java `ea` versions easier and allows detangling the used compiler jdk from the gradle java runtime.||||[0, 0, 0, 1, 3, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 2, 0]||||0||||0||||0
Optimize log cluster health performance. (#87723)          Optimize log cluster health performance by not building cluster health instances needlessly.          relates #77466     ||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0]||||0||||0||||0
Allow configuring snyk target reference and lifecycle properties (#88220)          We will use target reference to distinguish between different versions or branches of our elasticsearch project     to be able to trace vulnerable dependencies down to the version.          snyk lifecycle property allows filtering the project overview by `production` or `development`. When version     is ending with SNAPSHOT we configure the lifecycle as development. Otherwise its production.          Related to #87620||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 0]||||0||||0||||0
System indices ignore all user templates (#87260)          When creating an index with a system index descriptor, ignore all     templates. Update tests that check template behavior.          Co-authored-by: Nikola Grcevski <nikola.grcevski@elastic.co>||||[0, 0, 0, 0, 10, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 13, 0, 6, 16, 0]||||0||||0||||0
[Transform] Make default transform scheduler frequency 1s again (#88215)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Allow getting ShardCountStats. (#84805)          Co-authored-by: Elastic Machine <elasticmachine@users.noreply.github.com>||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Bump versions after 8.3.1 release     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Periodic warning for 1-node cluster w/ seed hosts (#88013)          For fully-formed single-node clusters, emit a periodic warning if seed_hosts has been set to a non-empty list.          Closes #85222     ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add generic interface for loading service providers from plugins (#88082)          Relates to 86224||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Mute test #88063 (#88207)          related #88063||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix testJoinWaitsForClusterApplier (#87842)          Block the cluster applier before disrupting the cluster so the victim     node doesn't try and rejoin too soon.          Closes #86974||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0]||||0||||0||||0
Retry after all S3 get failures that made progress (#88015)          S3 sometimes enters a state where blob downloads repeatedly fail but     with nontrivial progress between failures. Often each attempt yields 10s     or 100s of MBs of data. Today we abort a download after three (by     default) such failures, but this may not be enough to completely     retrieve a large blob during one of these flaky patches.          With this commit we start to avoid counting download attempts that     retrieved at least 1% of the configured `buffer_size` (typically 1MB)     towards the maximum number of retries.          Closes #87243||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Emit more detailed JDK runtime build information (#88180)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0]||||0||||0||||0
Run gradle integration tests with configuration cache enabled by default (#88148)          This changes AbstractGradleFuncTest to run with configuration cache enabled by default. That gives us better test coverage on how our build logic works with configuration cache enabled and makes it explicit which parts are not yet working.     We fixed some minor configuration cache related issues in our code.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 3, 0, 0, 4, 0, 0, 0, 8, 0]||||0||||0||||0
Replace ilm/slm with their full names (#88060)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 0]||||0||||0||||0
8.4 release notes ported from 8.3.0 release (#88136)          * Generate release notes for v8.3.0 (#87294)          * Generate release notes for v8.3.0          * [DOCS] Add 8.3 migration file to index          * Fixed version number          * Fix formatting of deprecation in 85326          * Use asciidoc format for deprecations          * Extract static content from migration/index          * This was just an enhancement          * Nope, it was an upgrade          * Added migration/index.asciidoc generation support (#87318)          Including extracting static content from migration/index, so the template would be as light as possible.          The reason for this work is because the gradle task `generateReleaseNotes` was not correctly adding new links and imports to the migrations/index and that caused documentation to fail building for 8.3.0.          * [DOCS] Add ml-cpp PRs to release notes          * Added back incorrectly deleted changlog          * Added missing highlight          * Fixed spelling of StackOverflowError          Co-authored-by: lcawl <lcawley@elastic.co>          * Brought back missing changelog for 87235 (#87370)          * Brought back missing changelog for 87235          * Regenerate release notes          * Regenerate release notes for BC3 (#87449)          * Regenerate release notes for BC3          * Re-applied manual fixes that Lisa Cawley used          * Fixed breaking changes generation          To match the manual edits done by Lisa Cawley          * Fixed failing test          Since the manual edits by Lisa removed the `-SNAPSHOT` from the docs     we remove it from the tests too.          * Remove changelogs for intermediate lucene upgrades          * Update release notes for BC4 (#87635)          * Update release notes for BC4          * Adding missing changelog for geo_grid          * Added missing highlight notes for 84250          * Update docs/reference/release-notes/highlights.asciidoc          Co-authored-by: David Kilfoyle <41695641+kilfoyle@users.noreply.github.com>          * Update docs/reference/release-notes/highlights.asciidoc          Co-authored-by: David Kilfoyle <41695641+kilfoyle@users.noreply.github.com>          * Backported fixes to original yaml          * Control sort order of release highlights          So that small changes to an individual highlight don't completely shuffle the entire document.          We also added links to the PRs from the highlight titles, for convenience.     Otherwise readers need to search the release notes for the changelog entry and click there,     which is a lot more work.          * Fixed failing test after new ordered highlights          Also made test verify re-ordering of highlights          Co-authored-by: David Kilfoyle <41695641+kilfoyle@users.noreply.github.com>          * Update release notes for BC5 (#87808)          * Update release notes for BC6 (#87912)          * Update release notes for BC9 (#88011)          * Regenerate release notes after version bump 8.4.0          And after forward porting 8.3.0 release notes changes.          * Regenerate after some changelog entries removed          * Re-prune the changelogs          * Removed three changelog entries          Co-authored-by: lcawl <lcawley@elastic.co>     Co-authored-by: David Kilfoyle <41695641+kilfoyle@users.noreply.github.com>||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 3, 0, 0, 5, 0]||||0||||0||||0
Add immutable 'operator' metadata classes for cluster state (#87763)          This commit only introduces the storage classes, unused for now.     Relates to #86224||||[0, 0, 0, 0, 4, 4, 0, 2, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 1, 6, 4, 0]||||0||||0||||0
Sort ingest pipeline stats by time spent executing (#88035)          This commit changes the `/_nodes/stats` API to return the pipelines in     descending order by the time spent executing. If a pipeline ties another     pipeline, they are sorted by ingest count.          This ensures that the most used and most expensive pipelines show up     first in the JSON response (to help tracking down which pipelines may be     most prevalent).          For example:          ```     {     "nodes" : {     "yiv09_ETRKSv4q8kz0d59A" : {     ...     "ingest" : {     "total" : {...},     "pipelines" : {     "set-name" : {     "count" : 4, // <-- tie-breaker     "time_in_millis" : 12, // <-- sorted first by this     ...     },     "set-face" : {     "count" : 2,     "time_in_millis" : 8,  // <-- less than 12     ...     }     ```||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]||||0||||0||||0
Script: Add Metadata to ingest context. (#87309)          Adds the `Metadata` class and `metadata()` method to the ingest context.          Metadata has getters and setters for index, id, routing, version and versionType.     It also has a getter for timestamp.          Refs: #86472||||[0, 0, 0, 0, 4, 2, 1, 0, 2, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 8, 9, 5, 1, 25, 0]||||0||||0||||0
Fixing CoordinationDiagnosticsServiceTests.testResultSerialization bug (#88189)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Cleanup needless anonymous classes where lambdas suffice (#88154)          Cleaning up a couple more spots of these, saving some verbosity     and in some cases also some allocations.          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 6, 0]||||0||||0||||0
Merge creating indices and shards methods in IndicesClusterStateService (#88184)          Looping over the local routing node can be quite expensive for e.g.     large warm/cold/frozen nodes. We can save one full iteration as well     as a couple of map lookups by dealing with index and shard creation+updates     in a single loop.          ||||[0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 21, 1, 4, 6, 0]||||0||||0||||0
Ingest: RandomDocumentPicks.randomExistingFieldName doesn't return _version (#88183)          When `RandomDocumentPicks.randomExistingFieldName` selects a field, the     caller expects to be able to manipulate that field in any manner.  `_version` has     special validation, must fit in an `long` and may not be `null`.          This change no longer returns `_version` from `randomExistingFieldName` unless it is the only field in the document.          Related to change: https://github.com/elastic/elasticsearch/pull/88102||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Creating a transport action for the CoordinationDiagnosticsService (#87984)          This exposes the CoordinationDiagnosticsService (#87672) through a transport action so that it can     be called remotely as part of the health API in the event that: (1) there has been no master recently,     (2) there are master-eligible nodes in the cluster, (3) none are elected, and (4) the current node is     not master eligible.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Simplify QueryCache Construction (#88173)          We don't need to keep references to index settings in all of these,     nor do we need per-index loggers or deprecation loggers here.     Making the construction here a little cheaper helps with the     performance of some cluster state operations that create temporary     index-services.     Also, removing references to `IndexSettings` and other per-index state     is helpful in identifying spots to reduce the per-index overhead on     data-nodes down the road.     ||||[0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 1, 5, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 10, 11, 0, 0, 25, 0]||||0||||0||||0
Ingest: Enforce _version metadata not null in sourceAndMetadata map (#88102)          * Ingest: Enforce _version metadata not null in sourceAndMetadata map          The `_version` metadata field should always exist in the sourceAndMetadata     map, this change enforces that invariant but allows tests to avoid it     if necessary.          Refs: #87309||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 17, 0, 0, 52, 0]||||0||||0||||0
Use the provided SAS token without SDK sanitation that can produce invalid signatures (#88155)          When the SAS token is prefixed with ? the SDK parses incorrectly     all the query params and removes the first query param, this     produces an invalid signature preventing the repository to     authenticate against the storage service. This commit reverts     to the previous behaviour where the SAS token was appended to     the URL as it is provided by the user.          Closes #88140||||[0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 10, 6, 0, 0, 0, 0, 0, 0, 0, 7, 0, 1, 2, 0]||||0||||0||||0
Setup elasticsearch dependency monitoring with Snyk for production code (#88036)          This adds the generation and upload logic of Gradle dependency graphs to snyk          We directly implemented a rest api based snyk plugin as:          the existing snyk gradle plugin delegates to the snyk command line tool the command line tool     uses custom gradle logic by injecting a init file that is          a) using deprecated build logic which we definitely want to avoid     b) uses gradle api we avoid like eager task creation.          Shipping this as a internal gradle plugin gives us the most flexibility as we only want to monitor     production code for now we apply this plugin as part of the elasticsearch.build plugin,     that usage has been for now the de-facto indicator if a project is considered a "production" project     that ends up in our distribution or public maven repositories. This isnt yet ideal and we will revisit     the distinction between production and non production code / projects in a separate effort.          As part of this effort we added the elasticsearch.build plugin to more projects that actually end up     in the distribution. To unblock us on this we for now disabled a few check tasks that started failing by applying elasticsearch.build.          Addresses  #87620||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]||||0||||0||||0
Stream input and output support for optional collections (#88127)          This PR adds support for reading and writing optional collections via     StreamInput and StreamOutput.     ||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]||||0||||0||||0
[Transform] Increase transform scheduler frequency so that it runs every 0.5s (#88153)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use a faster but less accurate log algorithm for computing Geotile Y coordinate (#87515)          This commit introduces a new algorithm to ESSloppyMath to compute logarithm (base e)||||[0, 0, 0, 0, 3, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Support updates of API key attributes [service layer] (#87924)          Service level implementation to add support for updating attributes of     existing API keys. This allows end-users to modify privileges and     metadata associated with API keys dynamically, without requiring     rolling out new API keys every time there is a change.          Updatable attributes are role_descriptors and metadata. Several     other attributes are updated automatically, on every update call,     including limited_by_role_descriptors, creator, and version. API     key attributes are replaced, not merged.          On every update, the API key doc cache is cleared for the updated API     key.          This PR implements the necessary service layer changes in     ApiKeyService. I will integrate this with the REST and transport     layers in a subsequent PR.          Relates: #87870||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Avoid WindowsFS in LongGCDisruption (#88110)          Closes #87914||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Bump versions after 7.17.5 release     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Port all remaining build-tool tests to spock (#88089)          - Make our build tool tests more readable     - One step closer to remove outdated test fixtures like GradleUnitTestCase and friends          Didn't port some basic setter getter tests like PluginExtensionTests as it does not add much value and we have integration test coverage for this stuff too||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Increase LDAP connection timeout settings to 10s (#88117)          AD tests sometimes fail due to a response timeout error.     By default connection and response timeouts were set to 5s.     This commit is increasing them to 10s.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Ensure the test version is always pre-8.3.0 (#88138)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] make ML stats APIs cancellable (#88030)          Many machine learning stats APIs make multiple searches per call. Making them cancellable allows for those searches to be cancelled if the HTTP connection is closed.          This improves scalability and performance.          Relates #88010||||[0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 15, 0, 0, 82, 0]||||0||||0||||0
Consolidate bootstrap state (#88041)          Now that initialization is broken into phases, the state between these     phases can be better organized. This commit reintroduces the Bootstrap     class, but now uses it as the holder for state between the phases.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 1, 0, 0, 8, 9, 0, 1, 5, 0]||||0||||0||||0
Include the calling transport task in the method for individual node task operations (#88081)          Currently, if the parent transport task is cancelled, there is no way to propagate the cancellation to any NEW transport action inacted by `TransportTasksAction#taskOperation`.          This commit passes the originating transport task into `TransportTasksAction#taskOperation` so that any additional transport actions can be cancelled if the originating transport task is cancelled.          Note: it is up to the implementer to enable this cancellation logic. This commit simply updates the framework to make it possible.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Encapsulate SequenceIDFields (#88092)          This makes the fields in `SequenceIDFields` private so we can modify     them more easily without them being accidentally used by other parts of     the application in incompatible ways.||||[0, 0, 0, 0, 4, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 2, 0, 0, 0, 1, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 55, 7, 0, 3, 67, 0]||||0||||0||||0
Fix synthetic source test (#88096)          The `testSyntheticSourceMany` was leaking an index reader *sometimes*,     causing the a file handle leak.          Closes #88069||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 5, 1, 0, 0]||||0||||0||||0
Add processors to autoscaling capacity response (#87895)          This adds `processors` to the autoscaling capacity response.          `processors` in the current capacity calculation is determined by the `allocated_processors` field in OsInfo. The reason behind this is because `allocated_processors` can be overridden by the process starting the node. Consequently, when autoscaling deciders need to look at the current processors and request for more, they should look at `allocated_processors` not `available_processors`. Mostly, this is because certain systems may want to account for threads being used by external processes and not allow ES to use all the available processors on the OS.||||[0, 0, 0, 0, 5, 4, 0, 5, 1, 1, 0, 0, 1, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, 9, 0, 5, 5, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 5, 47, 2, 5, 89, 0]||||0||||0||||0
Add version 8.3.1 and remove 8.2.4     ||||[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Unmute model deployment rolling upgrade test (#88124)          Unmuting to collect logs after adding more logging to     version 8.2.          Relates #87959          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
muting transform continuous IT (#88132)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Don't extend AbstractIndexComponent in AbstractCharFilterFactory (#88125)          Same as #88113 but for AbstractCharFilterFactory.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 7, 0, 0, 9, 0]||||0||||0||||0
[ML] improve trained model stats API performance (#87978)          Previous, get trained model stats API would build every pipeline defined in cluster state.          This is problematic when MANY pipelines are defined. Especially if those pipelines take some time to parse (consider GROK).          This improvement is part of fixing: #87931||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 2, 0]||||0||||0||||0
Fix look-ahead-time setting validation for release builds (#88087)          Follow up to #87847          Adding a setting polling callback will fail if the setting is not there.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]||||0||||0||||0
Fix ConcurrentSnapshotsIT.testMasterFailoverDuringStaleIndicesCleanup (#88065)          As a result of https://github.com/elastic/elasticsearch/pull/86514 we now     remove the snapshot delete from the cluster state before cleaning up     stale shard level blobs so we have to block master earlier on deleting the     root level index-N blob to get the desired cluster state where delete     and snapshot creation are both in the cluster state at the same time.          closes #88061     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Mute TermsGroupByIT test #88063     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Increase transform scheduler frequency so that it runs every 1s (#88116)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Don't extend AbstractIndexComponent in AbstractTokenFilter (#88113)          No need for this extension, we don't make use of the settings or deprecation logger     in production any more. Also, this slows down CS operations that require a     temporary index service which builds quite a bit slower when the loggers     need to be set up via reflective calls.     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 2, 0, 0, 83, 0]||||0||||0||||0
Update http client version (#87491)          Moves a few Apache HTTP client dependencies to their latest version          - httpclient -> 4.5.13     - httpasyncclient -> 4.1.5     - httpcore -> 4.4.13||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Skip building redundant set in `org.elasticsearch.indices.cluster.IndicesClusterStateService#removeIndices` (#88073)          No need to build a fresh set of all the indices, we already have a map of all of them     in the routing nodes that we can check.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0]||||0||||0||||0
Move the ingest attachment processor to the default distribution (#87989)          The ingest attachment processor is currently available as a plugin. This     commit moves the processor to the default distribution so it is always     available.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[TEST] Fixes to StringMatcherTests (#88046)          This commit fixes two issues with StringMatcherTests          **Problem 1**     Under some seeds (e.g. 3C93AEF7628D6611) prefix2 would start     with the same text as prefix1. This would mean that input that was     intended to test against prefix2 would actually match prefix1, and     violate the expectations of the test          **Problem 2**     The code had the equivalent of          randomFrom( "abc".toCharArray() )          But Hamcest does not have a randomFrom(char[]) method, so this     code was treated as          randomFrom( new Object[] { new char[] { 'a', 'b', 'c' } } )          and will return a char[]. Tests that were written assuming they had     a random character, actually had an array (char[]) and would then     stringify that object into something like          [C@5e67f506          Resolves: #88024||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Ingest: Add validation and strong typing to sourceAndMetdata map (#87673)          Adds `IngestSourceAndMetdata` to replace the sourceAndMetadata map.          This validates metadata values when they are added to the map for use in     scripts and other process as well as provides typed getters and for use     inside of server.          This change lays the foundation for strongly typed Metadata access in scripting.          Related: #87309||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 11, 17, 0, 2, 49, 0]||||0||||0||||0
Mute test05CheckLintian     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Synthetic source numbers in columns (#88025)          This speeds up synthetic source for numbers and dates by loading them     column by column. On cached disk blocks, on average it's only 1ms per     for 1k documents, but it seems to help a fair bit in the worst case     and I expect it'll help much more on non-cached disk blocks.          ```     |   50th percentile service time | default_1k | 32.9131 | 31.6141 | ms |  -3.95% |     |   90th percentile service time | default_1k | 34.937  | 34.8247 | ms |  -0.32% |     |   99th percentile service time | default_1k | 42.2246 | 40.0853 | ms |  -5.07% |     | 99.9th percentile service time | default_1k | 54.0964 | 41.993  | ms | -22.37% |     |  100th percentile service time | default_1k | 55.2969 | 53.4642 | ms |  -3.31% |     ```||||[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 0, 1, 0]||||0||||0||||0
Add detailed error messages for searchable snapshot shared folder assertions (#87497)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 3, 0]||||0||||0||||0
Add OperatorHandler interface (#87767)          ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] mute TermsOnDateGroupBy cont. test #88063 (#88067)          relates: https://github.com/elastic/elasticsearch/issues/88063||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] muting MLModelDeploymentsUpgradeIT #87959 (#88070)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix ShuffleForcedMergePolicyTests#testDiagnostics (#88062)          Closes #88032||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
[ML] Stopping a model deployment should trigger rebalance (#88016)          When a model deployment is stopped we remove the allocations     it was using. This opens up capacity for granting more allocations     to existing deployments that may not be fully satisfied.          With this commit we attempt to rebalance model assignments     after a model deployment has been stopped.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Add easier configuration cache test support in build logic tests (#88047)          This is intended to help us getting closer to #57918 by implicitly     testing our build logic configuration-cache support. Plugin and Task     tests can be marked as configuration cache compatible now and we will     always run then with configuration cache enabled.          By default, gradle will fail the build if configuration cache problems     have been detected during build execution. That should be in general     better then adding explicit tests for testing configuration cache     compatibility per Test class||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make AsyncPersistedState.resetVotingConfiguration fast (#88050)          Using the builder just to update that one field in the metadata means     running through the name collision checks on the metadata which are very     expensive. In the many-shards benchmark run it takes ~2% of total CPU     time just for this operation.     Even though this is running async on a thread off the critical path I think     it's worthwhile fixing this to free up some CPU for other tasks.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Don't ignore pipeline for upserts in bulk api (#87719)          Don't ignore pipelines defined in bulk item for updates with upsert in bulk api.          Closes #87131||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Geoip processor should respect the ignore_missing parameter in case of missing database (#87793)          If database is missing then respect ignore_missing parameter configured     on the geoip processor. If ignore_missing is enabled then the document     should not be tagged. In this case the document shouldn't be tagged.          Closes #87345||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[Transform] Introduce TransformScheduler central service (#84657)          ||||[0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 6, 3, 0, 0, 0, 1, 0, 0, 5, 13, 0, 0, 31, 0]||||0||||0||||0
Presize RoutingNode (#88043)          Presize maps in `RoutingNode` with the best-guess that every node     holds it's proportionate share of double the number of indices which     seems like the best possible guess (1 shards + 1 replica per index,     all nodes homogeneous).     This saves a lot of re-hashing when data nodes hold lots of shards     and speeds up bootstrapping 50k indices in the many-shards benchmark     by more than 2 percent.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 5, 0]||||0||||0||||0
Faster DatastreamMetadata Diff application (#88045)          This was doing a needless copy which showed up in many shards benchmarking.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Consolidate remaining startup in phase 3 (#88017)          This commit moves the remaining pieces of startup into a "phase 3". This     consists of everything after security manager is initialized. Phase 3     is where the node is constructed and the system becomes multi threaded.||||[0, 0, 0, 0, 6, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 4, 0, 0, 2, 0]||||0||||0||||0
Speedup setting default values a little (#87980)          Many shards benchmarks have recently seen a bit of an increase in the time spent on     settings from new settings getting added. This makes some defaults quite a bit     cheaper by saving re-serialization of the same default value which helps with     some cluster state application cases for large index counts.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Initialize ES logging api for tests (#88022)          This commit adds initialization of the new ES logging api into     ESTestCase, so that tests can begin using the new logging api.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] make trained model rest APIs cancellable (#88009)          This change makes all the trained model APIs cancellable, and addresses the handful of APIs that rely on our abstract resource structure.          closes: #87931||||[0, 0, 0, 0, 9, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 20, 0, 0, 72, 0]||||0||||0||||0
add missing logstash timestamp mapping (#87927)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Rebalance should not notify listener before update is applied (#88012)          When we are rebalancing trained model assignments, we eventually     update cluster state with the new metadata. We only want to     notify the listener after we have applied the cluster state update.     This commit fixes a bug where we could notify before the update     was actually applied resulting in NPE when writing the response     of the `CreateTrainedModelAssignmentAction`.          This is a fix following the work done in #87366.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0]||||0||||0||||0
Remove TaskListener interface (#87637)          `TaskListener` is almost always a trivial wrapper around an     `ActionListener`. There's a couple of places where that's not true, it     reports the task ID in a log message, but these logging effects can be     achieved in other ways which don't require polluting various widely-used     APIs so much.          This commit replaces all usages of `TaskListener` with `ActionListener`,     reworking the logging effects, and removing the now-unnecessary     overrides.          Relates #86765 in that this commit simplifies some of the APIs that     #86765 will need to adjust.||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 1, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 6, 1, 0, 0, 0, 0, 0, 0, 2, 9, 0, 0, 7, 0]||||0||||0||||0
Speed up synthetic keyword, ip, and text fields (#87930)          This speeds up synthetic source, especially when there are many fields     in the index that are declared in the mapping but don't have values.     This is fairly common with ECS, and the tsdb rally track uses that. And     this improves fetch performance of that track:     ```     |  50th percentile service time |    default |   6.24029 |  4.85568 | ms | -22.19% |     |  90th percentile service time |    default |   7.89923 |  6.52069 | ms | -17.45% |     |  99th percentile service time |    default |  12.0306  | 16.435   | ms | +36.61% |     | 100th percentile service time |    default |  14.2873  | 17.1175  | ms | +19.81% |     |  50th percentile service time | default_1k | 158.425   | 25.3236  | ms | -84.02% |     |  90th percentile service time | default_1k | 165.46    | 30.8655  | ms | -81.35% |     |  99th percentile service time | default_1k | 168.954   | 33.3342  | ms | -80.27% |     | 100th percentile service time | default_1k | 174.341   | 34.8344  | ms | -80.02% |     ```          There's a slight increase in the 99th and 100th percentile service time     for fetching ten document which think is unlucky jitter. Hopefully. The     average performance of fetching ten docs improves anyway so I think     we're ok. Fetching a thousand documents improves 80% across the board     which is lovely.          This works by doing three things:     1. Teach the "leaf" layer of source loader to detect when the field is     empty in that segment and remove it from the synthesis process     entirely. This brings most of the speed up in tsdb.     2. Replace `hasValue` with a callback when writing the first value.     `hasValue` was resulting in a 2^n-like number of calls that really     showed up in the profiler.     3. Replace the `ArrayList` of leaf loaders with an array. Before fixing     the other two issues the `ArrayList`'s iterator really showed up in     the profiling. Probably much less worth it now, but it's small.          All of this brings synthetic source much closer to the fetch performance     of standard _source:     ```     |  50th percentile service time | default_1k |  11.4016  | 25.3236  | ms | +122.11% |     |  90th percentile service time | default_1k |  13.7212  | 30.8655  | ms | +124.95% |     |  99th percentile service time | default_1k |  15.8785  | 33.3342  | ms | +109.93% |     | 100th percentile service time | default_1k |  16.9715  | 34.8344  | ms | +105.25% |     ```          One important thing, these perf numbers come from fetching *hot* blocks     on disk. They mostly compare CPU overhead and not disk overhead.     ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0]||||0||||0||||0
[TSDB] Simplify the rollup action (#87981)          This PR changes the _rollup action so that it will only create the rollup index.     Tasks such index swap in the data stream and source index deletion will not be     handled by the rollup action. Instead, those actions will be taken care of by the     rollup ILM.          Those changes make rollup behavior more consistent with similar operations     such as shrink or snapshot.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]||||0||||0||||0
Fix unique realm name check to cover default realms (#87999)          All enabled realms must have unique names. This PR tightened the logic     for ensuring realm name uniqueness. Previously the unique name check     does not cover realms that are automatically enabled.          Relates: #69096||||[0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 4, 0, 0, 1, 0]||||0||||0||||0
[Transform] Execute _refresh separately from DBQ, with system permissions. (#88005)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
[ML] Add logging to the model deployments rolling upgrade test (#87982)          To debug the failure in #87959.          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Use normalized memory in bin packing node prioritization (#87925)          This commit fixes a bug in the `LinearProgrammingPlanSolver`     used for distributing model allocations. When we are doing the     initial bin-packing, we should be using normalized memory     as a factor. Instead, we were using actual memory which would     dominate the heuristic and result in always prioritize the     largest nodes in terms of memory and completely disregard existing     allocations.          The linear solver would still provide a good solution most of     the times but in some edge cases we'd end up with a bad solution.     This commit adds a test with an edge case like this.          In addition, we improve the `AssignmentPlanner` by trying out     both approaches (1. preserve one allocation per assignment,     2. preserve all allocations) when the first try does not give     a result that satisfies all models.||||[0, 0, 0, 0, 3, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 1, 2, 0]||||0||||0||||0
simplify resize deciders (#87958)          This change pulls up checks and removes code duplication to make those     two deciders slightly cheaper.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 4, 0]||||0||||0||||0
Use HashMap in admin get actions (#87938)          Actions for getting aliases, indices, and settings all return a Map. Yet     internally these unnecessarily ImmutableOpenMap. This commit converts     these actions to use HashMap.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 13, 0]||||0||||0||||0
Remove legacy bootstrap plugins (#87775)          Bootstrap plugins were an internal mechanism added to allow a     filesystemprovider for cloud with the quota-aware-fs plugin. Since that     was removed, bootstrap plugins no longer serve a purpose. They were     never officially documented because they were for internal use only.     This commit removes the bootstrap plugins infrastructure.||||[0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 4, 0, 0, 0, 0, 0, 0, 30, 5, 1, 1, 49, 0]||||0||||0||||0
Cache notice generation tasks (#87991)          This commit makes the NoticeTask cacheable. Although it is not that     expensive (a few seconds), it's worth it overall.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Consolidate startup before security manager into phase 2 (#87941)          This commit introduces a second phase of startup. It consists of     evertying after logging, but before security manager is initialized.     This is for things that require security manager permissions that we do     not want to grant for the lifetime of the process.||||[0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0]||||0||||0||||0
[DOCS]Fix priorities typo in cluster state task config. (#87824)          Fix priorities typo in cluster state task config.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Upgrade to new Lucene snapshot (#87932)          This PR uses Lucene-9.3 snapshot in Elasticsearch 8.4. Noticeable changes in this Lucene snapshot:          - Merge-on-refresh (disabled)     - No more pathological merging     - SortedSetDocValues#count for value_count aggs||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 1, 1, 0, 0, 8, 0]||||0||||0||||0
Correctly pre-size HashSets (#87700)          The HashSet(int) constructor accepts the capacity of the set rather than its size. Unfortunately, HashSet requires N/0.75 capacity to hold N elements. So, if we call new HashSet(n) to hold N elements, the map will be too small and need to be     resized/rehashed midway.          We add a new methods Sets.newHashSetWithExpectedSize and Sets.newLinkedHashSetWithExpectedSize that calculate the correct capacity for the specified expected size.          See          * https://bugs.openjdk.org/browse/JDK-8284975     * https://bugs.openjdk.org/browse/JDK-8287419     * https://github.com/openjdk/jdk/pull/8302||||[0, 0, 0, 0, 6, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 67, 0]||||0||||0||||0
Test fix: Disable HealthNode in MetadataIndexTemplateServiceTests (#87967)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Prevent migration of system indices that match templates (#87933)          ||||[0, 0, 0, 0, 10, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 0, 1, 7, 0]||||0||||0||||0
Improve console exception messages (#87942)          This commit improves upon the recent console exception logging isolation     to emit more than just the exception message. The exception class is     also printed, as well as up to the first 5 elements of the stack. THe     stack trace is a hint, and can often be enough, yet the full stack trace     (or a truncated version if a guice exception) will still exist in the     logs. Addtionally, unit tests are added.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Batch ILM move to retry step task update (#86759)          This one was still unbatched, same appraoch to making it batched as with the other step update tasks.          Co-authored-by: Joe Gallo <joe.gallo@elastic.co>||||[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]||||0||||0||||0
Run TransportClusterInfoActions on MANAGEMENT pool (#87679)          Today subclasses of `TransportClusterInfoAction` execute     `masterOperation` on `SAME` which often means a transport worker. This     includes nontrivial things like decompressing mappings in     `TransportGetMappingsAction` and `TransportGetIndexAction` (if a field     filter is specified) and iterating over index settings and aliases in     `TransportGetIndexAction`.          This commit moves this work to the `MANAGEMENT` threadpool instead.||||[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 5, 0, 0, 1, 0]||||0||||0||||0
Fix StableMasterHealthIndicatorServiceTests and `start-slm` doc test (#87962)          ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 2, 0, 0, 0, 0]||||0||||0||||0
[ML] Include authorization info in responses when creating jobs (#87950)          https://github.com/elastic/elasticsearch/pull/87884 added     authorization information to the datafeed and data frame     analytics job configs returned by listing them, but not to     the ones returned from creating or updating them. For     consistency it's best that the same fields are present in     both places.||||[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 21, 0]||||0||||0||||0
Add start slm user action (#87854)          This creates a user action for the slm health indicator that will help     the user to start SLM.||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Add help guide to the contat support user action (#87689)          ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Add user action for repository_integrity indicator (#87920)          ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0]||||0||||0||||0
Create ILM not running user action (#87852)          This creates a user action for the ilm health indicator that will help     the user to start ILM.||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
More compact serialization of ShardStats (#87627)          The two paths are almost always the same, we can serialize     them only once to reduce memory consumption for shard stats     request handling on the coordinating node.||||[0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 4, 0, 2, 0, 0]||||0||||0||||0
Add support for VERSION field type in SQL and EQL (#87590)          ||||[0, 0, 0, 0, 18, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 20, 5, 0, 5, 0]||||0||||0||||0
Move kNN search and dense vectors to core (#87815)          This PR moves kNN search and dense vector support out of an xpack plugin and     into server.          In #87625 we plan to integrate ANN search into the main `_search` endpoint as a     new top-level component called `knn`. So kNN will be a dedicated part of the     search request, and we'll have kNN logic within the search phases. The classes     and logic will live in server, matching the other search components like     suggesters, field collapsing, etc.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0]||||0||||0||||0
Support removing ignore filters for audit logging (#87675)          Ignore filters of audit logging can be configured with the cluster     settings APIs. While adding new filters work correclty, removing     filters does not work until node restart due to a bug (#68588). This PR     fixes the bug by correctly remove the ignore filter when all rules of a     filtering policy is set to null.          Resolves: #68588||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]||||0||||0||||0
Use Azul Zulu JDK8 distribution instead of Adoptium/OpenJDK on MacOS with Apple Silicon (#87733)          ||||[0, 0, 0, 0, 3, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 1, 2, 0]||||0||||0||||0
Adding additional capability to the master_is_stable health indicator service (#87482)          This builds on #86524 by supporting two additional conditions, both of which happen when there has been     no elected master for more than 30 seconds (from the queried node's point of view), and both of which return     a RED status:     (1) There are no master-eligible nodes found in the cluster     (2) The node being queried sees a master-eligible node that has been elected the master, but cannot join it||||[0, 0, 0, 0, 7, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 1, 0, 0, 4, 0]||||0||||0||||0
Fixing a bug in testYellowWithTooManyMasterChanges (#87865)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Fix rest example plugin (#87923)          This is a followup to     https://github.com/elastic/elasticsearch/pull/87504, to fix the example     plugin that used BytesRestResponse.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Speed up synthetic source (#87882)          This speeds up synthetic source, especially when there are many fields     in the index that are declared in the mapping but don't have values.     This is fairly common with ECS, and the tsdb rally track uses that. And     this improves fetch performance of that track:          ```     |  50th percentile service time |    default |   6.24029 |  4.85568 | ms | -22.19% |     |  90th percentile service time |    default |   7.89923 |  6.52069 | ms | -17.45% |     |  99th percentile service time |    default |  12.0306  | 16.435   | ms | +36.61% |     | 100th percentile service time |    default |  14.2873  | 17.1175  | ms | +19.81% |     |  50th percentile service time | default_1k | 158.425   | 25.3236  | ms | -84.02% |     |  90th percentile service time | default_1k | 165.46    | 30.8655  | ms | -81.35% |     |  99th percentile service time | default_1k | 168.954   | 33.3342  | ms | -80.27% |     | 100th percentile service time | default_1k | 174.341   | 34.8344  | ms | -80.02% |     ```          There's a slight increase in the 99th and 100th percentile service time     for fetching ten document which think is unlucky jitter. Hopefully. The     average performance of fetching ten docs improves anyway so I think     we're ok. Fetching a thousand documents improves 80% across the board     which is lovely.          This works by doing three things: 1. Teach the "leaf" layer of source     loader to detect when the field is    empty in that segment and remove     it from the synthesis process    entirely. This brings most of the speed     up in tsdb. 2. Replace `hasValue` with `advanceToDoc` returning     `boolean` and     cache the result. 3. Replace the `ArrayList` of leaf     loaders with an array. Before fixing    the other two issues the     `ArrayList`'s iterator really showed up in    the profiling. Probably     much less worth it now, but it's small.          All of this brings synthetic source much closer to the fetch performance     of standard _source:          ```     |  50th percentile service time | default_1k |  11.4016  | 25.3236  | ms | +122.11% |     |  90th percentile service time | default_1k |  13.7212  | 30.8655  | ms | +124.95% |     |  99th percentile service time | default_1k |  15.8785  | 33.3342  | ms | +109.93% |     | 100th percentile service time | default_1k |  16.9715  | 34.8344  | ms | +105.25% |     ```          One important thing, these perf numbers come from fetching *hot* blocks     on disk. They mostly compare CPU overhead and not disk overhead.          ![image](https://user-images.githubusercontent.com/215970/174795592-dae78e69-4871-4698-911c-fb559eb5a78a.png)||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0]||||0||||0||||0
More tests for filter-by-filter fast paths (#87857)          This adds some more tests for the filter-by-filter execution mechanism     for `terms` and `date_histogram` around the "fast path" that it can take     when we can use the lucene `Weight#count` method. Specifically, this     fixes some flakiness in a test when some segments can't take the fast     path. And it adds a new test where all segments can take the fast path     even though there is a filter - but the filter matches all documents.     Finally, it fixes another flaky test that assumed there was always a     single segment.          Closes #87722||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Add force_synthetic_source to mget (#87574)          This adds the option to force synthetic source to the MGET API. See     #87068 for more discussion on why you'd want to do that - the short     version is to get an upper bound on the performance cost of using     synthetic source in MGET.     ||||[0, 0, 0, 0, 7, 2, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27, 23, 0, 0, 2, 0]||||0||||0||||0
[ML] Improve scalability of NLP models (#87366)          We can improve a model's latency and throughput by using more     threads for each inference request. We can also improve its     throughput by processing multiple inference requests in parallel.     A user can set the model's `number_of_allocations` and `threads_per_allocation`     settings to increase performance.     However, if we use more threads than the node's allocated processors,     we end up with thread oversubscription and performance deteriorates throughout.          This commit changes the way model allocations are distributed across the     ML nodes of the cluster. Up to now, we were trying to allocate each model     on every node. Now, we make use of the `AssignmentPlanner` class introduced     in #86004 in order to compute an assignment plan that distributes model     allocations across the cluster while we maximize the number of allocations     we provide to each model without oversubscribing the nodes' CPU.||||[1, 0, 0, 0, 38, 9, 4, 1, 0, 2, 0, 10, 8, 2, 1, 19, 3, 1, 0, 0, 1, 8, 9, 11, 1, 3, 7, 0, 0, 0, 0, 0, 0, 0, 15, 2, 0, 0, 0, 2, 0, 0, 117, 91, 2, 6, 159, 0]||||0||||0||||0
Fix failure on GeoShapeQueryTestCase#testRandomGeoCollectionQuery (#87916)          Use the safer GeometryTestUtils instead of Lucene GeoTestUtil to generate random polygons.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Cleanup indirection in batch close utils (#87685)          Some of these show up in profiling of heavy transport load.     It's not a big thing but it's always nice to save a few cycles     on transport threads.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 2, 21, 0, 2, 3, 0]||||0||||0||||0
fix compilation     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Cleanup dead code in o.e.common (round 2) (#87825)          Another 500+ LoC of simple deletes.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 52, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Add high level java docs to DesiredNodes (#87875)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use desired nodes during data tier allocation decisions  (#87735)          Today when the DataTierAllocationDecider checks if a shard can be allocated     in a node or not it uses the current cluster topology. This works fine in most cases     when the data flows from hotter to colder data nodes as it was designed. But     in certain situations users might want to remove a tier (i.e. the cold tier) that     allows having shards in hotter tiers, but with the current implementation once     a shard is allocated into the highest preference tier and there are nodes of that     tier, the shard won't move. This commit introduces a change that allows to use     the desired nodes (when available) to compute the preferred tier based on the     cluster topology provided by the desired nodes (only taking into account desired     nodes that are in ACTUALIZED status).||||[0, 0, 0, 0, 32, 5, 0, 2, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 38, 58, 0, 2, 23, 0]||||0||||0||||0
Remove keystore v1 and v2 formats (#87893)          The keystore format has been changed a few times since it was first     introduced. Part of Elasticsearch startup automatically upgrades the     format. Since Elasticsearch has fixed bounds of supported versions for     upgrades, there are also fixed bounds on the keystore formats we might     need to read.          The v3 keystore format was introduced in Elasticsearch 6.3.0. Since     current Elasticsearch master branch is 8.x, and 8.x only supports     offline upgrades from 7.x, it is therefore impossible to need to read     v1 or v2 formats. This commit removes support for those formats.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use HashMap inside cluster info service (#87899)          The InternalClusterInfoService internally uses ImmutableOpenMap     for keeping track of available space on each node. This commit converts     those usages to use HashMap. Note that an unmodifiableMap wrapper is     used because updates to this (from each node) are likely to happen often     as disk is used.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 7, 0]||||0||||0||||0
Revert "Simplify adding dynamic sub-fields to their dynamic parent object (#87866)"          This reverts commit 73b0273f4d83797fd364405bd2c420c7aee323bd (#87866) as an unexpected percolator test failure has surfaced, which did not surface as part of the PR tests run.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Simplify adding dynamic sub-fields to their dynamic parent object (#87866)          DocumentParserContext holds all the dynamic mappers created while parsing a document, as well as dynamic object mappers on a separate map so they can be looked up by name quickly when parsing their sub-fields and looking for their parent field. For every sub-field, so far we looked up the corresponding object mapper and then call .newBuilder on it. Calling newBuilder can be done already when the object mapper is added to the map, which simplifies the logic down the line as instead of creating a new builde for each sub-field, we re-use the same builder and add sub-fields to it. This has no effect on the resulting dynamic update, but it simplifies the code and it should have a positive impact on performance.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Move the master stability logic into its own service separate from the HealthIndicatorService (#87672)          This commit moves most of the logic of StableMasterHealthIndicatorService into CoordinationDiagnosticsService,     leaving only the parts that are specific to forming up the health API response.||||[0, 0, 0, 0, 6, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 23, 9, 0, 0, 0, 0, 0, 0, 10, 3, 0, 0, 4, 0]||||0||||0||||0
Ingest: move IngestDocument test ctor usage to static builder (#87770)          `IngestDocument` has a test constructor that takes a `sourceAndMetadata` and `ingestMetadata` map.          However, that test constructor was also used from wire deserialization in `WriteableIngestDocument`     and during `XContent` parsing.          This change moves test usage into test static builders and the wire usage into another static builder to     make the callers intent clear.          `IngestDocument`s constructed for test usage will not need metadata     validation performed on construction when that is added in a future commit.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 78, 57, 2, 0, 49, 0]||||0||||0||||0
[ML] Add authorization info to ML config listings (#87884)          ML datafeeds and data frame analytics jobs remember permissions     from their time of creation or most recent update. It can be     quite hard to determine what these are when listing their     configs, which can lead to uncertainty about whether some minor     update changed the permissions.          This change adds information about the permissions to the     config listings.          If the last update was from a user then the permissions used     are the roles they had at the time, and a list of these roles     is added to the new `authorization` field of the datafeed or     data frame analytics job config listing.          If the last update was using an API key then the permissions     of that API key are used for subsequent searches and the new     `authorization` field of the datafeed or data frame analytics     job config listing shows the API key name and ID.          If a service account did the last update then the service     account name is added to the new `authorization` field of the     datafeed or data frame analytics job config listing.||||[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 0, 0]||||0||||0||||0
Fix FollowIndexSecurityIT.testAutoFollowPatterns (#87853)          The test FollowIndexSecurityIT.testAutoFollowPatterns sometimes     fails when verifying the monitoring documents about auto-follow     stats. I wasn't able to reproduce locally but I suspect that monitoring     collects auto-follow stats before they are updated. Instead it should     collect auto follow stats monitoring documents once indices are     effectively followed.          There are also some index / auto-follow pattern conflicts with other     tests in the same class, so this PR also changes that. In case this     fix is not enough, the full monitoring documents should appear in     test log to help further debugging.          Closes #84888     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add more detail to assertion in TransportService (#87756)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Specify proper port range in InternalTestCluster (#87885)          Today nodes started in an `InternalTestCluster` use `transport.port: 0`     and `http.port: 0` which selects a port from the ephemeral range. This     range is also used by other tests, notably REST tests, and this can lead     to collisions and consequent failures when nodes restart.          This commit restricts the range of ports using the same algorithm as in     `ESTestCase`, avoiding[^1] such collisions.          [^1]: technically this isn't quite enough because the ephemeral range on     some CI workers overlaps the ranges chosen by `ESTestCase`, but that's a     separate issue tracked in #87734          Closes #87448||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove aliases list from IndexAbstraction (#87877)          We are not using this list outside of a couple of tests but setting it up     was a non-trivial contributor to the performance of building the indices lookup.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0]||||0||||0||||0
Simplify bootstrap error logging (#87809)          During startup of Elasticsearch we go to great lengths to present errors     in a meaningful way to users. Over time, though, the error handling has     been amended to address various issues, and that has resulted in a     complicated system of try/catches handling various cases. One     particularly kludgy piece is removing the console logger in special     cases to avoid printing exceptions to the console. Additionally, the     console removal wasn't actually effective because later in exception     handling the exception would be both logged anyways, and then also sent     to stderr, meaning that we could see the same exception several times.          This commit reworks how exceptions are logged during bootstrap. To     address the concern of printing full exceptions to the console, a new     log4j exception filter is added to the console appender which will only     print out the exception message and some additional explanatory info. To     address logging multiple times, the try/catch within init is removed so     that excpetions can propagate to the try/catch in main, which now     handles all exceptions. Additionally, phase 1 (before logging) handles     it's own failure cases since there is definitely no logging at that     time. This simplifies the other failure cases latere so that they do not     need to check if logging has been initialized through sysprops.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 7, 3, 11, 0, 0, 0, 0, 0, 2, 2, 0, 1, 2, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 12, 8, 0, 26, 6, 1]||||0||||0||||0
Make CBE message creation more robust (#87881)          Child circuit breakers rely on proper matching of acquire/release pairs.     This can be tricky to get right. If we get it wrong and accidentally     double-release a CB then it may end up with a negative `used` value.     This is definitely a bad situation in which to find ourselves, but today     in production it's made a whole lot worse because it causes exceptions     on every attempt to report a `CircuitBreakerStats` or to construct a     parent `CircuitBreakingException`.          This commit makes the message construction and stats serialization a     little more robust so that it's clearer what is going on in production.          Relates #86059||||[0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 14, 0, 0, 4, 0]||||0||||0||||0
Revert "Make CBE message creation more robust (#87687)"          This reverts commit 9ff9026871e27310c307020abb1c3fef0d4fc880.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 14, 18, 0, 0, 4, 0]||||0||||0||||0
Fix rest AzureSearchableSnapshotsIT (#87855)          This commit increases the rest client socket timeout to 90 seconds     so the client does not retry the tests requests when Azure is not     responding in a timely manner, this avoids confusing tests errors.          Closes #87389     Closes #86813||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make CBE message creation more robust (#87687)          Child circuit breakers rely on proper matching of acquire/release pairs.     This can be tricky to get right. If we get it wrong and accidentally     double-release a CB then it may end up with a negative `used` value.     This is definitely a bad situation in which to find ourselves, but today     in production it's made a whole lot worse because it causes exceptions     on every attempt to report a `CircuitBreakerStats` or to construct a     parent `CircuitBreakingException`.          This commit makes the message construction and stats serialization a     little more robust so that it's clearer what is going on in production.          Relates #86059.||||[0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 14, 0, 0, 4, 0]||||0||||0||||0
Checkstyle     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Upgrade Checkstyle to 10.3 (#87792)          Closes #83311.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Throw exception on illegal RepositoryData updates (#87654)          In some edge cases we could attempt a broken write here today,     lets throw in addition to the assertion to not corrupt the repository     until a solution for the underlying problem is found.          relates #86889||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Added additional index.look_ahead_time validation (#87847)          Added a requirement that index.look_ahead_time index setting     can't be lower than time_series.poll_interval setting.          Additional changes:     * Fixed a mistake in the docs that referenced indices.lifecycle.poll_interval     instead of time_series.poll_interval.     * Moved index.look_ahead_time setting to data stream module.||||[0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0]||||0||||0||||0
Remove submitUnbatchedStateUpdateTask(...) usage from UpdateTimeSeriesRangeService (#87597)          This service periodically updates the cluster state in background     (updating `index.time_series.end_time` setting of the latest backing     index of all data streams). It was using the unbatched forbidden method.     This PR changes the service to use the     `clusterService.submitStateUpdateTask(...)` variant that uses task     executor. Although it is unlikely that more than one concurrent update     is submitted from `UpdateTimeSeriesRangeService`, it is good to move     away from forbidden method usages. The executor is simple, in that it     just executes `updateTimeSeriesTemporalRange(...)` once if in the event     that multiple `UpdateTimeSeriesTask` are submitted.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add rollover permissions for remote_monitoring_agent (#87717)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]||||0||||0||||0
Improve ownership handling of bytesref and bytesrefarray (#87660)          When de-serializing a BytesRefArray and creating a BytesRefHash from it, the ownership wasn't properly defined. This PR improves ownership handling and passing ownership. Also fixes an unnecessary buffer cleaning on de-serialization.||||[0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 20, 0, 0, 6, 0]||||0||||0||||0
add BytesRefStreamOutput (#87661)          add StreamOutput that writes into BytesRef(Builder) that allows creating ByteRefs in situ, avoiding extra allocations.          relates #83055||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Adding a transport action to get cluster formation info (#87306)          This commit exposes ClusterFormationFailureHelper.ClusterFormationState in a transport action (ClusterFormationInfoAction), with the intention that it be used as part of the master stability health check.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Handle empty point values in DiskUsage API (#87826)          The DiskUsage API can hit NPE if the FieldInfos of points or doc-values     fields are still in segments; but the associated documents are gone.          Closes #87761||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fast build of allIndicesArray in Metadata.build (#87838)          No need to iterate this potentially enormous map twice to build the array,     just build it directly when iterating.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 0, 0]||||0||||0||||0
JvmService use SingleObjectCache (#87236)          In [[[STORE] Add simple cache for     StoreStats]](https://github.com/elastic/elasticsearch/commit/85c611a1b70627b2d1a6fbd254668b4ae64dff2b),     @s1monw  introduced a simple cache for `StoreStats`, `FsStats`,     `NetworkStats`, `OsStats`, `ProcessStats`, but not `JvmStats`. This PR     we introduce the `SingleObjectCache` into `JvmService`. I also remove     the useless `synchronized` in `OsService#stats()`.||||[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 5, 3, 0, 0, 0, 2]||||0||||0||||0
Verify bulk response in TsdbDataStreamRestIT (#87460)          Version conflicts were returned, this is ok, because same timestamp and     routing values were provided. However, the tests should verify whether     the bulk response contains no error, so that we can catch future bugs.          Adjusted the dummy data, so that we don't have documents that end up     generating the same time series id, which results in a bulk response     with no errors.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Rework testing conventions gradle plugin (#87213)          This PR reworks the testing conventions precommit plugin. This plugin now:     - is compatible with yaml, java rest tests and internalClusterTest (aka different sourceSets per test type)     - enforces test base class and simple naming conventions (as it did before)     - adds one check task per test sourceSet     - uses the worker api to improve task execution parallelism and encapsulation     - is gradle configuration cache compatible          This also ports the TestingConventions integration testing to Spock and removes the build-tools-internal/test kit folder that is not required anymore. We also add some common logic for testing java related gradle plugins.     We will apply further cleanup on other tests within our test suite in a dedicated follow up cleanup||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 4, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 18, 0, 9, 2, 0]||||0||||0||||0
Make Desired Nodes API operator-only (#87778)          * Remove Desired Nodes API from NON_OPERATOR_ACTIONS          * Add desired nodes to the operator privileges test          * Add desired nodes privileges integration tests          Resolves #87777.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[TRANSFORM] Add authorization info to transform config listings (#87570)          Transforms remember permissions from their time of creation     or most recent update. It can be quite hard to determine what     these are when listing transform configs, which can lead to     uncertainty about whether some minor update changed the     permissions.          This change adds information about the permissions to the     config listings.          If the last update was from a user then the permissions used     are the roles they had at the time, and a list of these roles     is added to the new `authorization` field of the transform config     listing.          If the last update was using an API key then the permissions     of that API key are used for subsequent transform operations,     and the new `authorization` field of the transform config listing     shows the API key name and ID.          If a service account did the last update then the service     account name is added to the new `authorization` field of the transform     config listing.||||[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]||||0||||0||||0
Automatically close idle connections in OIDC back-channel (#87773)          In some environment, the back-channel connection can be dropped     without sending a TCP RST to ES. When that happens, reusing the same     connection results into timeout error.          This PR adds a new http.connection_pool_ttl setting to control how long     a connection in the OIDC back-channel pool can be idle before it is     closed. This allows ES to more actively close idle connections to avoid     the timeout issue.          The new setting has a 3min default which means idle connections are     closed every 3 min if server response does not specify a shorter keep-alive.          Resolves: #75515     ||||[0, 0, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Fix optimization in BalancedShardsAllocator (#87843)          The optimization for a `null` does not apply today,     it should special case plain `YES`.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0]||||0||||0||||0
Revert "Deprecation dataset value changed to elasticsearch.deprecation (#83254)" (#87837)          This reverts commit bb06fac.     relates #83251||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0]||||0||||0||||0
Remove unused routing allocation from disk threshold decider. (#87745)          Remove unused routing allocation from disk threshold decider.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove default-value parameters from non-core queries (#87813)          This slims down the representations of all remaining queries not in the core          * percolate     * function_score     * script_score     * pinned          Relates to #76515||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 6, 0]||||0||||0||||0
Bound ack time (#87787)          Currently, our default wait time for ack is unbound. This could result     in an entire test suite timeout rather than individual test cases     failures.     ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]||||0||||0||||0
Do not wait for the health node task (#87830)          The health node task is a permanent task, for this reason it doesn't make sense to wait for it in a method that waits for pending tasks. This fixes that.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Small fixes to clear voting config excls API (#87828)          Fixes the name of the REST param in the error message, and expands the     API docs to emphasise that the exclusions should be empty in normal     operation.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Remove dead code from `TokenService` (#87739)          This PR removes code marked as unused or redundant in TokenService.     More involved code removal to come.          Relates #87729||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0]||||0||||0||||0
Make DiskThresholdDecider a little faster (#87821)          This is the most expensive allocator left in many-shards benchmarks.     It gets a little faster with this change iterating over the cheaper     array and inlining a little nicer by having specialized methods     for the two cached states.||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 3, 0, 0]||||0||||0||||0
Cleanup dead code in org.elasticsearch.common (#87820)          Just some obvious static cleanup of this package. Should be trivial     to review since it's deletes only and still compiles/tests fine.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 37, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Fix trained model metadata serialization (#87817)          This is a follow-up fix to #87806.||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 2, 0, 0, 1, 0]||||0||||0||||0
Remove redundant BlobMetadata interface (#87705)          No need to have more than a simple record here at this point.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0]||||0||||0||||0
Modularize the ingest-geoip component (#87746)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Rename trained model metadata after full cluster upgrade (#87806)          In #85503 we renamed trained model allocations to assignments.     However, it is important to wait for the full cluster to be     upgraded before we rewrite the cluster state so that there are     no undesired side-effects in a mixed cluster.||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 7, 0]||||0||||0||||0
Modularize ILM/SLM (#87769)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Re-enable several tests since JDK-8287097 has been fixed (#87803)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0]||||0||||0||||0
Remove unused wrapped rest handler (#87805)          This class isn't used anywhere.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use Map in snapshot/restore tracking (#87666)          Snapshot/restore keeps track of progress in ImmutableOpenMaps. This     commit changes these tracking structures to use HashMap.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Remove ImmutableOpenmap from disk threshold tests (#87658)          These tests pass ImmutableOpenMaps to ClusterInfo, but that now takes     Map. This commit uses HashMap in the tests instead.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 14, 10, 0, 51, 0]||||0||||0||||0
Remove HLRC impl of PinnedQueryBuilder (#87796)          We have an extra implementation of PinnedQueryBuilder that was added to     expose it to the high-level rest client. This is no longer needed, so we can     safely remove it.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Modularize the lang-mustache component (#87789)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Move logging config assertion to server cli (#87774)          The log4j configuration file is shipped with all ES distributions. We     also check recursively for files possibly added by plugins. If no files     are found, we give a helpful startup error message. However, since the     log4j2 configuration file shipped with ES should always exist, we can     check upfront in the cli before even initializing logging.          This commit moves the validation of an existing log4j2 properties file     to the server cli.||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0]||||0||||0||||0
Modularize the kibana, mapper-extras, parent-join, and systemd, components (#87794)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Modularize the lang-expression component (#87790)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove dead code in rest and http packages (#87786)          Removing some mroe unused and needlessly verbose things here,     this code is complicated enough as it is already.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 6, 0]||||0||||0||||0
Fix missing intermediate object error when applying dynamic template (#87622)          When we apply dynamic mappings, we iterate over all the dynamic mappers retrieved from the DocumentParserContext, which are registered while parsing the document, and for each field look up their parent (going back multiple levels if necessary), and add it to the dynamic mapping update with the added/modified sub-field.          Dynamic mappers that are iterated through consist of a flat set of mappers, which can be both object mappers or field mappers. Most times, the object mappers from such set have no sub-fields as they are mapped as a result of parsing a document where the object appears for the first time, which also has sub-fields that are going to be added to the set of dynamic mappers themselves once they are parsed.          There are scenarios though where a dynamic template matches an object, and defines its structure including its subobjects as well as sub-fields. In that case the dynamically mapped object may hold sub-fields as well as define non-default values for dynamic, enabled or subobjects. The described situation was not well covered in tests so far, and is currently affected by a bug introduced with #81449. When an object mapper is dynamically mapped, it is added to the map of dynamic object mappers, which makes it discoverable for sub-fields that will need to be added to it later, as well as to the set of dynamic mappers so that it becomes part of the mappings in case the document being parsed defines no sub-fields for it. What is missing is to recursively add its sub-fields to the dynamic object mappers. As a result of missing this step, intermediate objects that were dynamically mapped are not made discoverable which causes a cryptic "Missing intermediate object" error.          This commit fixed the problem by recursively registering inner sub-objects to the dynamic mappers whenever an object mapper is added to the dynamic mappers. It also changes the "missing intermediate object" error to make it more evident that it's an internal error and not a user error: it is now an IllegalStateException instead of an IllegalArgumentException.          Closes #87513||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Require that threads_per_allocation is a power of 2 (#87697)          As the number of cores in CPUs is typically a power of 2,     this commit adds a validation that trained model deployments     start with `threads_per_allocation` set to be a power of 2.     When we look for how we distribute the allocations across the     cluster, this prevents situations where we have a lot of wasted     CPU cores.          In addition, we add a max value limit of `32`.||||[0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]||||0||||0||||0
Fix CancellableRateLimitedFluxIteratorTests#testCancellation (#87641)          Ensure the test cancellation consumer provides enough visibility.          Closes #87112||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0]||||0||||0||||0
Remove key rotation code from `TokenService` (#87744)          The key rotation code in the TokenService was never used outside of     tests. I've made a conservative pass with this PR that removes key     rotation related code but maintains BWC.          I haven't touched things like the keyCache field and the code related     to the actual use of the encryption key. AFAICT that code is still     relevant from a BWC perspective, where upgrades from old versions are     concerned. Making BWC cuts is tracked separately (#87726).          Relates #87729||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Simplify RestResponse Implementations (#87504)          This sets up chunked encoding rest responses. Make it so we only have     a single REST response implementation (+the security filtering override)     throughout the codebase. The test implementations were all redundant,     removing them made the abstract base class redundant.     A follow-up to this will change the signature of the `content()` method     to an abstraction that allows for chunked encoding and simplify     the very complicated resource handling associated with REST responses in     `org.elasticsearch.http.DefaultRestChannel#sendResponse` based on the     simplification in here.||||[0, 0, 0, 0, 12, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 3, 0, 0, 14, 7, 0, 0, 148, 4]||||0||||0||||0
[Test] [IdP] Add test for multiple SSO roles (#87680)          Within the Identity Provider we support SSO roles (via application     privileges) being assigned directly to an SP (by entity id) or via a     wildcard.          It is possible that a user has a role via a wildcard (e.g. "viewer" on     "marvel:avengers:*") and a different role via a direct assignment (e.g.     "editor" on "marvel:avengers:thor"). In this case the SAML assertion     should contain both attributes ("viewer" and "editor").          This commit adds a test for this behaviour. No other code changes were     required because the functionality works as intended, it just didn't     have an integration test.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Tests for synthetic _source from translog (#87578)          This adds tests to make sure that we use all of the normal synthetic     source machinery, even when loading from the translog. So all GETs on     synthetic source indices will require an in memory index. That'll be an     extra cost on indices that are updated very very frequently.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add more debugging for readiness test timeout (#87652)          ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 0, 0, 2, 0]||||0||||0||||0
[ML] Add reason of stopping model deployment to logs (#87752)          The reason was not logged in INFO level. The reason is very     useful to debug issues.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Remove unused DeadlockAnalyzer (#87664)          Random find, this class and a couple of other spots in the package are unused.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add Lintian overrides to ignore Intel MKL not linked to libc (#87706)          We don't build these libraries ourselves and the license forbids     us from modifying them in any way, so we won't be able to make     this rule pass on them. All we can do is override it.          Fixes #87632||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]||||0||||0||||0
Modularize the ingest-user-agent component (#87747)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Modularize the legacy-geo component (#87740)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[Transforms] fix bug when unsetting retention policy (#87711)          It is currently not possible to unset the retention policy in a typical multi-node cluster.          This commit fixes that bug. If unsetting the retention policy failed, it would fail looking like the following error:          ```     An error occurred calling the API endpoint to update transforms.     Bad Request: [illegal_argument_exception: [illegal_argument_exception] Reason:     Unknown NamedWriteable [org.elasticsearch.xpack.core.transform.transforms.RetentionPolicyConfig][null_retention_policy]]:     Unknown NamedWriteable [org.elasticsearch.xpack.core.transform.transforms.RetentionPolicyConfig][null_retention_policy]     ```          closes: https://github.com/elastic/elasticsearch/issues/87688||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0]||||0||||0||||0
Do not leak recover from snapshot file permits when recover from snapshot is disabled (#87633)          Closes #86705||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0]||||0||||0||||0
Modularize the h3 component (#87737)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix possible NPE in startup exception handling (#87732)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0]||||0||||0||||0
Do not include desired nodes in snapshots (#87695)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]||||0||||0||||0
Log 'output of node' separators to stdout (#87736)          Today when using Gradle-managed test clusters we separate the log output     from each node with a separator that looks like this:          === Log output of node `node{:qa:mixed-cluster:v8.2.0-0}` ===          However, we write this to `stderr` and yet write the rest of the log     output to `stdout`. This commit moves the separators to the same log     level as the rest of this output so that they can all be redirected to     the same place.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make snapshot deletes not block the repository during data blob deletes (#86514)          Snapshot deletes need not block other operations beyond the updates to the repository metadata at the beginning of the delete operation. All subsequent blob deletes can safely run async and concurrent to other operations.          This is the simplest possible implementation of this change that I could find. It's not the most optimal since concurrent deletes are not guarded against trying to delete the same blobs twice. I believe this is not a big issue in practice though.     For one, we batch overlapping deletes into single operations, so we will only try to redundantly delete blobs leaked by previous operations that are part of indices still referenced (which will generally by a very limited number of blobs I believe) and indices that went out of scope. Indices that went out of scope are deleted by listing out blobs and deleting them in turn, which means that we likely won't be attempting all that many redundant deletes even if the same index would be touched by concurrent delete operations and even if we did, the additional memory use would be bounded.||||[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 7, 2, 0, 9, 0]||||0||||0||||0
Persistent health task (#86131)          This PR introduces a persistent task which will be used to select the health node.||||[0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 7, 0]||||0||||0||||0
Make GetIndexAction cancellable (#87681)          The get-indices API does some nontrivial work on the master and at high     index counts the response may be very large and could take a long time     to compute. Some clients will time out and retry if it takes too long.     Today this API is not properly cancellable which leads to a good deal of     wasted work in this situation, and the potentially-enormous response is     serialized on a transport worker thread.          With this commit we make the API cancellable and move the serialization     to a `MANAGEMENT` thread.          Relates #77466||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0]||||0||||0||||0
Keep track of desired nodes status in cluster state (#87474)          This commit adds desired nodes status tracking to the cluster state. Previously status was tracked     in-memory by DesiredNodesMembershipService this approach had certain limitations, and made     the consumer code more complex. This takes a simpler approach to keep the status updated when     the desired nodes are updated or when a new node joins, storing the status in the cluster state,     this allows to consume that information easily where it is necessary.     Additionally, this commit moves test code from depending directly of DesiredNodes which can be     seen as an internal data structure to rely more on UpdateDesiredNodesRequest.          Relates #84165||||[0, 0, 0, 0, 25, 5, 0, 2, 0, 1, 0, 2, 0, 0, 0, 2, 2, 0, 0, 0, 1, 1, 1, 1, 0, 0, 3, 0, 0, 0, 1, 0, 0, 0, 4, 0, 0, 0, 0, 4, 0, 0, 60, 47, 2, 1, 69, 0]||||0||||0||||0
Fix ConfigDatabasesTests#testDatabasesDynamicUpdateConfigDir() test (#87699)          ConfigDatabases#getDatabase(...) can return null and that is ok,     but an assertBusy() block in testDatabasesDynamicUpdateConfigDir() test     expects that the loader is always not null and that may not the case.     Adjusted this assertBusy() to check for null. Otherwise, a NPE may be     thrown and assertBusy() doesn't retry that, it only retries assertion     errors.          Closes #86805||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Fixup highlighting with synthetic source (#87667)          Synthetic source has a habit of reordering text fields. This frustrates     highlighting because it *often* wants to use index structures to find     the offsets to values in the field. This disables the FVH highlighter     for multi-valued text fields when synthetic source is enabled and runs     the unified highlighter in "analyze" mode when synthetic source is     enabled. That's *enough* to stop them from spitting out wrong answers.          We might be leaving some performance on the table when the unified     highlighter works on a single valued text field that is indexed with     offsets or term vectors. We don't really expect that to be common at all     though because *generally* folks will enable synthetic source to save     space and adding offsets or term vectors is quite space inefficient. If     it comes up, we might be able to improve here.     ||||[0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 1, 3, 0]||||0||||0||||0
Fix ReplicaShardAllocatorIT.testPreferCopyCanPerformNoopRecovery (#87638)          Prevent failure in the unlikely edge case of having the dummy index not     allocated on the empty data node because a slow shard store fetch     disabled the rebalance allocator. This failed because the subsequent     relocation would then make `ensureGreen` time out because as a result     of getting blocked just the same way the initial peer recovery tested     is blocked.          closes #87569||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
[ML] add sentence piece pre-compiled normalizer (#87575)          This is one of the many prerequisites for supporting sentence-piece tokenization within NLP.          Sentence piece is a fairly complicated and involved tokenization scheme.          This commit contains the normalization logic that transforms the provided string from its current utf8 bytes into a standard normalized set of utf8 bytes.          The typical storage for this normalizer is a compressed representation of a DARTS array and a null delimited normalization string.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Check earlier for nested type with disabled subobjects while parsing doc (#87644)          With #87218 we have expanded testing and made sure that we check that the nested type is not used within objects that have subobjects disabled.     This commit moves the check needed while applying dynamic mappings to an earlier point, where it is possible to distinguish between nested and object, so we can expose a different error in the two scenarios.          Also, this commit rewords the error message thrown so that it is more user-friendly.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Ingest: IngestDocument requires non-null version (#87665)          Changes the type of the version parameter in `IngestDocument` from     `Long` to `long` and moves it to the third argument, so all required     values occur before nullable arguments.          The `IngestService` expects a non-null version for a document and will     throw an `NullPointerException` if one is not provided.          Related: #87309||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 53, 0]||||0||||0||||0
[TSDB] Add Kahan support to downsampling summation (#87554)          This PR adds support for Kahan summation when downsampling time series indices          Relates to #74660||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Skip ML BWC tests against versions before 7.17.5 and 8.2.2 on RHEL 9 (#87678)          RHEL 9 suffers the same problems as Ubuntu 22.04 that were fixed by     https://github.com/elastic/ml-cpp/pull/2272.          The glibc version on RHEL 9 is 2.34 (versus 2.35 on Ubuntu 22.04),     so we need to adjust the skip logic.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use Map in ClusterBlocks (#87659)          ClusterBlocks keeps track of cluster wide blocks per index. This map is     not updated often, and so ImmutableOpenMap is not critical. This commit     converts it to using immutable jdk Maps.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0]||||0||||0||||0
Bump version for 8.2.3 release     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add ParameterizedMessage to forbidden api (#87631)          ParameterizedMessage will not be part of the new ES logging API and therefore should not be used.     java.util.Supplier and String.format should be used instead.          this commit adds ParameterizedMessage to forbidden api          relates #86549||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
EQL: avoid attempting PIT close on PIT open failure (#87498)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0]||||0||||0||||0
Use Map in SnapshotShardSizeInfo (#87579)          SnapshotShardSizeInfo keeps a mapping of shard to size of the shard.     This commit converts that from an ImmutableOpenMap to Map. Note that     this does not yet change the implementation to HashMap (except in     tests). ImmutableOpenMap is still used in InternalSnapshotInfoService     for now.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 10, 0]||||0||||0||||0
Report overall mapping size in cluster stats (#87556)          Adds measures of the total size of all mappings and the total number of     fields in the cluster (both before and after deduplication).          Relates #86639     Relates #77466||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Handle empty result in testRandomLimitConcurrentRequests (#87619)          Closes #87595||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove obsolete test for realm domain setting registration (#87630)          As part of feature flagging user profiles (#83347), we introduced     branching based on build type for setting     DOMAIN_TO_REALM_ASSOC_SETTING to enable easy downstream testing.     We've since removed the feature flag and the branching logic. The     outdated test fails for non-snapshot builds because the setting is now     always included. This PR removes the test since     DOMAIN_TO_REALM_ASSOC_SETTING is now a regular xpack setting like any     other.          Closes #87628     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove total and active shard count from RoutingNodes (#87617)          These are not used any longer.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 2, 0]||||0||||0||||0
Deprecation dataset value changed to elasticsearch.deprecation (#83254)          The dataset value for all ES logs are prefixed with elasticsearch + log     type. Like elasticsearch.server. Deprecation log had it reverted     deprecation.elasticsearch     This commit renames the dataset for deprecation logs to     `elasticsearch.deprecation.          closes #83251||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0]||||0||||0||||0
Remove filter-by-filter specialization for match_all and match_none. (#87550)          With better rewriting of `bool` queries and the introduction of `Weight#count`,     we no longer need to specialize filter-by-filter for `match_all` and     `match_none` queries and can instead rely on their implementations of     `Weight#count` to return maxDoc / 0.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 6, 4, 0, 0, 12, 1]||||0||||0||||0
Give doc-value-only mappings to numeric fields on metrics templates. (#87100)          It doesn't make much sense to filter samples depending on the values of some     metric fields, as these metrics mostly make sense in aggregate and over time.     This change proposes to give doc-value-only mappings to numeric fields in the     default metrics template. This helps reduce index-time CPU usage and disk usage     while not impacting the search-time experience.          These doc-value-only dynamic templates might catch fields that are not metrics     at times, which is probably ok.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add logging for ID Token header on BadJoseException (#87347)          When ID token validation fails with BadJoseException, the JWT Header     section can provide useful information for troubleshooting without     having to ask for the full ID token. This PR adds a debug message to     show the header.          Note the header may not be sufficient for debugging all failure     scenarios. But it should be helpful for more common configuration     errors.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0]||||0||||0||||0
Refactor various ParameterizedMessage usages into String.format (#87603)          ParameterizedMessage is part of log4j api and should not be used     in places where a lambda and String.format would be enough.          This commit is the last batch of refactoring to get rid of ParameterizedMessage     in ES codebase and consists of various, not related usages.          relates #86549||||[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 8, 9, 0, 0, 35, 0]||||0||||0||||0
Changing the URL for increasing tier capacity documentation (#87560)          This commit changes the URL of the documentation for increasing node capacity in a tier in the     shards availability indicator in the heath API from http://ela.st/node-capacity to     http://ela.st/tier-capacity.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Simplify boostrap shutdown (#87581)          The shutdown hook registered in bootstrap is run when the JVM is     shutting down. An almost identical method, stop(), exists for a special     Windows case that can skip shutdown hooks. This commit consolidates the     two into a new shutdown() method used for both. Additionally, the flag     for determining whether the shutdown hook should be added in bootstrap     setup was always true, so it is removed.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 0]||||0||||0||||0
Clamp auto-expand replicas to the closest value (#87505)          Ensure that the number of replicas chosen for an auto-expand-able shard     is within the range of the available data nodes, i.e., excluding those     nodes that cannot be assigned a replica.          Closes #84788||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 3, 0]||||0||||0||||0
Mute testGeoPointGeoHex #87391 (#87606)          related #87391||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] fixes inference timeout handling bug that throws unexpected NullPointerException (#87533)          The timeout thread was being scheduled to be executed before all the requisite fields were populated.          This would (usually only in extreme circumstances), would throw a null pointer exception that looked like:          ```     2022-06-06T23:40:42,534][ERROR][o.e.b.ElasticsearchUncaughtExceptionHandler] [javaRestTest-2] uncaught exception in thread [elasticsearch[javaRestTest-2][ml_utility][T#4]]     java.lang.NullPointerException: Cannot invoke "org.elasticsearch.xpack.ml.inference.deployment.DeploymentManager$ProcessContext.getTimeoutCount()" because "this.processContext" is null     at org.elasticsearch.xpack.ml.inference.deployment.AbstractPyTorchAction.onTimeout(AbstractPyTorchAction.java:58) ~[?:?]     at org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:709) ~[elasticsearch-8.4.0-SNAPSHOT.jar:?]     at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]     at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]     at java.lang.Thread.run(Thread.java:833) [?:?]     ```          This PR fixes this bug and an additional (more minor) bug where inference call rejections were not accurately counted.          closes: https://github.com/elastic/elasticsearch/issues/87457||||[1, 0, 0, 0, 4, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 33, 0, 2, 1, 0]||||0||||0||||0
Use cheaper map for RoutingNode.shardsByIndex (#87599)          No need for preserving order on this map, it's only used for counting     shards of a specific index per node.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0, 1, 7, 0]||||0||||0||||0
Speed up iteration over ImmutableOpenMap on hot paths (#87600)          The adjusted spots can see very large maps of O(index_count) getting iterated.     Moving them to the efficient `forEach` that iterates the action in a tight loop     over an array instead of using the indirection of the iterator loop gives     a measurable speedup in many-shards benchmark bootstrapping.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0]||||0||||0||||0
Suppress WindowsFS in ReloadingDatabasesWhilePerformingGeoLookupsIT (#87517)          WindowsFS fails if a files that is open/in use while being deleted.     However, when there is a new database in geoip index then DatabaseNodeService     will download that and replaces the database file in use by using a file move.     Only windows has issues with this and WindowsFS emulates this behaviour.          I think for now it is best to suppress windows fs in this test.          Closes #87453||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix configuration cache compatibility issues in gradle plugins (#87567)          This fixes references to project that makes the plugin incompatible with Gradle     configuration cache. We also remove custom xpackProject utility:          using xpackProject in certain situations can break configure configuration cache compatibility as it uses a mutual project object under the hood that is discouraged to use in some use cases (e.g. at execution time)          It always breaks compatibility with --configure-on-demand          using xpackProject uses the project of the :x-pack project. referencing other project objects from other subproject should avoided where possible to decouple (sub project configurations). There's a good explanation of why we want to decouple our project configurations as much as possible here: https://docs.gradle.org/current/userguide/multi_project_configuration_and_execution.html#sec:decoupled_projects          it adds little value over default out of the box gradle api (just use project(':x-pack:someProject') instead of xpackProject('someProject') Also in some occasions its even shorter. e.g. when this is used as xpackProject('someProject').path instead of just passing :x-pack:someProject          I'll try to put a bit more context in the PR description in the future to make the motivation behind these kind of changes more clear upfront          Related to #57918||||[0, 0, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 9, 1, 0, 14, 0]||||0||||0||||0
Test fix: Ensure a node role will not be used as an attr (#87588)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Stable logging API - the basic use case (#86612)          Introducing a stable logging API under libs/logging.     This change covers the most common use cases for logging: fetching a logger with LogManager, emitting a log messages with Logger and Level.     It is influenced by log4j2-api, but do not include Marker and LogBuilder methods.     Also methods using org.apache.logging.log4j.util.Supplier are replaced with java.util.Supplier          The basic implementation is present in server and injected statically in LogConfigurator          relates #84478||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Refactor ParametrizedMessage.getFormattedMessage into Strings.format (#87324)          ParametrizedMessage is part of log4j api and should not be used     in places where a simple String.format would be enough.     Many of usages like this are message formatting for exceptions being     thrown.          relates #86549||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0]||||0||||0||||0
`403` on unauthorized grant API key action (#87461)          Users with only the manage_own_api_key privilege are unauthorized to     grant API keys. The current error response in this scenario is a 400,     with a confusing error message. This PR changes error handling to     return a 403 with a canonical "action ... is unauthorized for user     ..." error message instead, since the underlying cause is an     authorization error rather than a bad request.          Closes #87438||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Avoid making the index read-only in the Force merge action for ILM (Closes #43426) (#81162)          Added a new NoopStep that we can use as a placeholder for a step that we had in a previous version but now we want to remove it. If the just go and erase the step then the indices that were in that step will get into a stuck state. Instead, we're using the same old step key but with this NoopStep which does nothing but the transition to the next step.          Modify the ForceMergeLifecycleAction in ILM so it doesn't make the index read-only. For older indices already in the "convert index to read-only" step before the upgrade, we'll use the NoopStep mentioned before in order to ignore the step and just transition to the next one.          Solves: #43426          Co-authored-by: Lee Hinman <dakrone@users.noreply.github.com>||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 10, 1, 0, 0, 12, 0]||||0||||0||||0
Remove impossible exception from security configuration (#87542)          Bootstraping security declares a checked NoSuchAlgorithmException.     However this seems to be a historical implementation detail that is no     longer present, as none of the methods called from Security.configure     declare this as a thrown exception. This commit removes the exception     from the method's declaration.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Add more GraalThread filtering in tests (#87571)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add error message when searchable snapshot cache wasn't cleared (#87503)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Script: Load Whitelists as Resource (#87539)          Changes PainlessPlugin.class.getResourceAsStream to     PainlessPlugin.class.getResource to avoid leaking unclosed     input streams||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fixing bug in StableMasterDisruptionIT.testRepeatedNullMasterRecognizedAsGreenIfMasterDoesNotKnowItIsUnstable() (#87519)          The test could wait up to 30 seconds for a master to step down. In that case, the start of the "null" master     could be 30 seconds ago, which put it outside of the range of the default acceptable time for there to     have been a master for the stability check. So the stability check returned RED since there was no master     in the last 30 seconds. This changes that setting to 60 seconds so that it is always picked up.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
[ML] Fix WordPiece tokenization of unknown words with known subwords (#87510)          Unknown words containing known subwords are still unknown||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0]||||0||||0||||0
Add force_synthetic_source to GET (#87536)          This adds the option to force synthetic source to the GET API. See     #87068 for more discussion on why you'd want to do that - the short     version is to get an upper bound on the performance cost of using     synthetic source in GET.     ||||[0, 0, 0, 0, 2, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 20, 0, 0, 6, 0]||||0||||0||||0
Simplify + speedup Metadata build some more (#87557)          No need to iterate the indices map another time just to add up     the shard counts.     Also, removes the redundant use of the indices keyset together with     the indices map as well as a redundant loop over the aliases in the     name collision check.||||[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 1, 6, 3, 4, 0]||||0||||0||||0
Fail shard if STARTED after master failover (#87451)          If `cluster.no_master_block: all` then we remove all shards locally     whenever there's no master, but there might still be a shard-started     message in flight. When the new master is elected we start to recover     our shards again and the stale shard-started message could arrive and     move this shard to `STARTED` in the cluster state too soon. This is     pretty rare so we fix it by just failing the shard and starting the     recovery again.          Closes #87367||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove ImmutableOpenMap from autoscaling (#87535)          Autoscaling uses ImmutableOpenMap to keep track of the memory used on     each node. A Map should work just fine here. Note that the wrapper     Collections.unmodifiableMap is used because of the way modifications are     made to the map. Map.copyOf could be used, but it's unclear if the extra     indirection is worse than the extra copying since this should not be     changing or being accessed in any hot loops.          relates #86239     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 6, 4, 0, 0, 4, 0]||||0||||0||||0
Remove impossible checked exception from jarhell (#87541)          The jarhell check declares a URISyntaxException. However, this should     not be possible as the paths and URLs come from the jdk conversion. This     commit makes a URISyntaxException when converting form URL to URI an     assertion error, similar to MalformedURLException when creating a URL.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
[Transform] Implement per-transform num_failure_retries setting. (#87361)          ||||[0, 0, 0, 0, 8, 5, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 32, 0, 0, 24, 0]||||0||||0||||0
Speed up ClusterStateHealth constructor (#87552)          This does not need to build the routing nodes, nor do we need to iterate all indices     twice.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 7, 2, 0]||||0||||0||||0
Add assertion that all field mapper names are interned (#87238)          Follow up to #86301. Assert that all field names are interned so we don't     lose this optimization and fix `FieldAliasMapper.name` for it not to trip.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0]||||0||||0||||0
Revert "Add support for VERSION field type in SQL and EQL (#85502)"          This reverts commit 79b0078b0dfaeba83a68ccc8c9e39701b2f231e3.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 3, 0, 0, 0, 0, 0, 0, 20, 1, 5, 0, 5, 0]||||0||||0||||0
Add support for VERSION field type in SQL and EQL (#85502)          ||||[0, 0, 0, 0, 17, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 20, 5, 0, 5, 0]||||0||||0||||0
Move test-only code from RoutingNode to tests module (#87537)          With recent refactoring we only instantiate these with an empty map in production     and mutate afterwards. We can do the same in tests and save the test only code     in server.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 8, 0, 0, 42, 0]||||0||||0||||0
[ML] Fix parsing of pytorch thread settings (#87525)          During #86277 an error was introduced in parsing of pytorch     thread settings. This commit fixes the issue.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove cluster block preflight check from health api (#87520)          Removes the logic at the start of the health service that returns UNKNOWN status in case     the cluster state not recovered block is in place. Instead, we will defer directly to the     master-is-stable indicator and all following preflight indicators.||||[0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 10, 1, 0, 0, 8, 0]||||0||||0||||0
Consolidate early startup into phase1 (#87509)          This commit introduces a new method in startup of Elasticsearch that     consolidates all the steps up to and including initialization of     logging. Some ordering is changed as some steps were not actually     necessary to run before logging, for example loading secure settings     since they are not actually used by logging.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 12, 0, 6, 2, 2, 0]||||0||||0||||0
Report file checksum when encountering artifact transform failures (#87522)          ||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 6, 0, 0, 1, 0]||||0||||0||||0
Upgrade folders after settings validation (#87319)          When upgrading from 7.x to 8.x, we remove the `nodes/0` subfolders from the     data path. This is an irreversible change and once done, downgrade is not     possible. Now do settings validation prior to moving folders to ensure that     a bad setting does not prevent a downgrade.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0]||||0||||0||||0
Mute CancellableRateLimitedFluxIteratorTests testCancellation (#87524)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Speed counting filters/range/date_histogram aggs (#81322)          Lucene has a `Weight#count` method which will return a count of matching     documents if it can do so in constant time. We have similar code in the     `filters` aggregator and it seems silly to maintain two copies of the     same thing. Better yet, Lucene knows how to take the constant time count     path in a few cases that aggs don't and we get to pick those up. Namely,     we can now get a constant time count for `match_all` even when there are     deleted documents or document level security. We can also go the     constant time count path on cached queries now which is a lovel speed     bump.          Co-authored-by: Adrien Grand <jpountz@gmail.com> (seriously, he really rescued this thing)||||[0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 33, 0]||||0||||0||||0
Fix test conventions when skipping ML upgrade tests (#87516)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add tier information on health api migrate tiers user actions (#87486)          The shards availability indicator can produce user actions that suggest migrating to data tiers     for a set of indices. This change updates the text returned from those user actions to include     the data tier that is affected.          Co-authored-by: Andrei Dan <andrei.dan@elastic.co>||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Speedup RoutingNodes constructor (#87514)          The RoutingNode instances are mutable. This PR leverages     that fact by building them directly instead of first collecting     a shards map and then building from that which saves quite     a few cycles since no per-data-node map has to be iterated.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 7, 2, 0, 3, 0]||||0||||0||||0
Add back Netty4WriteThrottlingHandler to HTTP pipeline (#87407)          Follow-up to #86922 bringing back the write throttling handler (with necessary adjustments)     as removing has measurably reduced scroll performance in nightly Rally runs.     Throttling at a lower level instead of only at the 1M HTTP chunk level provides a measurable     benefit to latency as it turns out in benchmarks so lets bring it back.     This requires adjusting the write throttling handler to pass through writes that could be flushed     directly so that the upstream throttling sees the correct channel writability status.     Before this change the channel would always look writable because we wouldn't be buffering     anything in the actual outbound buffer but just in the internal queue in the write throttling     handler.     Also, this PR adds coverage for the new code paths in the write throttling handler which together     with the existing coverage should give us safe coverage of all possible throttling and message     size combinations.          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
User Profile - remove feature flag (#87383)          The feature flag is no longer necessary in the 8.4 release cycle. The     feature itself is still in beta.||||[0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 11, 2, 0, 4, 0, 0]||||0||||0||||0
Fixing an occasional testYellowWithTooManyMasterChanges failure (#87483)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Don't run include_in_parent when in copy_to context (#87123)          We changed how copy_to is implemented in #79922, which moved     the handling of dots in field names into a specialised parser. Unfortunately,     while doing this we added a bug whereby every time a copy_to directive     is processed for a nested field, the nested field's include_in_parent logic     would be run, meaning that the parent would end up with multiple copies     of the nested child's fields.          This commit fixes this by only running include_in_parent when the parser     is not in a copy_to context. It also fixes another bug that meant the parent     document would contain multiple copies of the ID field.          Fixes #87036||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Move the writeTo and read for get requests (#87467)          This moves the writeTo methods next to the read requests for GET, MGET,     and `_search` so they are easier to read.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make bootstrap stacktrace printing less cumbersome (#87478)          The special StartupException is a class that exists to allow truncating     long stacktraces from the terminal output on startup. This is     particularly important for guice errors, which can be enormous.     Currently BootstrapExceptions are wrapped with StartupException to     handle possibly truncating them when printing. However, since main no     longer throws Exception, all handling of stacktrace printing is within     exitWithUnknownException. This commit makes the truncated stacktrace     printing a utility method instead of a full blown RuntimeException     wrapper.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 2, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 2, 33, 0, 0, 4, 0]||||0||||0||||0
[Test] Increase LDAP connection timeout (#87208)          Increased LDAP connection timeout to 10s to avoid test failures.          By default, LDAP and Active Directory's timeout was set to 5s.     This seems not to be enough when running integration tests on CI servers     that use Samba fixture.          Closes #86958||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Fix a bug with flattened fields in terms aggregations (#87392)          The root cause here was that missing did not correctly delegate `supportsGlobalOrdinalsMappnig` to the wrapped values source, instead falling back to the default.  I've added the delegation, and made the base method abstract so this doesn't happen again.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]||||0||||0||||0
Lower overhead of RestApiVersion use in x-content parsing (#87356)          Noticed loads of duplicate lambdas on the heap and code related to these predicates     etc. pop up during benchmarking things that are hot on x-content parsing.     These changes way simplify the rest-api code (though it could be made even simpler I think)     and remove it from profiling for the most part.          Co-authored-by: Joe Gallo <joe.gallo@elastic.co>     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
SQL: Fix date range checks (#87151)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make the metric in the buckets_path parameter optional (#87220)          With this change the metric field name becomes optional if the     'bukets_path' is pointing to a multi-value aggregation with a single     metric field. Normally the full path would be required including     the aggregation name followed by the metric field.          If the metric is not specified in the path and the multi-value     aggregation computes more than one value an error is thrown.          The old notation is still supported for backward compatibility in case     the full path is specified and the target multi-value aggregation     computes a single value.||||[0, 0, 0, 0, 3, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 12, 2, 2, 0, 0]||||0||||0||||0
Fork to WRITE thread before failing shard in updateCheckPoints (#87458)          Failing a shard may block on IO so must not happen on a transport worker     thread. With this commit we use a `WRITE` thread to handle shard     failures caused by exceptions thrown within `updateCheckPoints`.          Closes #87094||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 9, 0, 0, 3, 0]||||0||||0||||0
Add debug information to ReactiveReason about assigned and unassigned shards (#86132)          We would like to see not only the amount of assigned and unassigned shards, but also the ids of the respective shards.          Fixes #85243          * Calculate assigned shards based on storagePreventsRemainOrMove and storagePreventsAllocation0     * Correctly set assignedShardIds     * Add a TODO     * Add tests for assigned and non-assigned shard ids for ReactiveStorageDeciderService     * Remove changes in ProactiveStorageDeciderService     * Update docs/changelog/86132.yaml     * Return empty list for unassigned shards if can't make a decision     * Keep a terse constructor for ReactiveReason     * Move assignedBytesUnmovableShards initialization to the original point     * Add tests for JSON representation of ReactiveReason     * Add a missed LICENSE header     * shards ids are empty if the context is null     * use shardIds helper     * Use ShardId in records     * Use record to represent amount of bytes and shard ids     * Sort shards by their ids     * Limit the amount of assigned shards in the output     * Test that we limit the amount of assigned shards in the output     * Move to SortedSet     * Add tests that shard ids are sorted     * Remove internal package protected methods of allocation info     * Verify shard ids     * Correctly calculate the amount of unmovableShards     * Move assignedBytes     * Extract the max amount of assigned shard ids to a constant     * Extract the shard ids output version to a constant     * Rename BytesShardIds to ShardsSize     * Extract ShardsSize to a top level class     * Keep shards its closer to the total size     * Add missed license import     * Update docs/changelog/86132.yaml     * Fix the test for assigned shard JSON field names     * Limit the amount of unassigned shards     * Rename the limit to MAX_AMOUNT_OF_SHARDS     * Use toList instead of Collections.toList     * Bring back public accessors     * Precollect unallocated shards to avoid double calculation     * Update version to V_8_4_0     * Randomize index name     * Coalesce numAllocatableSubjectShards and allocatableShards     * Randomize indexName     * Add comment about duplicated shard ids||||[0, 0, 0, 0, 6, 4, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 8, 37, 1, 0, 31, 0]||||0||||0||||0
Fix serialization checks in force_synthetic_source (#87481)          This fixes a missing check for unsupported version logic that'd cause     `force_synthetic_source` to be silently dropped when sent to nodes     before 8.4. It also fixes an incorrect version number in an error     message.          Relates to #87068||||[0, 0, 0, 0, 3, 0, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 6, 0, 0, 1, 0]||||0||||0||||0
Use Map in SegmentStats (#87307)          SegmentStats has an ImmutableOpenMap tracking the files that exist     within an index segment. This commit converts the member to a Map. It     also slightly tweaks the contract of the class so that the map is no     longer immutable. The reason for this is that the class as a whole is     used as an accumulator when building stats for a segment. While doing     so, the other members of SegmentStats are modified. Yet with keeping     track of files, the map is needlessly rebuilt. Instead this commit     returns an immutable view for consumers, but keeps the map internally as     mutable for adding more stats. Note that the class is already not thread     safe, so immutability is not needed here for that purpose.          relates #86239     ||||[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 18, 5, 0, 0, 0, 0]||||0||||0||||0
Use Map in DiscoveryNodes (#87427)          DiscoveryNodes uses ImmutableOpenMap to internally keep track of various     sets of nodes with particular attributes, like master nodes and data     nodes. This commit converts these containers to Map.          relates #86239||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 4, 1, 1, 4, 0]||||0||||0||||0
Skip ML tests on later glibc for incompatible BWC versions (#87476)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 0]||||0||||0||||0
Move spatial3d dependency to spatial (#87397)          Server depends on spatial3d, but it is only ever used by the spatial     xpack component. This commit moves the dependency there.          closes #87026||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use Map in IndexTemplateMetadata (#87473)          This commit converts IndexTemplateMetadata to use Maps instead of     ImmutableOpenMap internally.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 3, 0]||||0||||0||||0
Use all lucene index compatible versions for bwc version generation (#87133)          The updateCIBwcVersions task regenerates the list of versions that are     tested in CI. This task internally calls a filter method which filters     out incompatible versions for the local system. That means it can change     depending on the type of system the task is run on. This commit adds a     new variant of the internal method to return all actual index compatible     versions, and renames the existing method to make it clear it is for     running actual tests on the local system.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add an option to _search to force synthetic source (#87068)          This adds `?force_synthetic_source` to, well, force running the fetch     phase with synthetic source. If the mapping is incompatible with     synthetic source it'll throw a 400 error.     ||||[0, 0, 0, 0, 8, 2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 18, 0, 0, 11, 0]||||0||||0||||0
Use Map instead of ImmutableOpenMap in ClusterInfo (#87393)          The internals of ClusterInfo are several maps. Currently these are     ImmutableOpenMaps. This commit converts them to Map.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 3, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 64, 13, 19, 0, 124, 0]||||0||||0||||0
Pre-parse tsdb index settings (#87278)          The index.mode, index.time_series.start_time and     index.time_series.end_time index settings are parsed in order to     determine what write index should be selected when indexing into a tsdb     data stream.          Parsing a setting has a certain overhead, which normally isn't     noticeable. However, these settings are parsed every time we need to     determine the write index for a document and then parsing these settings     has a noticeable overhead (takes around 10% in captured flame graphs).          This change pre-parses the mentioned settings and records the respected     parsed values with the IndexMetadata instance.          Relates to #74660||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 3, 0]||||0||||0||||0
Synthetic source: don't allow disabling source (#87270)          This rejects mappings that disable the `_source` but also configure it     to be `synthetic` because that sort of configuration doesn't make sense     - `synthetic` is a way to enable source at a low cost.     ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]||||0||||0||||0
Synthetic source: paranoid test for hidden copy_to (#87432)          This adds a paranoid test to make sure that you can't hide `copy_to`     under a multi field. We don't want to support `copy_to` for synthetic     source at this point because we can't figure out which values are being     copied vs the values that come in the original source.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Handle ordering in plain highlighter for multiple inputs (#87414)          The ordering logic in the plain highlighter only worked for single-valued     inputs. If you had multiple inputs, then order-by-score would only do this     ordering for fragments within each input, and order-by-position would     interleave fragments from the different inputs. This commit fixes both     issues.          Fixes #87210||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Add mapping stats for indexed dense_vectors (#86859)          Add cluster mapping stats for indexed dense_vectors          Currently _cluster/stats mapping section displays all mapping types     along with their count. In 8.0 we introduced indexed dense_vector     types, and we would like to collect more enhanced stats on them:     - number of indexed dense_vector fields     - sum of dims across all indexed dense_vector fields          This allows to differentiate how indexed dense_vector types are     used as opposed to unindexed dense_vector types.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Allow pipeline processor to ignore missing pipelines (#87354)          Add `ignore_missing_pipeline` option to `pipeline` processor. This     controls whether the `pipeline` processor should fail with an error if     no pipeline with a name specified in the `name` option exists.          This enhancement is useful to setup a pipeline infrastructure that     lazily adds extension points for overwrites. So that for specific     cluster setups custom pre-processing can be added at a later point in     time.          Relates to #87323||||[0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 2, 0]||||0||||0||||0
Only perform ensureNoSelfReferences check during ingest when needed (#87352)          The 'ensure no self reference' check during ingest only needs to be     performed when there is a chance that a map or list is added to     `IngestDocument` that references other entries in the `IngestDocument`     and when there is a risk that a circular reference is created between     entries.          Today this is only possible in `ScriptProcessor`, since a custom script     could do this. So doing this check if no script processor is used is a     not useful. Doing this check just adds an additional tax to time spent     on ingest, that in many cases really isn't necessary.          A flag is added to `IngestDocument` that controls whether the 'ensure no     self reference' check is performed at the end when all pipelines have     been executed. The `ScriptProcessor` has been modified to set this flag     and so this check will be performed if pipelines that execute have one     or more script processors.          Closes #87335||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Expose segment details in PCSS debug log (#87412)          Elasticsearch 8.x won't start if the cluster state on disk contains 6.x     indices. We've seen a couple of cases where users shut down one or more     nodes, then delete their older indices, and then report that they cannot     upgrade the shut down nodes since those nodes (obviously) didn't hear     that the old indices were deleted. This is a pain to diagnose today.          With this commit we expose the details of the segments making up the     cluster state index in the `DEBUG` logs so we can see their timestamps     and other metadata which is needed to diagnose this kind of situation.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Warn when stored credential hashers not compliant with FIPS (#87363)          Warn in FIPS mode, if hashers for API keys or service tokens are not     compliant with FIPS. Going for a warning log instead of validation     error for bwc.||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 9, 0]||||0||||0||||0
Optimize geogrid aggregations for singleton points (#87439)          Use a different code path when we detect that the points on a segment     are all single valued which allow us to optimise the tight loop used     while iterating the doc values.          Checks on rally shows a modest, still nice performance improvement:          ```          |                                                        Metric |        Task |       Baseline |      Contender |        Diff |   Unit |   Diff % |     |--------------------------------------------------------------:|------------:|---------------:|---------------:|------------:|-------:|---------:|     |                                                Min Throughput | geotilegrid |    0.573237    |    0.600875    |     0.02764 |  ops/s |   +4.82% |     |                                               Mean Throughput | geotilegrid |    0.607767    |    0.630151    |     0.02238 |  ops/s |   +3.68% |     |                                             Median Throughput | geotilegrid |    0.612317    |    0.633243    |     0.02093 |  ops/s |   +3.42% |     |                                                Max Throughput | geotilegrid |    0.623922    |    0.645545    |     0.02162 |  ops/s |   +3.47% |     |                                       50th percentile latency | geotilegrid | 1539.4         | 1492.69        |   -46.7073  |     ms |   -3.03% |     |                                       90th percentile latency | geotilegrid | 1570.21        | 1514.08        |   -56.1252  |     ms |   -3.57% |     |                                      100th percentile latency | geotilegrid | 1573.78        | 1515.79        |   -57.9968  |     ms |   -3.69% |     |                                  50th percentile service time | geotilegrid | 1539.4         | 1492.69        |   -46.7073  |     ms |   -3.03% |     |                                  90th percentile service time | geotilegrid | 1570.21        | 1514.08        |   -56.1252  |     ms |   -3.57% |     |                                 100th percentile service time | geotilegrid | 1573.78        | 1515.79        |   -57.9968  |     ms |   -3.69% |     |                                                    error rate | geotilegrid |    0           |    0           |     0       |      % |    0.00% |     |                                                Min Throughput | geohashgrid |    2.5986      |    2.99851     |     0.39992 |  ops/s |  +15.39% |     |                                               Mean Throughput | geohashgrid |    2.64153     |    3.02417     |     0.38264 |  ops/s |  +14.49% |     |                                             Median Throughput | geohashgrid |    2.65188     |    3.02704     |     0.37516 |  ops/s |  +14.15% |     |                                                Max Throughput | geohashgrid |    2.66263     |    3.03953     |     0.3769  |  ops/s |  +14.16% |     |                                       50th percentile latency | geohashgrid |  371.621       |  328.431       |   -43.19    |     ms |  -11.62% |     |                                       90th percentile latency | geohashgrid |  373.7         |  331.22        |   -42.4795  |     ms |  -11.37% |     |                                      100th percentile latency | geohashgrid |  374.082       |  332.37        |   -41.712   |     ms |  -11.15% |     |                                  50th percentile service time | geohashgrid |  371.621       |  328.431       |   -43.19    |     ms |  -11.62% |     |                                  90th percentile service time | geohashgrid |  373.7         |  331.22        |   -42.4795  |     ms |  -11.37% |     |                                 100th percentile service time | geohashgrid |  374.082       |  332.37        |   -41.712   |     ms |  -11.15% |     |                                                    error rate | geohashgrid |    0           |    0           |     0       |      % |    0.00% |     |                                                Min Throughput |  geohexgrid |    0.125189    |    0.132832    |     0.00764 |  ops/s |   +6.11% |     |                                               Mean Throughput |  geohexgrid |    0.127163    |    0.133508    |     0.00634 |  ops/s |   +4.99% |     |                                             Median Throughput |  geohexgrid |    0.126976    |    0.133546    |     0.00657 |  ops/s |   +5.17% |     |                                                Max Throughput |  geohexgrid |    0.131959    |    0.134025    |     0.00207 |  ops/s |   +1.57% |     |                                       50th percentile latency |  geohexgrid | 7802.83        | 7426.77        |  -376.056   |     ms |   -4.82% |     |                                       90th percentile latency |  geohexgrid | 8501.63        | 7552.32        |  -949.308   |     ms |  -11.17% |     |                                      100th percentile latency |  geohexgrid | 9058.2         | 7726.13        | -1332.07    |     ms |  -14.71% |     |                                  50th percentile service time |  geohexgrid | 7802.83        | 7426.77        |  -376.056   |     ms |   -4.82% |     |                                  90th percentile service time |  geohexgrid | 8501.63        | 7552.32        |  -949.308   |     ms |  -11.17% |     |                                 100th percentile service time |  geohexgrid | 9058.2         | 7726.13        | -1332.07    |     ms |  -14.71% |     |                                                    error rate |  geohexgrid |    0           |    0           |     0       |      % |    0.00% |     ```          Retry #87290 after being reverted by mistake.||||[0, 0, 0, 2, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 8, 0, 0, 28, 11, 0, 0, 10, 0]||||0||||0||||0
Security plugin close realms (#87429)          The `Closeable#close` method on `Realm`s was never called upon node     shutdown. This is a problem when realms (eg OIDC) create non-daemon     threads that expect to be stopped when the `close` method is invoked.     Specifically, it is a problem on Windows where the graceful shutdown is     implemented by terminatting all non-daemon threads (see `Bootstrap#stop`     and `Bootstrap#initializeNatives`).          Closes https://github.com/elastic/elasticsearch/issues/86286||||[0, 0, 0, 3, 7, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Revert "Optimize geogrid aggregations for singleton points (#87290)"          This reverts commit 30406baabfbafad6603e68177b7500f551715738.     ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 19, 0, 0, 0, 0, 8, 0, 0, 11, 28, 0, 0, 10, 0]||||0||||0||||0
Optimize geogrid aggregations for singleton points (#87290)          Use a different code path when we detect that the points on a segment     are all single valued which allow us to optimise the tight loop used     while iterating the doc values.          Checks on rally shows a modest, still nice performance improvement:          ```          |                                                        Metric |        Task |       Baseline |      Contender |        Diff |   Unit |   Diff % |     |--------------------------------------------------------------:|------------:|---------------:|---------------:|------------:|-------:|---------:|     |                                                Min Throughput | geotilegrid |    0.573237    |    0.600875    |     0.02764 |  ops/s |   +4.82% |     |                                               Mean Throughput | geotilegrid |    0.607767    |    0.630151    |     0.02238 |  ops/s |   +3.68% |     |                                             Median Throughput | geotilegrid |    0.612317    |    0.633243    |     0.02093 |  ops/s |   +3.42% |     |                                                Max Throughput | geotilegrid |    0.623922    |    0.645545    |     0.02162 |  ops/s |   +3.47% |     |                                       50th percentile latency | geotilegrid | 1539.4         | 1492.69        |   -46.7073  |     ms |   -3.03% |     |                                       90th percentile latency | geotilegrid | 1570.21        | 1514.08        |   -56.1252  |     ms |   -3.57% |     |                                      100th percentile latency | geotilegrid | 1573.78        | 1515.79        |   -57.9968  |     ms |   -3.69% |     |                                  50th percentile service time | geotilegrid | 1539.4         | 1492.69        |   -46.7073  |     ms |   -3.03% |     |                                  90th percentile service time | geotilegrid | 1570.21        | 1514.08        |   -56.1252  |     ms |   -3.57% |     |                                 100th percentile service time | geotilegrid | 1573.78        | 1515.79        |   -57.9968  |     ms |   -3.69% |     |                                                    error rate | geotilegrid |    0           |    0           |     0       |      % |    0.00% |     |                                                Min Throughput | geohashgrid |    2.5986      |    2.99851     |     0.39992 |  ops/s |  +15.39% |     |                                               Mean Throughput | geohashgrid |    2.64153     |    3.02417     |     0.38264 |  ops/s |  +14.49% |     |                                             Median Throughput | geohashgrid |    2.65188     |    3.02704     |     0.37516 |  ops/s |  +14.15% |     |                                                Max Throughput | geohashgrid |    2.66263     |    3.03953     |     0.3769  |  ops/s |  +14.16% |     |                                       50th percentile latency | geohashgrid |  371.621       |  328.431       |   -43.19    |     ms |  -11.62% |     |                                       90th percentile latency | geohashgrid |  373.7         |  331.22        |   -42.4795  |     ms |  -11.37% |     |                                      100th percentile latency | geohashgrid |  374.082       |  332.37        |   -41.712   |     ms |  -11.15% |     |                                  50th percentile service time | geohashgrid |  371.621       |  328.431       |   -43.19    |     ms |  -11.62% |     |                                  90th percentile service time | geohashgrid |  373.7         |  331.22        |   -42.4795  |     ms |  -11.37% |     |                                 100th percentile service time | geohashgrid |  374.082       |  332.37        |   -41.712   |     ms |  -11.15% |     |                                                    error rate | geohashgrid |    0           |    0           |     0       |      % |    0.00% |     |                                                Min Throughput |  geohexgrid |    0.125189    |    0.132832    |     0.00764 |  ops/s |   +6.11% |     |                                               Mean Throughput |  geohexgrid |    0.127163    |    0.133508    |     0.00634 |  ops/s |   +4.99% |     |                                             Median Throughput |  geohexgrid |    0.126976    |    0.133546    |     0.00657 |  ops/s |   +5.17% |     |                                                Max Throughput |  geohexgrid |    0.131959    |    0.134025    |     0.00207 |  ops/s |   +1.57% |     |                                       50th percentile latency |  geohexgrid | 7802.83        | 7426.77        |  -376.056   |     ms |   -4.82% |     |                                       90th percentile latency |  geohexgrid | 8501.63        | 7552.32        |  -949.308   |     ms |  -11.17% |     |                                      100th percentile latency |  geohexgrid | 9058.2         | 7726.13        | -1332.07    |     ms |  -14.71% |     |                                  50th percentile service time |  geohexgrid | 7802.83        | 7426.77        |  -376.056   |     ms |   -4.82% |     |                                  90th percentile service time |  geohexgrid | 8501.63        | 7552.32        |  -949.308   |     ms |  -11.17% |     |                                 100th percentile service time |  geohexgrid | 9058.2         | 7726.13        | -1332.07    |     ms |  -14.71% |     |                                                    error rate |  geohexgrid |    0           |    0           |     0       |      % |    0.00% |     ```||||[0, 0, 0, 2, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 8, 0, 0, 28, 11, 0, 0, 10, 0]||||0||||0||||0
Script: Add UpdateByQuery and Reindex contexts (#87431)          * Script: Add UpdateByQuery and Reindex contexts          Add two new scripting contexts, UpdateByQuery and Reindex, in addition     to the Update context.  These three contexts have different sets of     metadata and so their Metadata classes will be different.  This split     prepares for the addition of their own Metadata classes.          Refs: #86472||||[0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 9, 2, 12, 0, 0]||||0||||0||||0
Add support for building elasticsearch source on macos before monterey (#87430)          Closes #87426||||[0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]||||0||||0||||0
Master stability health indicator part 1 (when a master has been seen recently) (#86524)          This is the first PR for the master stability check, which is part of the health API. It handles the case     when we have seen a master node recently. The more complicated case when we have not seen a     master node recently will be in subsequent PRs.||||[0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0]||||0||||0||||0
Force property expansion for security policy (#87396)          When resolving the security policy files for server and components of     Elasticsearch, each jar file location is put into a special system     property value so that policy files may contain codeBase specific     grants. The mechanism for substituting system properties is part of the     JDK's policy parser. However, a security property exists,     policy.expandProperties, which controls whether properties will actually     be expanded. If a user ends up setting this, Elasticsearch will fail to     start.          This commit forces the value of the security property to ensure the     policy files can always be parsed correctly.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]||||0||||0||||0
[ML] adjust change_point to not throw with too few buckets (#87297)          It can be frustrating for agg consumers to handle failure modes when we should just indicate that there were too few buckets to calculate the change.          Other aggs simply return NaN or empty results when too few docs are calculated. We should follow suit for continuity of experience.||||[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Simplify master task failure handling (#86970)          Today a batching executor must submit an `ActionListener<ClusterState>`     for every task in the batch that succeeds. This listener allows to     consume the published cluster state, or any failure that occurs during the     publication following the successful task execution.          There's no real reason for an executor to customise the failure handling     here, and in practice these listeners always defer failures to the     task's `onFailure()` method. This commit removes the ability for     executors to handle failures differently here by replacing the     `ActionListener<ClusterState>` with a simple `Consumer<ClusterState>`.          Moreover we consider it an antipattern to actually consume the published     `ClusterState`, so this commit introduces variants that ignore the     `ClusterState` and accept a `Runnable` instead.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 21, 0]||||0||||0||||0
App permissions with action patterns do not retrieve privileges (#85455)          In order for file realm users, with application privileges, to continue     to work (authenticate) when the `.security` index is unavailable,     Security must avoid loading the application privileges from the     .security index (which is unavailable, hence error out). Roles (defined     inside the `roles.yml` file, not in the index) that must work when the     `.security` index is unavailable must use inlined action patterns for     application permisions, rather than privilege names.          Related https://github.com/elastic/elasticsearch/issues/85312||||[0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 0, 1, 1, 0]||||0||||0||||0
Remove unused import from NumberFieldMapper          Fixes checkstyle error of #85688     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
User Profile - Move profileHasPrivileges API behind the feature flag (#87385)          The API should be behind feature flag for the 8.3 release.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Speed up NumberFieldMapper (#85688)          No need to create an intermediary list here. Creating it and adding it     to the document tended to take more time than the parsing of the number itself.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 12, 0, 0, 11, 0]||||0||||0||||0
Convert o.e.cluster to use Map in public methods (#87168)          Many classes that use ImmutableOpenMap expose the maps directly, when     the consumers actually only use methods from the base Map interface.     This commit converts public methods in subpackages of o.e.cluster to     return Map instead of ImmutableOpenMap. Note that o.e.cluster classes     are not yet converted because they require more involved changes.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 0, 0, 0, 0, 0, 0, 15, 0]||||0||||0||||0
Remove ImmutableOpenMap test utils (#87305)          These utilities were the equivalent hamcrest matchers to those for Map,     but are now unused.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
TSDB: Fix RollupActionSingleNodeTests failing with IndexNotFoundException (#87333)          Looks like the failure reported at #69799 (comment) happens because of     randomly generated index names conflict between two tests.          Add more random numbers to test names, so that the probability of conflicts is negligible     Generate source and rollup index names more carefully so that they are logged properly.     Cleanup test code          Fixes #69799     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Implement write throttling in Netty4HttpPipeliningHandler (#86922)          A step towards chunked rest encoding that only serializes chunks that     can be written right away and an optimization in isolation. A follow-up to this change will be able to use the flush + writability hooks introduced here to do serialization lazily and in chunks. This change was extracted into its own PR because it is somewhat complex for one but also because it provides performance benefits in isolation.          Introduces the concept of queuing writes in the handler once a channel becomes unwritable     to the `Netty4HttpPipeliningHandler`. Doing this reduces the memory consumption of compressed     responses as well as their first byte latency by only compressing chunks of a message     that can be written to the channel directly. Prior to this change, all chunks would be compressed     first before any writes to the channel, wasting buffers that can't be written yet as well as     making the write to the channel wait until compression completed.     A further advantage of this change is that a large REST response will not block the transport thread     for a long compression operation any longer as it does today.          The implementation of writability and flush hooks in `Netty4HttpPipeliningHandler` has been intentionally coded in a similar fashion to that in `Netty4WriteThrottlingHandler` (albeit it is much simpler because we do not chunk individual messages on the byte level in it) to allow for some drying up of the logic in a follow-up.     ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 1, 0, 0, 0, 0]||||0||||0||||0
Relax geo_grid query test for max geo_tile zoom (#87357)          This commit removes testing geo_grid queries on the maximum geo_tile zoom||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Tests ignore longitude=180 when index Legacy point (#87364)          * Tests ignore longitude=180 when index Legacy point          It turns out that LegacyGeoShape has an issue indexing points with     longitude=180, but since this is legacy, rather than fix that,     we just skip it from tests.          See https://github.com/elastic/elasticsearch/issues/86118     ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Allow start cluster with unreachable remote clusters (#87298)          If the local cluster has a remote_cluster setting defined in YAML file     and the remote cluster is not reachable, then the local cluster won't     start. This PR relaxes that constraint as it's too restricted and     requires manual intervene.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0]||||0||||0||||0
Faster NumberFieldMapper.value (#87351)          Calling `currentToken` isn't as cheap as a getter call since it hits a huge switch statement     and doesn't inline well. Even more so when a delegating x-content parser is called which has     a bunch of additional overhead -> saving the expensive call here to save a couple of % of runtime     for number field mappers.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Fix resolution of wildcard application privileges (#87293)          Previously, a role with application privileges of          {     "application": "*",     "privileges": ["*"]     "resources": ["*"]     }          would be resolved to mean every _defined_ privilege in every _defined_     application (subject to condition 1 described below).          This implementation was based on the assumption that every action that     would ever be checked by _has_privileges would be explicitly defined     as an application privilege (via PUT /_security/privilege)          That assumption would have been fine if not for 2 discrepancies          1. The resolved privileges were then filtered by privilege name and     wildcards were not respected. So the role shown above would     actually filter down to nothing. However if the user had another     role with named privileges (not wildcards) then the filtering would     include that privilege _if it was defined_.          2. The logic to construct a runtime ApplicationPrivilege from the     resolved ApplicationPrivilegeDescriptor instances had special case     logic to handle 0 matching descriptors. This was needed so that     superuser always had every privilege, even if the descriptors had     not yet been defined, or where unavailable for some reason. However     because this logic only applied if there were no matching     descriptors the behaviour was inconsistent. For the most part it     would look like wildcard application privileges functioned     correctly even when no application privileges were defined, but     this behaviour could not be relied on if the user had additional     roles that references defined application privileges (per point 1).          This change solves point 2, by always including the wildcard     permission even if there are matching descriptors. It does nothing to     solve point 1, and it is likely that we need additional commits to     cleanup the logic there.     ||||[0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 1, 3, 3, 0]||||0||||0||||0
Mute TokenAuthIntegTests#testRefreshingMultipleTimesWithinWindowSucceeds (#87353)          Relates #85697||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Cancellable Profile Has Privilege check  (#87224)          The "profile has privileges" endpoint is designed to check the     privileges of many users, given their profile ids, in a single call.     This commit runs the privileges check under a "cancellable" task. When     the task is cancelled, the check is interrupted for the remaining     profiles to-be-checked. The task can also be cancelled when the HTTP     client disconnected.||||[0, 0, 0, 2, 11, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 6, 0, 0, 9, 0]||||0||||0||||0
Fix Enrich*IT test failures (#87317)          Fix EnrichIT, EnrichSecurityIT and EnrichAdvancedSecurityIT test failures     caused by a warning being emitted during auto creation of 'my-index' index.     The warning has nothing to do with the index being created, but the monitor     index being created at the same time (in same cluster state update) triggers     a warning and that leaks to the index response in this test, which causes     test failures.          Closes #83366     Relates to #85506||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[TEST] Verify that nested type is not supported when subobjects is false  (#87218)          We have tests that verify that objects can't be created in the mapping under an object that has subobjects set to false. The existing checks work also for the nested type, as NestedObjectMapper extends ObjectMapper, yet this commit adds specific tests for this scenario.          This helps clarify that we were checking this twice, once at parse time and once in buildMappers. The latter check should not be needed, hence the check at parse time is broadened to cover for the nested type while the second check in buildMappers throws now IllegalStateException when not satisfied.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
User Profile - audit support for security domain (#87097)          Security domain allows sharing resources across different realms which     means it is now part of the authorization process. Hence we should     capture it in relevant audit entries for completeness.          In theory, the domain name should be captured in all the places realm     name is captured. However, it is not necessary in practice because:          1. The field `realm` in authentication_success event is for BWC purpose.     Hence we don't need pair it with domain.     2. API Keys cannot be under any domain.     3. No need to audit domain for authentication_failed events because no     authorization is possible in these cases.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Disallow three-digit minor and revision versions (#87338)          This came up because a yml test erroneously had 8.2.999 as a skip version, however, when the yml     test parser calls Version.fromString("8.2.999") the version 8.11.99 is what is actually     parsed out. This commit makes the minor and revision numbers have a limit of two digits, to match     our existing version conceptions. There is no limit on the number of major version digits.          Hopefully we don't need more than 100 minor versions within a single major (yet), or more than 100     patch releases.     ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0]||||0||||0||||0
Remove ImmutableOpenMap from most xpack tests (#87334)          Many tests in xpack create ImmutableOpenMap for building mock cluster     states. However, since most of the API signatures for the cluster state     have changed to be Map, it is no longer necessary to build     ImmutableOpenMap. This commit converts most tests in xpack to build Maps     for their mock cluster states.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 14, 1, 0, 87, 0]||||0||||0||||0
Skip ensureNoSelfReferences check in IngestService (#87337)          A self reference check is performed by the XContentBuilder when the     document map is serialized using the `indexRequest.source(...)` call.     This means we can remove the call to     `CollectionUtils.ensureNoSelfReferences` above and only do the check     once instead of twice.          Relates to #85926 and (subsequent work in) #87335||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Using the correct connection to fetch remote master history (#87299)          Previously MasterHistoryService was using openConnection to open a connection to the master in order to fetch the remote master history. However it was not passing that connection to sendRequest so we might have been using another one. This change uses connectToNode instead.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Added migration/index.asciidoc generation support (#87318)          Including extracting static content from migration/index, so the template would be as light as possible.          The reason for this work is because the gradle task `generateReleaseNotes` was not correctly adding new links and imports to the migrations/index and that caused documentation to fail building for 8.3.0.     ||||[0, 0, 0, 0, 6, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 0]||||0||||0||||0
Port BuildPluginIT to spock (#87104)          We port all our tests for gradle build logic to use spock          Part of #86720||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 2, 0]||||0||||0||||0
Small speedup in FieldMapper.Builder.parse (#87209)          Creating the params map is quite hot in benchmarks.     Presizing it correctly helps a little. Also replaced a needless series     of conditionals with a switch to make the massive loop a little cheaper.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fields API to allow fetching values when _source is disabled (#87267)          Back when we introduced the fields parameter to the search API, it could only fetch values from _source, hence     the corresponding sub-fetch phase fails early whenever _source is disabled. Today though runtime fields can     be retrieved from a separate value fetcher that reads from fielddata, and metadata fields can be retrieved     from stored fields. These two scenarios currently throw an unnecessary error whenever _source is disabled.          This commit removes the check for disabled _source, so that runtime fields and metadata fields can be retrieved even when _source is disabled. Fields that need to be loaded from _source are simply skipped whenever _source is disabled, similar to when a field is not found in _source.          Closes #87072||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 0, 0, 4, 0]||||0||||0||||0
Mute RestClientMultipleHostsIntegTests#testNonRetryableException (#87316)          Relates #87314||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Modularize deprecation component (#87287)          This is a change to modularize deprecation component by adding module-info.java     relates #78744||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use Map in indices responses (#87292)          This commit converts GetAliasesResponse and GetSettingsResponse to use     Map instead of ImmutableOpenMap.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 3, 0]||||0||||0||||0
Move declarative plugin sync to server cli (#87273)          When running in Docker, the elasticsearch-plugins.yml allows configuring     plugins that should be installed in the system. Upon Elasticsearch     starting up, plugins are installed/removed to match the configured     plugins. However, this happens late in startup, and it would be nice to     keep the main Elasticsearch process from ever writing outside the     configured data directories. Now that the server cli has been moved to     Java, this is possible.          This commit moves invocation of the plugins sync command into the server     cli. Note that the sync plugins action should probably be reworked as it     can be implement Command directly now. However, this commit tries to be     the minimal change possible to remove plugin cli knowledge from server.||||[0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 6, 6, 2, 3, 0]||||0||||0||||0
Convert cluster state "customs" to Map (#87265)          The pluggable portions of in memory cluster state are held within an     ImmutableOpenMap. This commit converts that to a Map. Note that the diff     format is the same for immutableopenmap and jdk map, so no bwc logic is     necessary.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Remove some blocking in CcrRepository (#87235)          Today `CcrRepository#getRepositoryData` blocks the calling thread     pending receipt of the full metadata of the remote cluster. It would be     preferable if it didn't get the full cluster metadata at all, but we can     at least remove the blocking wait here.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 2, 2, 0]||||0||||0||||0
Fix Geotile aggregations on geo_shapes for precision 0   (#87202)          Changes the way we handle geo_shapes at precision 0 by using always brute force scan.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0]||||0||||0||||0
Fork after calling getRepositoryData from StoreRecovery (#87264)          `Repository#getRepositoryData` will occasionally complete its listener     on a blocking-free thread (a transport worker or the cluster applier     thread) so it's not valid to call `Repository#restoreShard` directly.     This commit fixes this by using a forking listener.          Closes #87237||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Log warning when cache hasher not compliant with FIPS (#86740)          Currently, it's possible to choose a hash function for various cache     hashers (e.g., in ApiKeyService) that is not compliant with FIPS 140     (e.g., MD5). This PR logs a warning on node start if a non-compliant     hashing algorithm is used in FIPS mode.          Note that there are other usages of non-FIPS compliant hash functions,     which are not configured through settings (e.g.     FingerprintProcessor). I plan to address these in a separate PR.          Relates #68743||||[0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 3, 0]||||0||||0||||0
Revert "Fork after calling getRepositoryData from StoreRecovery (#87254)"          This reverts commit 1c48b04b252639e8296eaecda4e9e778a56633cd.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Fork after calling getRepositoryData from StoreRecovery (#87254)          `Repository#getRepositoryData` will occasionally complete its listener     on a blocking-free thread (a transport worker or the cluster applier     thread) so it's not valid to call `Repository#restoreShard` directly.     This commit fixes this by using a forking listener.          Closes #87237||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Do not retry client requests when failing with ContentTooLargeException (#87248)          ||||[0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 2, 0, 0, 1, 0]||||0||||0||||0
Fix range aggregator test (#87253)          The test for range aggregator expected the index it was testing not to     be force-merged to a single segment. But it's a lucene test case so all     kinds of weird things can happen - about 3.4% of the time the index was     indeed one segment. This fixes the assumption.          Closes #87205||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Replace log4j-1.2 with log4j2 API (#87225)          Some of the logging usages are incorrectly using log4j v 1.2     instead of log4j2-api.     This commit fixes this.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix date_histogram test (#87250)          The test for date_histogram expected the index it was testing not to be     force-merged to a single segment. But it's a lucene test case so all     kinds of weird things can happen - about 3.4% of the time the index was     indeed one segment. This fixes the assumption.          Closes #87203||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Assert that some getters are not accessed for unmanaged indices (#87059)          * Assert that some getters are not accessed for unmanaged indices          There are many properties in SystemIndexDescriptor that should only be     accessed when dealing with managed system indices. Any code that accesses     the getters for these properties should be inside of a block that checks     whether an index is managed or not. Here, we add assertions to verify     that this is the case, or to point us to places where our code may be     buggy.||||[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 15, 0, 5, 5, 0]||||0||||0||||0
Delete index commits last in CombinedDeletionPolicy (#87221)          If we hit an IOException while reading the doc count of the safe commit     (i.e., calling getDocCountOfCommit), then IndexFileDeleter will expose     deleted index commits. This change re-arranges the onCommit method to     ensure that deleting index commits is the last thing in the method.          Closes #87204||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 7, 3, 2, 5, 0]||||0||||0||||0
Hide system indices and their aliases in upgraded clusters (#87125)          * Hide system indices in upgraded clusters          We have code that is supposed to make sure existing system indices are     made into hidden indices if they are visible, and to hide aliases for     system indices. However, that code was in a ClusterStateUpdateTask, and that     task was only submitted in the case when we needed to toggle an index's     "system" setting from true to false or false to true.          Here, we update the checks so that the task is submitted in the cases     where an index is correctly marked as a system index, but is not itself     hidden or has aliases that are not hidden. We also add test coverage for     the method that checks whether system index metadata should be updated.          * Update docs/changelog/87125.yaml          * Unit test interaction of boolean checks||||[0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0, 0, 6, 0]||||0||||0||||0
Add Javadoc for basic System Indices classes (#87184)          Add javadoc describing the expected behavior of the SystemIndices class,     the descriptor classes, and the SystemIndexPlugin interface.          Co-authored-by: Elastic Machine <elasticmachine@users.noreply.github.com>||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Revert "Remove some blocking in CcrRepository (#87016)"          This reverts commit 9c9bc8797b34994d0a1117debd2e8058658b407d.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 5, 0, 2, 2, 0]||||0||||0||||0
Remove some blocking in CcrRepository (#87016)          Today `CcrRepository#getRepositoryData` blocks the calling thread     pending receipt of the full metadata of the remote cluster. It would be     preferable if it didn't get the full cluster metadata at all, but we can     at least remove the blocking wait here.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 2, 2, 0]||||0||||0||||0
Refactor ParameterizedMessage used in lambda and casted to Supplier (#87156)          This is a result of structural search/replace in intellij. This only affects log methods with a signature     logger.info((Supplier) ()-> ParametrizedMessage) logger.info((Supplier) ()-> ParametrizedMessage, Throwable)          relates #86549||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 0]||||0||||0||||0
Support exists query for API key query (#87229)          Exists query is useful for testing whether expiration date is configured     for an API key or whether a metadata field exists. This PR adds support     for it.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[Test] Random domain names are now unique (#87227)          Duplicate domain names can cause settings builder to override each other     but in a not complete way. This leads to partially configured settings     which in turn leads to assertion failure.          This PR fixes it by ensure unique domain names in test. This is     reasonable because settings deduplication in production is done before     they reach to the realms code.          Resolves: #87226||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Fix status code when open point in time without keep_alive (#87011)          Closes #87003||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]||||0||||0||||0
[TEST] Rename DynamicTemplateTests to DynamicTemplateParseTests (#87217)          We have had since today DynamicTemplateTests as well as DynamicTemplatesTests. When adding a new test for dynamic templates, naming does not help understanding what the right place is. This commit addressed this by renaming DynamicTemplateTests to DynamicTemplateParseTests as it holds only tests around the static parse method that parse a dynamic template into its corresponding object.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[TEST] Expand tests for subobjects false (#87216)          This commit adds more tests that cover edge cases around setting subobjects to false for a given object. The new tests focus on dynamic mapping behaviour, for instance when dynamic is set to false on the parent mapper, or the mapping for the object itself comes from a dynamic template. Also, a new test is added to cover geo_point parsing, meaning to verify that objects are accepted in a document when for fields that are mapped (either in the mapping or through dynamic template) and support parsing objects natively.||||[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Clean up DeflateCompressor after exception (#87163)          We must reset the thread-local buffer in `DeflateCompressor` whether the     compression succeeds or fails.          Closes #87160||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 7, 0, 0]||||0||||0||||0
Modularize the ingest.common component (as well as dissect and grok dependent libs) (#87219)          This is change modularizes the ingest.common component,     by adding a module-info.java. As well as two dependent libs.          The project only requires painless SPI to compile, so that was     fixed along the way ( so that the compile module path can be     inferred directly from the dependencies ).||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Tolerate GraalVM compiler threads in testThreadNames (#87105)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Adjust assertion for responses without successful shards (#87195)          Closes #85760||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Mute RangeAggregatorTests.testRuntimeFieldRangesNotOptimized (#87206)          Relates #87205||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Catch an exception due to incorrect pattern in Strings.format (#87132)          Strings.format method, which is used heavily in logging with     Supplier should handle exceptions when a format is incorrect.     This will prevent a hard to catch mistakes to blow up in server.     Those mistakes are especially hard to detect in logging when a     code to create a message might be only executed when logger is debug     or trace. Which is not always the case in CI.          relates #87077 (comment)          relates #86549||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 1, 0, 0]||||0||||0||||0
Visit point values once (#85499)          Closes #85484 Closes #86723||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Minor RangeAgg optimization (#86935)          * Minor RangeAgg optimization          Shortcut for when we have single values in a range aggregation. This also     targets date histogram aggregations which often are converted to range     aggregations. Add profiling counts for the singleton and non-singleton     code paths.          Closes #84262     ||||[0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 4, 0]||||0||||0||||0
Bump versions for 8.2.2 release     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix NullPointerException in creating the parent Pid directory (#87008)          ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
[ML] Split node load counts by job type (#87172)          This refactoring is in preparation to remove native inference jobs     from the jobs that account towards the max open jobs limit.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 21, 0]||||0||||0||||0
Modularize the data-streams component (#87157)          This is change modularizes data-streams, by adding a module-info.java||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Temporarily provide SystemPropertiesPropertySource (#87149)          Temporarily provide SystemPropertiesPropertySource to workaround a bug in Log4J where it does not declare the provider implementations in its module-info.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Implement support for partial search results in SQL CLI (#86982)          Add support for          allow_partial_search_results = true/false          command in SQL CLI.          If true, returns partial results if there are shard request timeouts or shard failures.     If false, returns an error with no partial results.||||[0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 3, 0]||||0||||0||||0
Add Resolve Index API to the "read" permission for an index (#87052)          This commit allows the index "read" permission to also allow using the     resolve index Action.          Resolves #86977||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Make pidfile deletion more resilient (#87134)          Deleting the pidfile when Elasticsearch is shutting down was moved in #86934.     However, the delete SM permission is still needed, since SM is installed     by the time we shutdown. This commit adds back to the pidfile delete     permission, and also rethrows any io exception so it can be logged by     our uncaught exception handler.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 10, 0]||||0||||0||||0
Fixing testComplicatedBucketPath for avg bucket agg (#87161)          The test was erroneously creating a test Lucene index reader directly. This means that sometimes the reader was wrapped as a Parallel (threaded) reader which we don't support yet.          This commit cleans up the test and uses AggregatorTestCase#newIndexSearcher directly.          closes #87155||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 1, 0, 0, 2, 0]||||0||||0||||0
Make KeywordFieldMapper more compact (#87147)          Removing some redundant fields to make these objects smaller.     This change saves almost 200M on heap per data node in the many-shards     benchmark by saving an estimated 14b-16b (didn't do the alignment math)     per instance.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Replace new ParametrizedMessage() with java.util.Supplier<String>  (#87077)          This is a result of structural search/replace in intellij. This only affects log methods with a signature     logger.info(ParametrizedMessage)     logger.info(ParametrizedMessage, Throwable)          relates https://github.com/elastic/elasticsearch/issues/86549||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 9, 4, 0, 0, 165, 0]||||0||||0||||0
Update bucket metric pipeline agg paths to allow intermediate single bucket and bucket qualified multi-bucket aggs (#85729)          Bucket metric pipeline aggregation paths currently always expect the sibling aggregation to be a multi-bucket agg.          This honestly doesn't have to be the case for bucket metric pipeline aggs to work.          Consider the following path:          ```     filter_agg>filters_agg['bucket_foo']>histo>some_metric_agg     ```          Since `filter_agg>filters_agg['bucket_foo']` are well defined and are not crossing bucket threasholds, metrics should still be able to be calculated against the bucket values for `histo`          This commit allows any combination of single bucket aggs (e.g. filter) and bucket specific multi-bucket aggs before reaching the desired multi-bucket used for the metric calculation.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 12, 0]||||0||||0||||0
Hide ImmutableOpenMap in Metadata public methods (#87124)          This commit converts the remaining methods in Metadata that return an     ImmutableOpenMap to return Map, thus hiding the fact that Metadata uses     ImmutableOpenMap internally.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 7, 0]||||0||||0||||0
[Refactor] Remove nearly-redundant method from SystemIndices (#87093)          The getProductSystemIndexMetadataPredicate was only used once, and could be     replaced by the very similar method getProductSystemIndexNamePredicate. This     not only simplifies the public API, but removes the cognitive load of     understanding how the two methods differed.          Co-authored-by: Elastic Machine <elasticmachine@users.noreply.github.com>||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
[ML] expand allowed NER labels to be any I-O-B tagged labels (#87091)          Named entity recognition (NER) is a special form of token classification. The specific kind of labelling we support is Inside-Outside-Beginning (IOB) tagging. These labels indicate if they are the inside of a token (with a `I-` or `I_`), the beginning (`B-` or `B_`) or outside (`O`).          Each valid token classification label starts with the require prefix or `O`.          Before this commit, we restricted the labels to a specific set:          ```     O(Entity.NONE),      // Outside a named entity     B_MISC(Entity.MISC), // Beginning of a miscellaneous entity right after another miscellaneous entity     I_MISC(Entity.MISC), // Miscellaneous entity     B_PER(Entity.PER),   // Beginning of a person's name right after another person's name     I_PER(Entity.PER),   // Person's name     B_ORG(Entity.ORG),   // Beginning of an organization right after another organization     I_ORG(Entity.ORG),   // Organisation     B_LOC(Entity.LOC),   // Beginning of a location right after another location     I_LOC(Entity.LOC);   // Location     ```          But now, any entity is allowed, as long as the naming of the labels adhere to IOB tagging rules.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 6, 10, 0, 10, 55, 0]||||0||||0||||0
Remove leftover debugging statement on error (#87128)          A debugging statement was left being printed when ES exits with a     non-zero status. This commit removes the debug statement.          relates #85758||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]||||0||||0||||0
Bump version to 8.4.0     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
TSDB: Implement downsampling on time-series indices (#85708)          This PR implements downsampling operation on time series indices.          The PR creates a _rollup endpoint that allows users to downsample an index and can be     accessed by the following call:          POST /<source_index>/_rollup/<rollup_index>     {     "fixed_interval": "1d"     }          Requirements          An index can be downsampled if all of the following requirements are met:          Must be a time series index (have the index.mode: time_series index setting)     Must not be writeable (have the index.blocks.write: true index setting)     Must have dimension fields marked with mapping parameter time_series_dimension: true     Must have metric fields marked with mapping parameter time_series_metric          Relates to #74660          Fixes #65769     Fixes #69799     Finally, this PR is based on the code written for #64900     ||||[0, 0, 0, 1, 18, 13, 1, 0, 0, 0, 2, 4, 10, 0, 0, 9, 0, 0, 1, 2, 0, 2, 1, 9, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 14, 4, 0, 0, 0, 0, 0, 0, 39, 52, 2, 1, 16, 0]||||0||||0||||0
Increase force_merge threadpool size (#87082)          Changes the default size used for the force_merge threadpool to 1/8 of     the allocated processors, with a minimum value of 1.          Closes #84943||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Extract transport cluster settings/ilm execute logic (#86941)          Extract execute logic from the transport actions for cluster     update settings and ILM put/delete to support future reuse for     operator file based updates.          Relates to #86224||||[0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 1, 0]||||0||||0||||0
Handle unexpected exit code from server process (#87098)          When running Elasticsearch in the foreground, the cli process waits     indefinitely on the server. If the server dies unexpectedly, the     ServerProcess throws an exception. However, the exit code is hidden in     the exception message. This commit changes waitFor to return the exit     code, so it can be propagated to the cli main. Note that when stopping     in a shutdown hook the exit code must be ignored because calling     System.exit from a shutdownhook results in a deadlock.||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 7, 7, 0, 0, 0, 0]||||0||||0||||0
Read official plugins list non-statically (#87096)          New plugin telemetry keeps track of whether a plugin is in the list of     official plugins. This requires reading the plugins list resource file.     Reading that statically depends on the jar being built, but that is not     available during tests. It's also not necessary to keep this list in     memory for the lifetime of the node. This commit moves reading the file     to occur only when constructing the plugin runtime info.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add unstable plugin API telemetry (#87061)          This commit adds some new information to the node info and cluster stats responses regarding plugins. For each plugin returned, in addition to the plugin descriptor, a boolean indicating whether the plugin is an official plugin, as well as info on the particular interfaces and methods that the plugin implements are returned. This will allow measuring the effectiveness over time of the stable plugin API.          Co-authored-by: ChrisHegarty <christopher.hegarty@elastic.co>||||[0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 20, 10, 0, 1, 12, 0]||||0||||0||||0
Fix SnapshotLifecycleRestIT testStartStopStatus failing (#87088)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Timing out stale remote master history (#86936)          This change makes it so that the remote master history that has been fetched will time out after 5 minutes (by     default). The MasterHistoryService will return its value as null if it is older than the configured timeout. This way     MasterHistoryService clients don't report status based on out of date information.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 2, 0]||||0||||0||||0
Upgrading to tika 2.4 (#86015)          Tika 1.x is end of life as of later this year. This change updates the     AttachmentProcessor to use tika 2. The goal was to keep the     functionality as close as possible, just with upgraded tika. The tests     have been slightly modified because of a small change in tika     functionality -- as of 2.4.0 it now adds an extra newline to the output     for every embedded attachment in a document. Also as part of this I have     broken apart the tika-parsers into individual dependencies. The reason     is that we are considering breaking this plugin apart, and want to know     exactly which parsers we pull in.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]||||0||||0||||0
Health api copy editing (#87010)          Edits to human readable text returned from the health api. A number of edits have been added for     readability and correctness.||||[0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0]||||0||||0||||0
Make sure to rewrite explain query on coordinator (#87013)          Some queries (like terms lookup queries) need to be rewritten on the     coordinator node, usually to fetch some resource. The explain action was     missing this rewrite step, which caused failures later when trying to execute     the query.          Closes #64281.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 0, 0]||||0||||0||||0
Fix DataStreamSecurityIT#testRemoveGhostReference() test (#87087)          If the modify data stream api can find the IndexMetadata of an index it     tries to remove from a data stream then it can unhide the index as well,     otherwise it can't.          This determines whether the expected index stats is either 1 or 2 in the     last get indices stats call.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Return a default user action if no actions could be determined (#87079)          If a shard is unassigned for a reason other than NO_VALID_SHARD_COPY or the deciders returning     a NO response, then no user actions are returned. If the deciders return no, but we cannot determine     a root cause in the indicator we return a default user action. If we could not generate any user actions     for a shard being unassigned, we should always add one.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Allow the modify data stream api to remove broken reference to a backing index (#87030)          This adds a `force_remove_backing_index` action to the modify data     stream api to allow removing broken reference to backing indices from a     data stream.          ```     POST _data_stream/_modify     {     "actions": [     {     "force_remove_backing_index": {     "data_stream": "my-logs",     "index": ".ds-my-logs-2099.01.01-000001"     }     }     ]     }     ```||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 8, 0, 2, 5, 0]||||0||||0||||0
Bump versions for 8.1.2 release     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Improve "Has Privilege" performance for boolean-only response (#86685)          Boolean-only privilege checks, i.e. the ones currently used in the     "profile has privilege" API, now benefit from a performance improvement,     because the check will now stop upon first encountering a privilege that     is NOT granted over a resource (and return `false` overall). Previously,     all the privileges were always checked over all the resources in order     to assemble a comprehensive response with all the privileges that are     not granted.||||[0, 0, 0, 0, 3, 1, 1, 16, 0, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 5, 0, 1, 2, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 7, 0, 0, 89, 97, 0, 1, 21, 0]||||0||||0||||0
Add troubleshooting guides to shards allocation actions (#87078)          Add troubleshooting guides to shards allocation actions.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Run yaml rest tests using CCS in multi-cluster setup (#86521)          Currently we only test a small subset of cross cluster search functionality in     rest tests living in the 'multi-cluster-search' qa module. In order to increase     test coverage for basic CCS functionality , this change adds a new qa modula     that re-uses a subset of existing yaml rest tests and runs them in a slightly     modified fashion in a CCS scenario.     Document data and other write operations are executed agains a "remote"     cluster, while all calls to the search API aand other APIs that support CCS are     performed on a local cluster connected to the remote with all the data via CCS.          Relates to #84481||||[0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]||||0||||0||||0
Remove ImmutableOpenMap from GetMappingsResponse (#87045)          When retrieving mappings, the response class exposes an     ImmutableOpenMap. Yet the consumers just use Map operations. This commit     changes the type returned by the response class, as well as the internal     type, to Map.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 6, 0]||||0||||0||||0
Make ImmutableOpenMap hash code the same as HashMap (#87070)          ImmutableOpenMap implements Map so that we can slowly convert uses to     regular Maps. However, many serialization tests check equal and hashcode     is the same with a roundtrip. In order for that to be true, the hashcode     for ImmutableOpenMap needs to be the same as HashMap. This commit     makes ImmutableOpenMap extend AbstractMap, and then changes the each     entry hashCode to the be the same as HashMap.Entry.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix CCR following a datastream with closed indices on the follower corrupting the datastream (#87076)          Reproducer and fix for #87048.          Reproduces the edge case by closing follower index that is part of a datastream and then recreating and re-adding that same index on the leader to make it get picked up by the auto-follower again. Using stats call in the test mainly to reproduce the exact issue that motivated #87048 and to show that the datastream is correctly resolved by the index name expression resolver.          closes #87048||||[0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 6, 0, 2, 2, 0]||||0||||0||||0
Bump versions for 7.17.4 release     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Port Thirdparty audit task tests to spock (#86832)          One step closer to #86720||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 1, 3, 0]||||0||||0||||0
Support configurable claims in JWT Realm Tokens (#86533)          ||||[0, 0, 0, 0, 1, 1, 0, 0, 3, 0, 0, 2, 10, 0, 1, 0, 0, 0, 0, 3, 0, 5, 0, 2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 11, 0, 0, 39, 0]||||0||||0||||0
Remove default values from term and span query xcontent (#86985)          Mostly this is just removing boosts, but it also simplifies span_not     slightly. It also removes the boost parameter from term, as that     shares an implementation with span_term.          Relates to #76515||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 9, 0]||||0||||0||||0
Refactor log4j supplier of ParameterizedMessage with throwable (#87022)          This is a result of structural search/replace in intellij. This only affects log methods with a signature     logger.info(Supplier<?>, Throwable) where level could be info/debug etc and supplier argument is in a form of     ()-> new ParameterizedMessage          relates #86549||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 137, 0]||||0||||0||||0
[Rest Api Compatibility] Enhance error message with ref to dev guide (#86831)          When a rest api compatibility test fails a message should be enriched     to include a ref to a developers guide.     The developers guide contains more information on how to troubleshoot     the test failure, where to look for transform tests etc.          relates #85955||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0]||||0||||0||||0
Add log4j.core to requires for the security module (#87073)          org.apache.logging.log4j.core is referenced in the LoggingAuditTrail     class. This PR adds it to the requires list of the security module.          Relates: #81066||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Randomize connection mode for AbstractMultiClustersTestCase (#86865)          Currently tests extending AbstractMultiClustersTestCase, i.e. mostly the CCS     tests, use the default connection mode configuration of the abstract base tests,     which is the default "sniff" mode. In order to increase coverage for "proxy"     mode connections this change starts to randomize the connection type in the     setup. Subclasses of this test are free to use or overwrite this behaviour.          Relates to #84481||||[0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 7, 0, 0, 1, 0]||||0||||0||||0
Improve rejection handling in ThreadedActionListener (#87042)          Today if the submission within `ThreadedActionListener#onResponse` is     rejected from its threadpool then we call `delegate#onFailure` with the     rejection exception on the calling thread. However, if the submission     within `ThreadedActionListener#onFailure` is rejected then we just drop     the listener and log an error.          In most cases completing a listener exceptionally triggers some cleanup     which is often fairly lightweight and therefore safe enough to complete     on the calling thread. In any case it's generally preferable to complete     a listener exceptionally on the wrong thread rather than just dropping     it entirely.          This commit fixes this and adds a test to verify that     `ThreadedActionListener` completes properly even in the face of     rejections.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Dry up collection writing to StreamOutput (#86386)          Small weekend project around automated refactoring:     We have endless duplication here, drying up some of it.||||[0, 0, 0, 0, 0, 0, 5, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 294, 49, 0, 32, 50, 0]||||0||||0||||0
[Test] Ensure shardSearch task is handled before cancelling (#87021)          When the ShardSearch task is registered but not really handled,     cancellation does not work as expected. This PR ensures the task is     actually handled, i.e. creating a new readerContext, before     cancellation.          Resolves: #86881||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Convert ExecutorNames POJO to Record object (#87020)          ExecutorNames was a very simple data-holding class that easily     works as a Java record.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Improve server process tests (#87012)          When the server process dies, the cli should reflect the unexpected exit     of the process in its return from waitFor. The test for this closed the     input side of the pipe, but that is where the buffer lives. This means     there is a race condition in the cli testcase fully reading the final     message expected. This commit removes some complexity from the test by     using a single latch, and closing the pipe from the process side to     mimic the break.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 1, 0]||||0||||0||||0
Change Metadata indices to return Map (#87047)          The indices/getIndices methods of Metadata expose the impl detail of     using an ImmutableOpenMap. This commit changes the return type to Map.     For the one case in rollup where the map was fed back to an     ImmutableOpenMap builder, the type for the builder ctor was relaxed to     Map with special casing an existing ImmutableOpenMap.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 11, 0]||||0||||0||||0
Ensure Java compile module path is tracked as a task input (#87064)          This is a follow up to #81066 which ensures that we track the module     path as a input on Java compilation tasks. Since we truncate the compile     classpath and pass the module path as separate CLI arguments we need to     track those separately. We do that by simply annotating a getter on the     `CommandLineArgumentProvider`.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Synethetic Source: Fix scaled float (#86760)          This causes scaled float values that entirely saturate their numeric     range to continue saturating their range on round trip.     ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Deprecate LDAP/AD realm settings missing bind password for bind DN (#85326)          LDAP/AD authentication realms can be configured to authenticate through     LDAP via a bind user. For this it's necessary to set a bind DN (via     bind_dn) together with a bind password (via bind_password or     secure_bind_password). Setting a bind DN without a bind password will     cause all LDAP/AD realm authentication to fail, leaving the node     non-operational. This PR introduces a deprecation warning when bind_dn     is set without a bind password.          Closes #47191||||[0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0]||||0||||0||||0
Remove startup sleep time from archive tests (#87058)          The packaging tests had an env var that would sleep for some seconds to     allow Elasticsearch to startup. This commit removes the env var as it is     no longer used or necessary.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Replace the implementation of the categorize_text aggregation (#85872)          This replaces the implementation of the categorize_text aggregation     with the new algorithm that was added in #80867. The new algorithm     works in the same way as the ML C++ code used for categorization jobs     (and now includes the fixes of elastic/ml-cpp#2277).          The docs are updated to reflect the workings of the new implementation.||||[0, 0, 0, 0, 10, 4, 4, 0, 0, 0, 0, 3, 12, 0, 0, 5, 3, 0, 0, 0, 0, 0, 10, 2, 1, 3, 0, 0, 0, 0, 0, 1, 0, 2, 11, 12, 0, 0, 0, 0, 0, 0, 68, 31, 1, 3, 38, 0]||||0||||0||||0
Remove "Push back excessive requests for stats (#83832)" (#87054)          ||||[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 9, 0, 0, 0, 0, 0, 0, 35, 0, 0, 0, 9, 0]||||0||||0||||0
More verbose logging in testJoinWaitsForClusterApplier (#86975)          Relates #86974||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0]||||0||||0||||0
Guard for adding null value tags to vector tiles (#87051)          This commit adds a guard so tags with null values are ignored.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]||||0||||0||||0
[TEST] assert busy waiting for dynamic update (#87044)          Dynamic updates are not guaranteed to be applied on the master node after an index operation, hence we need to wrap the get mappings call with an assertBusy and retry until the updated mappings made it to the master.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Cleanup dead variable in restore task (#87031)          This is unused and it's confusing to have a reference to this in the restore task     because these things hold the repository generation.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Moving deprecation info API checks off the transport_worker thread (#86811)          Doing a lot of work on the tranport_worker thread can cause the cluster to become unstable because nodes can't communicate quickly enough. With a lot of indices, the deprecation info API check can take tens of seconds. This change moves those checks off of the transport_worker thread.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]||||0||||0||||0
Dump a truncated file if over limit in packaging tests (#86821)          The packaging tests run many shell commands, and capture the stdout and     stderr of those commands into files. If the file is extremely large, the     shell omits reading the file. That makes debugging any issue with large     output difficult. This commit adds handling to read up to the max file     size worth of characters from the file.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Fix ML task auditor exception early in cluster lifecycle (#87023)          In a very young cluster where there's never been a persistent     task it was possible that the ML task assignment auditor could     throw null pointer exceptions. Nothing particularly bad resulted     from this apart from filling up the log file with stack traces.          This PR avoids the problem.          Fixes #87002||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0]||||0||||0||||0
Remove unused method from SystemIndices.Feature (#87017)          This unused method looks like an accidental duplication of     SystemIndices.Feature#fromSystemIndexPlugin.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Speed up FieldMapper construction/parsing/serialization (#86860)          Speeding this up some more as it's now 50% of the bootstrap time of the many shards benchmarks.     Iterating an array here in all cases is quite a bit faster than iterating various kinds of lists     and doesn't complicate the code. Also removes a redundant call to `getValue()` for each parameter     during serialization.||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 0, 0, 12, 13, 0, 0, 26, 0]||||0||||0||||0
[Refactor] Use Lists instead of Maps for SystemIndices features (#87004)          The SystemIndices constructor should take a list instead of a map as an     argument so that we can guarantee that the map we use for feature lookups is     keyed on the feature name.          We also provide some new getter methods so that calling code does not have to     handle the map directly.||||[0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 8, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 38, 0]||||0||||0||||0
Error on direct creation of non-primary system index (#86707)          * Error on direct creation of non-primary system index     * Update docs/changelog/86707.yaml     * Allow requests to create the system alias     * Adjust watcher tests to avoid error          The last bit is ugly, but it appears that for over a year the System Indices     index creation code has been silently overwriting requests from the     watcher integration test setup. This commit changes the requests in the     watcher test so that they match what is actually executed.||||[0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 2, 0, 0, 7, 0]||||0||||0||||0
new geo_grid query to be used with geogrid aggregations (#86596)          Query that allows users to define a query where the input is the key of the bucket and it will match the     documents inside that bucket.     ||||[0, 0, 0, 0, 11, 2, 1, 0, 0, 0, 0, 3, 1, 0, 0, 9, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 30, 18, 1, 0, 7, 0]||||0||||0||||0
Read subobjects mapping parameter in advance (#86894)          As part of #86166 we added support for a new mapping parameter called `subobjects` that     can be set to the `object` field type. Such parameter will affect not only how incoming     documents will be dynamically mapped in the future, but also how field names are treated     as part of the mappings themselves.          Mappings get parsed into a map, where keys ordering is not guaranteed. In case a mappings call     contains `subobjects` set to `false` and also sub-fields for that same object, we need to make     sure that we read the parameter in advance in order to know how to treat the sub-field and decide     whether we need to expand dots in field names or leave them as they are.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 17, 0]||||0||||0||||0
Don't output default values in text query xcontent representations (#86979)          This removes default values from the xcontent representations of the     following queries:          * intervals     * combined_fields     * match_bool_prefix     * match_phrase_prefix     * match_phrase     * multi_match     * query_string     * simple_query_string||||[0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27, 0, 27, 6, 0]||||0||||0||||0
Temporarily skip server module tests on JDK 19 until a JDK bug is resolved (#87019)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0]||||0||||0||||0
Replace supplier of ParameterizedMessage with java.util.Supplier<String> (#86971)          This is a result of structural search/replace in intellij. This only affects log methods with a signature     logger.info(Supplier<?>) where level could be info/debug etc and supplier argument is in a form of     ()-> new ParameterizedMessage          This commit also introduced a Strings utility class to avoid passing Locale.ROOT to every     String.format(Locale.ROOT, pattern, args)     relates #86549||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 115, 0]||||0||||0||||0
Remove test that relied on JWT feature flag (#86499)          The testJwtRealmDependsOnBuildType test assumed that JWT was behind a     feature flag which is no longer the case          Resolves: #85407||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Modularize analysis-common (#87005)          This is change modularizes analysis-common, by adding a module-info.java||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
User Profile - Support literal username as base of profile UID (#86952)          Some identity system can provide strong guarantee on username     uniqueness. In this case, it is desirable that the unique Profile ID is     transparently related to the username, i.e. the profile UID and the     username are tranlatable in both ways. This means hashing the username     is not a viable option since hashing is one way.          This PR adds support for using the literal username as the base of a     profile UID with a fix suffix string of admin's choosing (configured on     the security domain level). This mode of UID generation also means that     ES will *not* try to differentiate users when they have the same name     because this should be guaranteed by the identity system. ES will     instead throw an error on duplication which is the safe behaviour.     ||||[0, 0, 0, 0, 1, 5, 0, 1, 0, 0, 0, 0, 1, 0, 0, 5, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 3, 25, 2, 3, 8, 0]||||0||||0||||0
Use -d with windows packaging tests (#86995)          Historically the windows elasticsearch.bat did not support the -d option     to daemonize. This meant packaging tests needed to mimic the behavior to     run in the background. With the completation of migration of the server     cli to java, the -d option is now available on windows. This commit     removes the packaging test code that runs Elasticsearch in the     background in favor of using the new option.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Health api add indicator doc links (#86904)          This PR adds a number of documentation links to health indicators. An indicator's help URL will be displayed     when a health indicator returns a non-GREEN result.||||[0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 44, 0]||||0||||0||||0
Skip on 19 (#87000)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Fix null message in stdout (#86981)          ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Script: add ability to alias classes in whitelist (#86899)          This adds the ability to add aliases to classes in the whitelist.          Currently, inner classes need to be scoped by outer classes.  However for metadata, https://github.com/elastic/elasticsearch/issues/86472, we want the metadata for each update script to be of type `Metadata` but have different implementations and different whitelisted fields.          This change makes it possible to add an alias for a class name so scripts can refer to that alias, eg `Metadata md = meta();` vs `IngestScript.Metadata md = meta();`          Refs: #86472||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Improve error message for search API url parameters (#86984)          The search API uses url query parameters that require other parameters to be     present. When one of them is ommited, the other depending parameters might not     be consumed, leading to an error message about unconsumed parameters from the     BaseRestHandler that are not actionable by the user.     This change adds improvements for url query parameters that require the     existance of the 'q' query string parameter and also adds better error message     for suggestion url parameter handling.          Closes #79719||||[0, 0, 0, 0, 3, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 0, 0, 0]||||0||||0||||0
Adjust osprobe assertion for burst cpu (#86990)          When gathering v1 cgroup cpu stats, the file is expected to have 3     lines. However, if the burst feature of cpu accounting is enabled, it     will actually have 5 lines. This commit adjusts the assertion to allow     for the extra lines. We ignore these lines already in the parsing of the     calling method. Unfortunately this is not currently easy to test, and no     tests exist. Give it is just an assertion that is relaxing, I think it's     ok to fix this issue, and separately work on revamping the OsProbe     tests.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] adds start and end params to _preview and excludes cold/frozen tiers from unbounded previews (#86989)          n larger clusters with complicated datafeed requirements, being able to preview only a specific window of time is important. Previously, datafeed previews would always start at 0 (or from the beginning of the data). This causes issues if the index pattern contains indices on slower hardware, but when the datafeed is actually started, the "start" time is set to more recent data (and thus on faster hardware).          Additionally, when _preview is unbounded (as before), it attempts to only preview indices that are NOT frozen or cold. This is done through a query against the _tier field. Meaning, it only effects newer indices that actually have that field set.||||[0, 0, 0, 0, 13, 4, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 21, 0, 0, 6, 0]||||0||||0||||0
[TEST] Wait to lose master in Readiness tests (#86696)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Add libgraal thread leak filter (#86976)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[Refactor] Move classpath plugins to MockNode (#86914)          We only use classpath plugins in tests, so we should move code handling them to     our test framework. This PR introduces a new MockPluginsService in our test     framework. The MockPluginsService is constructed with a list of classpath     plugins that it will load by reflection. As before, these classpath plugins     won't have their own classloaders.          We have to construct the pluginsService early in the Node class constructor so     that MockNode methods can access it, but we have to do it after Node updates     its Settings argument. Therefore, instead of passing in classpath plugins as a     paramater, we are passing in a constructor function that takes a Settings     argument and returns a PluginsService. This lets us remove the classpath plugin     list from the production code entirely.          The MockPluginsService delegates almost everything to a real PluginsService,     overriding only the protected plugins() method and the info() method.          This commit also changes the PluginDescriptor.equals() method. We have long had     a todo comment for removing the version comparison and making two plugin     descriptors equal if and only if they have the same name. The original commit     that introduced version comparison between plugin descriptors was:          abf9a866788b2fab855b50728670e2aa2dd42c5a          The change did not seem to have a specific purpose in that commit, and no tests     guaranteed the behavior.          Closes #86635     ||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 0, 10, 0]||||0||||0||||0
Rename PluginInfo to PluginDescriptor (#86950)          The class PluginInfo represents the plugin-descriptor.properties file     that each plugin must have. This commit renames the class to more     closely match what it represents: the plugin descriptor.||||[0, 0, 0, 0, 5, 4, 0, 0, 0, 4, 0, 7, 2, 0, 0, 14, 0, 0, 0, 7, 0, 3, 4, 5, 0, 3, 23, 0, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 0, 12, 2, 1, 43, 29, 0, 2, 167, 0]||||0||||0||||0
Add `status` field to MultiSearchTemplateResponse (#85496)          This change adds a `status` field to MultiSearchTemplateResponse items,     as is already the case for MultiSearchResponse, making the two response     formats consistent.          Closes #83029||||[0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 2, 1, 5, 2, 0]||||0||||0||||0
Correctly keep master in master history if it was active at the beginning of the master history period (#86708)          This commit fixes a problem with the MasterHistory class. If we have had a single master for a week and then that     master went to null 5 seconds ago, we want to say that we have had a non-null master within the last 30 seconds.     However before this change, MasterHistory.hasSeenMasterInLastNSeconds(30) would return false in that case     because the non-null master had a start time much more than 30 seconds ago. This fix recognizes that a node is     master up until the start time of the master that replaces it. This required changing the methods that pruned the     master history based on time so that we do not prune masters that are in any way active during the time period.||||[0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 4, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 26, 0, 1, 1, 0]||||0||||0||||0
Add run-as support for OAuth2 tokens (#86680)          Authentication with an OAuth2 token can now perform run-as with changes     in this PR. This is in addition to the existing run-as support for realm     and API key authentication.          NB there are additional constraints on whether an OAuth2 token is     indeed qualified for run-as:     1. The token cannot itself cannot already be a run-as (this can happen when     the token is created using run-as and client_credentials grant)     2. The token cannot be created by anonymous or internal users          Service accounts cannot create tokens which meant run-as is not     supported for service accounts (none of existing service accounts     requires it anyway).     ||||[0, 0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 15, 7, 5, 16, 0]||||0||||0||||0
Modularize Elasticsearch (#81066)          This PR represents the initial phase of Modularizing Elasticsearch (with     Java Modules).          This initial phase modularizes the core of the Elasticsearch server     with Java Modules, which is then used to load and configure extension     components atop the server. Only a subset of extension components are     modularized at this stage (other components come in a later phase).     Components are loaded dynamically at runtime with custom class loaders     (same as is currently done). Components with a module-info.class are     defined to a module layer.          This architecture is somewhat akin to the Modular JDK, where     applications run on the classpath. In the analogy, the Elasticsearch     server modules are the platform (thus are always resolved and present),     while components without a module-info.class are non-modular code     running atop the Elasticsearch server modules. The extension components     cannot access types from non-exported packages of the server modules, in     the same way that classpath applications cannot access types from     non-exported packages of modules from the JDK. Broadly, the core     Elasticseach java modules simply "wrap" the existing packages and export     them. There are opportunites to export less, which is best done in more     narrowly focused follow-up PRs.          The Elasticsearch distribution startup scripts are updated to put jars     on the module path (the class path is empty), so the distribution will     run the core of the server as java modules. A number of key components     have been retrofitted with module-info.java's too, and the remaining     components can follow later. Unit and functional tests run as     non-modular (since they commonly require package-private access), while     higher-level integration tests, that run the distribution, run as     modular.          Co-authored-by: Chris Hegarty <christopher.hegarty@elastic.co>     Co-authored-by: Ryan Ernst <ryan@iernst.net>     Co-authored-by: Rene Groeschke <rene@elastic.co>||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 1, 0, 9, 0]||||0||||0||||0
[Test] Ensure generated username does not start nor end with a whitespace char  (#86965)          Closes #86955     ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 7, 0, 1, 4, 0]||||0||||0||||0
Propagate MapperBuilderContext across merge calls (#86946)          With #86166 we have added support for leaf fields that have dots in their names, without needing to expand their path to intermediate objects. That means that for instance a host.name keyword field mapper can be held directly by the root object mapper if the root has subobjects set to false.          This opens up for situations where a field name containing dots can't necessarily be split into a leaf name and a parent path made of intermediate object mappers. In the field mapper merge code, we build the full path of the merged field making that now incorrect assumption, which causes the result of merged leaf fields to have incorrect full path. This is a bug although it got unnoticed so far as the full path of a field mapper is not so widely used compared to its leaf name (returned by the simpleName method). One place where the full path is used is when sorting the child mappers in ObjectMapper#serializeMappers which was causing MapperService#assertRefreshIsNotNeeded to trip as the result of the merge has fields in a different order compared to the incoming mappings.          With this fix, we add a MapperBuilderContext argument to the different merge methods, propagate the MapperBuilderContext in all the merge calls and create a child context when needed, meaning whenever merging object mappers, so that their children mappers are created with the proper full path.||||[0, 0, 1, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 20, 0]||||0||||0||||0
Fix audit logging to consistently include port number in origin.address (#86732)          This commit changes audit logging of `connection_denied`     and `connection_granted` events in order to include a port number.          Closes elastic/elasticsearch#86694||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 0]||||0||||0||||0
fix: check field existence before trying to merge running stats (#86926)          * fix: check field existence before trying to merge running stats          All fields must coexist in the same docs for the stats to be     calculated correctly. As a result, we need to check existence of     the fields before trying to merge running stats.          Instead of collecting all field names into a collection we decided     to extract the field names from one of the maps. This saves us from     serialising/deserialising another collection and some backward     compatibility pain. This means also that we assume all maps     to hold the same set of keys and just chose one of them as the     candidate to extract keys (field names) from.          This is a fix for issue #73276.||||[0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix needless capturing lambda in analyzer wrapper (#86954)          Just a random thing I found when inspecting a heap dump that had ~100M     of these in it.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Avoid building duplicate FieldTypeLookup in MappingLookup Constructor (#86932)          If we don't have runtime fields we don't need to build this twice.     These are huge for something like Beats mappings and this change saves     about 400MB of heap per data node in the many shards benchmarks.||||[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 2, 0]||||0||||0||||0
Add support for CPU ranges in desired nodes (#86434)          This commit adds support for CPU ranges in the desired nodes API.          This aligns better with environments where administrators/orchestrators     can define lower and upper bounds for the amount of CPUs that the     desired node would get once deployed.          This allows to provide information about the expected CPU and possible     allowed overcommit that the desired node will run on.          This was the previous expected body for the desired nodes API (we still support it):     ```     PUT /_internal/desired_nodes/history/1     {     "nodes" : [     {     "settings" : {     "node.name" : "instance-000187",     "node.external_id": "instance-000187",     "node.roles" : ["data_hot", "master"],     "node.attr.data" : "hot",     "node.attr.logical_availability_zone" : "zone-0"     },     "processors" : 8,     "memory" : "58gb",     "storage" : "1700gb",     "node_version" : "8.3.0"     }     ]     }     ```          Now it's possible to define `processors` or `processors_range` as in:     ```     PUT /_internal/desired_nodes/history/1     {     "nodes" : [     {     "settings" : {     "node.name" : "instance-000187",     "node.external_id": "instance-000187",     "node.roles" : ["data_hot", "master"],     "node.attr.data" : "hot",     "node.attr.logical_availability_zone" : "zone-0"     },     "processors_range" : {"min": 8.0, "max": 16.0},     "memory" : "58gb",     "storage" : "1700gb",     "node_version" : "8.3.0"     }     ]     }     ```     Note that `max` in `processors_range` is optional.          This commit also moves from representing CPUs as integers to     accept floating point numbers.          Note: I disabled the bwc yamlRestTests for versions < 8.3 since we introduced     a few "breaking changes" but since this is an internal API it should be fine.||||[0, 0, 0, 0, 6, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 1, 5, 0]||||0||||0||||0
Lazy instantiate Cache in BitsetFilterCache (#86462)          An empty cache instance costs 50kb of heap. Lazy initializing the cache when needed     in this class comes with trivial overhead relative to the cost of using the cache     but can save hundreds of MB of heap on large data nodes.          relates #77466||||[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 7, 0, 2, 3, 0]||||0||||0||||0
Auto generate index.routing_path from mapping (#86790)          If no index.routing_path has been specified in the matching template or the component template that the template refers to then attempt to generate the index.routing_path index setting from the matching template's mapping or component template the template refers to.          Relates #74660||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 16, 0]||||0||||0||||0
Add access to internal representation of geo_point doc values (#86800)          Refactors GeoPoint docvalues wrappers to expose the internal SortedNumericDocValues||||[0, 0, 0, 0, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 1, 0, 2, 1, 1, 0, 0, 5, 9, 0, 0, 11, 8]||||0||||0||||0
Remove `MockSinglePrioritizingExecutor` (#86921)          `MockSinglePrioritizingExecutor` contains a hack that stops working with     JDK19 which introduces a different way to start threads. This commit     removes the hack and captures the tasks to be executed as they're passed     to the executor instead.          It turns out this hack was also apparently swallowing some tripping     assertions, so this commit fixes those assertions.          Closes #86880||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0]||||0||||0||||0
User Profile - hash only username for profile uid (#86916)          This PR changes the profile uid calculation to hash only the username     and removes any use of domain/realm information. This means any users     with the same username now has the same base uid, which will still be     differentiated by the numerical suffix.          The reasons for this change are:     1. Make profile uid generation resistant to domain name or composition     changes. Initially the predictable uid is only necessary for the     moment of creation. But we now agree that there are benefits for this     UID to be predictable in longer terms.     2. Allow a ESS-like experience where username is always unique and hence     a 1-to-1 relationship between username and profile uid is desirable.     If users can provide the same unique username guarantee with their     own identity management system, they will be able to have the     ESS-like experience.     ||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0]||||0||||0||||0
[Test] Increase length of test password for FIPS (#86948)          Password must be at least 114 bits in FIPS mode. This PR fixes the     password length in the new ServerCliTests so it passes in FIPS mode.          Relates: #85758          PS: The test     [failed](https://gradle-enterprise.elastic.co/s/mrlw6o27onxee/tests/:distribution:tools:server-cli:test/org.elasticsearch.server.cli.ServerCliTests/testKeystorePassword)     on my PR CI.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Handle windows scripts invoked without .bat (#86944)          On Windows cmd, one can invoke `myscript.bat` by just typing `myscript`.     This commit adjusts the CliToolLauncher to account for this case, making     the .bat stripping to find the toolname conditional.          closes #86940||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0]||||0||||0||||0
Move pidfile handling to server cli (#86934)          Now that the server cli is in java, we can do more system level things     inside it. This commit moves validating and writing the pidfile into the     server cli. One benefit is we get validation of directory/file problems     up front before even trying to start the ES process.||||[0, 0, 0, 0, 5, 0, 1, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 25, 4, 9, 3, 14, 0]||||0||||0||||0
Rename NodeEnvironment.NodePath to DataPath (#86938)          The NodePath inner class of NodeEnvironment represents path.data entries     of the node. The name however is sometimes confusing since these are the     data paths, and there is normally no singular concept of "node path" (an     installation has several different paths). This commit renames NodePath     to DataPath, as well as all methods and variables referring to it, so     that the more general term "node paths" can be utilized for something     node wide: the paths in environment (in a future PR).||||[0, 0, 0, 1, 1, 0, 0, 0, 6, 4, 1, 0, 0, 0, 0, 29, 0, 0, 0, 6, 0, 10, 11, 11, 0, 6, 5, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 4, 0, 0, 2, 2, 0, 0, 159, 0]||||0||||0||||0
Allow serial_diff under min_doc_count aggs (#86401)          Before 6.6 we allowed the `serial_diff` agg in lots of places, including     under `date_histogram` aggregations with `min_doc_count: 1`. This     allowed you to take the difference of two adjacent buckets, skipping any     that don't have any value. So if you have a value at 10am, no value at     11am, and another at noon the `serial_diff` will diff the 10am and noon     values. In 6.6 we disabled support for this. We'd like it back.||||[0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 9, 0]||||0||||0||||0
Speed up building RoutingTable from RoutingNodes (#86903)          We do the routing nodes -> routing table step during reroute and it's a significant contributor     to the runtime of reroute.     The PR speeds it up by more than double in the common one shard + one primary case by saving the expensive     and slow-to-iterate hashmap keyed by shard id, the needless precomputation of the allocation ids set     and a redundant round of building `IndexShardRoutingTable` in `addShard`.          This gives us another 2-3% speedup on the initial indices bootstrap in the many-shards benchmark.     ||||[0, 0, 0, 0, 5, 1, 1, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 32, 44, 0, 7, 60, 0]||||0||||0||||0
Replace most shell script logic with Java (#85758)          Elasticsearch provides several command line tools, as well as the main script to start elasticsearch. While most of the logic is abstracted away for cli tools, the main elasticsearch script has hundreds of lines of platform specific shell code. That code is difficult to maintain because it uses many special shell features which then must also exist in other platforms (ie windows batch files). Additionally, the logic in these scripts are not easy to test, we must be on the actual platform and test with a full installation of Elasticsearch, which is relatively slow (compared to most in process tests).          This commit replaces logic of the main server script, as well as the windows service management script, with Java. The new entrypoints use the CliToolLauncher. The server cli figures out all the jvm options and such necessary, then launches the real server process. If run in the foreground, the launcher will stay alive for the lifetime of Elasticsearch; the streams are effectively inherited so all output from Elasticsearch still goes to the console. If daemonizing, the launcher waits around until Elasticsearch is "ready" (this means the Node startup completed), then detaches and exits.          Co-authored-by: William Brafford <william.brafford@elastic.co>||||[0, 0, 0, 0, 14, 4, 0, 1, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 18, 4, 0, 0, 0, 0, 0, 0, 30, 27, 1, 1, 19, 0]||||0||||0||||0
Make user and role name constraint consistent with max document ID. (#86728)          This change tries to make user and role name constraints consistent with     what is currently allowed to store in the native realm (512).     Because the document IDs are prefixed by either `user-` or `role-`,     the actual possible max length is a funky looking 507 chars.     If we choose (in the future) to allow more than 507 chars we should     either consider increasing the max allowed size for document ID or     consider hashing names longer than 507 in order to fit into document ID.          Closes elastic/elasticsearch#66020||||[0, 0, 0, 0, 17, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 1, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 19, 2, 2, 16, 0]||||0||||0||||0
Fix clearing of lastSuccessfulAuthCache when clear all realm cache API is called (#86909)          This commit adds missing call to clear last successful authentication cache,     when clear all realm cache action is called.          Closes #86650          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]||||0||||0||||0
[Refactor] Extract method for mandatory plugins check (#86906)          This commit factors out a checkMandatoryPlugins method     so we can keep test coverage without using the classpath     plugin code path, which will soon be moved to MockNode.          I also couldn't resist using set logic instead of for-loop list     building for the check itself.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 2, 0, 0, 0, 0]||||0||||0||||0
[Refactor] Move plugin setting merge method from PluginsService to Node (#86891)          The PluginsService#updatedSettings method was only used once in the Node constructor, so it makes sense to make that a utility method on the Node class. We make it testable by factoring out the PluginsService, instead providing a map of names to plugins as an argument.          This commit also adds test coverage to verify that we reject two plugins with the same name when loading from disk.||||[0, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Fix max_primary_shard_size resize factor math (#86897)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 10, 0]||||0||||0||||0
Use default hash setting helper in ApiKeyService (#86845)          Small refactor to re-use the default stored hash setting helper.          Missed this in #86146.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Don't download geoip databases if geoip system index is blocked. (#86842)          For example in the case that the a cluster is running out of disk     space and indices reject writes.          This can otherwise load to unnecessary error logs being printed and     just add to more instability. Instead, the GeoIpDownloader should     just try to download the files the next it runs.||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 10, 0, 0, 0, 0]||||0||||0||||0
Strengthen testIncorrectHeaderHandling (#86886)          Enhances this test to cover more combinations of present/absent headers,     and makes the fake REST request immutable to align it with the     production implementation.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 1, 9, 0]||||0||||0||||0
Simplify CellIdSource classes used in GeoGrid aggregations (#86806)          small refactor to share some common code.||||[0, 0, 0, 1, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 6, 15, 9, 0, 0, 0, 0, 0, 0, 12, 3, 0, 0, 0, 0]||||0||||0||||0
SQL: Fix FORMAT function to better comply with Microsoft SQL Server specification (#86225)          ||||[0, 0, 0, 0, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 12, 0]||||0||||0||||0
Fix compilation for (#86591)          The above PR was merged concurrently to another one that refactored     a method name.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add text field support to archive indices (#86591)          Adds support for "text" fields in archive indices, with the goal of adding simple filtering support on text fields when     querying archive indices.          There are some differences to regular text fields:          - no global statistics: queries on text fields return constant score (similar to match_only_text).     - analyzer fields can be updated     - if defined analyzer is not available, falls back to default analyzer     - no guarantees that analyzers are BWC     The above limitations also give us the flexibility to eventually swap out the implementation with a "runtime-text field"     variant, and hence only provide those capabilities that can be emulated via a runtime field.          Relates #81210||||[0, 0, 0, 3, 2, 3, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 10, 0, 2, 10, 0]||||0||||0||||0
Convert Metadata templates return type to Map (#86776)          The methods for getting templates from Metadata expose the underlying     ImmutableOpenMap, but the callers all just need a Map. This commit     converts the return type of these methods and adjusts the few places     assuming it was an ImmutableOpenMap.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 6, 2, 1, 0, 10, 0]||||0||||0||||0
Upgrade to lucene snapshot 978eef5459c (#86852)          Final (hopefully!) snapshot before the 9.2.0 release          * Update test to expect persian tokenfilter - will be exposed later     * Fix KnnVectorQueryBuilderTests::doAssertLuceneQuery          Co-authored-by: Mayya Sharipova <mayya.sharipova@elastic.co>||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0]||||0||||0||||0
Soft-deprecation of point/geo_point formats (#86835)          * Soft-deprecation of point/geo_point formats          Since GeoJSON and WKT are now common formats for all three types:     geo_shape, geo_point and point     We decided to soft-deprecate the other point formats by ordering:     * GeoJSON (object with keys `type` and `coordinates`)     * WKT `POINT(x y)`     * Object with keys `lat` and `lon` (or `x` and `y` for point)     * Array [lon,lat]     * String `"lat,lon"` (or `"x,y"` in point)     * String with geohash (only in `geo_point`)          The geohash is last because it is only in one field type.     The string version is second last because it is the most controversial     being the only version to reverse the coordinate order from all other     formats (for geo_point only, since the coordinates are not reversed     in point).          In addition we replaced many examples in both documentation and tests     to prioritize WKT over the plain string format.          Many remaining examples of array format or object with keys still exist     and could be replaced by, for example, GeoJSON, if we feel the need.          * Incorrect quote position||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[Refactor] Make PluginBundle package-private (#86863)          Our plugin loading code uses the PluginBundle class to describe a plugin on     disk. This should be an implementation detail of the plugin loading code, and     not part of the API shared with the plugin CLI.          * Refactor to hide internal code from Plugin CLI     * Add javadoc||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 2, 6, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 1, 0, 0, 2, 0]||||0||||0||||0
Script: Fix setter shortcut for unbridged setters (#86868)          The setter shortcut resolution worked for bridged setter methods, in `PainlessLookupBuilder.cacheRuntimeHandles`, but did not work for other setters.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Guard cursor for journalctl command in packaging tests (#86820)          It is possible for the cursor from journalctl to be empty, perhaps if     the log is empty. This commit guards the getLogs command line to only     add the --after-cursor if a non empty cursor exists, otherwise     journalctl raises an error.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 0, 0]||||0||||0||||0
Authorize painless execute as index action when an index is specified (#85512)          Painless execute allows users to validate their scripts. Some of the supported script contexts     support providing a sample document as well as an index to pull the mappings from.          The painless execute API requires cluster admin privileges today and while that's ok for the contexts that     don't support providing an index, it is not ideal when an index is provided. In fact users can run scripts     as part of the search API, which requires only the indices/read privilege on the indices that the users     is reading from.          This commit maps the painless execute action to an indices/read action when an index is specified, so that in     that case the same privileges as a search action will be requested to run painless execute.          Relates to #48856     Closes #86428||||[0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0]||||0||||0||||0
Rename IndicesService#createIndexMapperService() method (#86851)          Rename from `createIndexMapperService(...)`` to `createIndexMapperServiceForValidation(...)`          Followup from #86790||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]||||0||||0||||0
Add reminder to add BWC codecs on major version upgrade (#86844)          Codifies the requirement to add Lucene BWC codecs and corresponding tests when upgrading Elasticsearch to the next major version.          Relates #81210||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add support for dots in field names for metrics usecases (#86166)          This PR adds support for a new mapping parameter to the configuration of the object mapper (root as well as individual fields), that makes it possible to store metrics data where it's common to have fields with dots in their names in the following format:          ```     {     "metrics.time" : 10,     "metrics.time.min" : 1,     "metrics.time.max" : 500     }     ```          Instead of expanding dotted paths the their corresponding object structure, objects can be configured to preserve dots in field names, in which case they can only hold leaf sub-fields and no further objects.          The mapping parameter is called subobjects and controls whether an object can hold other objects (defaults to true) or not. The following example shows how it can be configured in the mappings:          ```     {     "mappings" : {     "properties" : {     "metrics" : {     "type" : "object",     "subobjects" : false     }     }     }     }     ```          Closes #63530||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 4, 0]||||0||||0||||0
Fix mvt polygon orientation (#86555)          This commit forks the method we use in JTSAdapter to generate the vector tile feature containing the right logic     for polygon orientation.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 7, 0]||||0||||0||||0
Support geo label position through REST vector tiles API (#86458)          Support label position in REST vector tiles          There is a need to provide sensibly calculated label positions for polygons and lines in Kibana maps. A very convenient way to satisfy this need is through a runtime field that the rest API can make use of when labels are requested. This has the advantage of providing painless access to the label position as well.          This  work adds support for the REST API to provide label positions to MVT queries, both for the HITS layer and the AGGS layer. To enable this feature, set with_labels to true as a query parameter to the vector tile search query.||||[0, 0, 0, 0, 5, 4, 1, 0, 0, 0, 0, 0, 4, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 39, 0, 6, 6, 0]||||0||||0||||0
Update gradle JavaPlugin to support generating javadoc for modules (#86781)          This change updates the JavaPlugin to support generating javadoc for modules, i.e. ensure that modular dependencies can be found on the module path.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Skip redundant mapping by hash GC in Metadata.Builder (#86830)          No need to check for mappings to GC if we didn't remove any use of any mapping.     Saves ~4% overall on the many-shards benchmarks initial indices bootstrap.     ||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 6, 0, 1, 0, 0]||||0||||0||||0
Remove elasticsearch.rest-test gradle plugin (#85491)          Removes and remaining usages of `elasticsearch.rest-test` and the plugin itself from the codebase          Relates to https://github.com/elastic/elasticsearch/issues/63696||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Skip redundant name collision check in metadata build (#86829)          No need to check for name collisions when we are reusing the indices lookup     and have checked that we didn't change any naming.     -> saves us another percent on CS updates around reroute||||[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 3, 0]||||0||||0||||0
Removing Blocking Wait for Close in RecoverySourceHandler (#86127)          Remove the blocking wait when releasing safe commits or store references on the recovery source.     This seems safe enough these days with https://github.com/elastic/elasticsearch/pull/85238 not tripping     and the assertion that makes sure we never submit the close task to an already shut-down pool          closes #85839||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Ensure authentication is wire compatible when setting user (#86741)          The SecurityServerTransportInterceptor class is responsible for writing     authentication header in a wire compatible format before the request     leaving the local node. However, a bug made it ignore the wire version     when setting user based on the action origin. This PR fixes it and adds     relevant tests.          It is an old bug but never manifested itself previously because (1) the     code path is rare enuough and (2) authentication didn't have any version     difference till 8.2.          Resolves: #86716     ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 0]||||0||||0||||0
The Authentication class is now final (#86544)          This PR marks the Authentication class to be final which is the last     step of locking down the Authentication class. The Authentication class     is basically a record class and it has internal logics on what values     can or cannot be used together. We don't expect it to be extended by any     subclasses and a concrete object should always be created for tests     instead of mocking.          Relates: #86424     Relates: #86206||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0]||||0||||0||||0
[Test] Fix authentication randomisation for operator check (#86535)          Internal users bypass operator check. So we should not use them for     operator check test.          Relates: #86424     Resolves: #86530||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Fix Terminal flushing and make api consistent (#86808)          This commit fixes the PrintWriters created by Terminal to use     autoflushing. It also fixes prompting to flush the error stream after     writing. Finally, it makes the APIs more consistent by adding getters     for verbosity and reader so that subclasses of Terminal can fully wrap     and existing terminal.          relates #85758||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0]||||0||||0||||0
Improve debug logging in packaging tests (#86809)          When the Elasticsearch log file cannot be moved during packaging test     cleanup, it usually means the Windows Elasticsearch process is still     running. This commit moves the code to dump all available log     information out to a separate dumpDebug() method and utilizes it when     a failure ocurrs moving the log file.          relates #85758||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use Network Recycler for Rest Responses (#82093)          Same as #80111 but for the REST layer.||||[0, 0, 0, 0, 1, 7, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 5, 0, 0, 6, 9, 0, 1, 23, 0]||||0||||0||||0
Endpoint events - give `kibana_system` privs to index template, not backing indicies. (#86797)          * Endpoint events - give privs to index, not datastream.          * Update tests.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0]||||0||||0||||0
Wildcard support in Logstash pipelines search API. (#85847)          * Wildcard support in Logstash pipelines search API.          * Code review improvements: patter compile repetition fixed, descriptive naming hit counts, failure check before putting the result into result map.||||[0, 0, 0, 0, 4, 3, 3, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 13, 1, 3, 3, 0]||||0||||0||||0
[ML] [Transforms] prefer secondary auth headers for transforms (#86757)          When creating and updating transforms, it is possible for clients to provide secondary headers.          When PUT, _preview, _update is called with secondary authorization headers, those are then used or stored with the transform.          closes: https://github.com/elastic/elasticsearch/issues/86731||||[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 19, 5, 0, 0, 7, 0]||||0||||0||||0
Use ESTestCase in server cli tests (#86783)          This commit removes the LaunchersTestCase in favor of ESTestCase.          relates #85758||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0]||||0||||0||||0
[Refactor] Flexible general actions over plugins in PluginsService (#86642)          PluginsService had a handful of methods that simply called a method from     the Plugin superclass for every plugin in the plugin service. Here, we     refactor this logic out to the call sites by adding flexible, generic     methods for applying actions to all plugins.          We also find places in the Node class that were using     filterPlugin(Plugin.class) to accomplish the same thing, and replace     those usages with these new methods.||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Synthetic source: More docs (#86766)          Adds lots of javadocs to the synthetic source innards.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[Transform] Support `range` aggregation in transform (#86501)          ||||[0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 1, 2, 0]||||0||||0||||0
Save redundant singleton maps in field mappers (#86785)          In the many-shards benchmarks the singleton maps storing just a single     analyzer for each keyword field mapper cost around 5% of the total heap     usage on data nodes (700MB for ~15k indices which translate into ~16M instances     of keyword field mapper for Beats mappings).     Creating specific implementations for the zero, one or many analyzers     use cases that already have their own specialized constructors eliminates this     overhead completely.          relates #77466||||[0, 0, 1, 0, 14, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 1, 0, 0, 0, 0, 0, 0, 3, 18, 0, 0, 22, 0]||||0||||0||||0
Simplify Netty4HttpPipeliningHandler (#86791)          No need to collect responses into an intermediary list, we can write them directly     as they become writable. Also, we can be more efficient for the common case where the response written is of the     right sequence number and write it out directly.     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 14, 0, 2, 1, 0]||||0||||0||||0
[ML] [Transforms] fix transform _start permissions to use stored headers in the config (#86802)          It was previously required that the _start API caller required the same roles as the create API caller.          This does not make sense as when the transform is actually running (after _start) we rely solely on the roles of the caller who created the transform.          Consequently, this commit does the permission validations and various checks with the roles of user who created the transform, not the one calling _start||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 9, 0]||||0||||0||||0
Port SymbolicLinkPreservingTarIT to spock (#86758)               Part of #86720||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add points metadata support for archive indices (#86655)          Archive indices appear just as regular indices in a cluster, and can be part of index patterns when queried. To allow     searches to quickly skip shards of archive indices that might not have relevant data, we're adding support for skipping     shards of archive indices here that don't have data falling in the time range being queried. This is critical for the Kibana     experience which relies on the date range picker to quickly skip some of the indices in an index pattern.          Doing the actual time-range query on the archive index is much more expensive as on a regular index (as it's using doc     values instead of points to run the query, equating to a full scan of the columnar data). The solution here is to make     points metadata available in archive indices, so that the minimum and maximum value can be retrieved in constant time     (only a tiny fraction of the full points capabilities).||||[0, 0, 0, 0, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 0, 7, 0]||||0||||0||||0
Move RestWrapper to interceptor.RestInterceptor (#86784)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Port buildResources func tests to spock (#86756)          Unify our build tool testing          Part of #86720||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[Osquery] Extend kibana_system role with an access to osquery_manager… (#86609)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 4, 0]||||0||||0||||0
Flatten Netty4 http pipeline handlers into a single handler (#86133)          This sets up the implementation of chunked REST response encoding     that will be able to send large responses without serializing them     in full on heap upfront.     Having all the steps of sending a response in one place together with     the pipelining logic allows adding another response type that serializes     on the transport threads alongside `Netty4HttpResponse` in a follow-up     that will only require changes to `Netty4PipeliningHandler`.     Also, this change in isolation saves loads of indirection and now (that the NIO     transport is gone) redundant abstractions, making the path of sending a REST     response all around easier to follow.     ||||[0, 0, 0, 0, 9, 10, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 7, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 1, 2, 0, 0, 0, 1, 0, 0, 10, 18, 0, 0, 21, 0]||||0||||0||||0
Add a Gradle Plugin for compiling modular source projects. (#86602)          This PR upstreams a custom Gradle Plugin for compiling modular source     projects, that we've been using for a while now over on the modules     branch. The Plugin infers which dependencies should be on the module     path and which dependencies should be on the class path, when compilng     the main java sourceset. This supports the "bottom up" modularization of     Elasticsearch, where parent projects are modularized before child     projects. Allowing to modularize the core of the server independently of     the extension components, that can themselves be modularized later.          With this plugin various subprojects can be modularized (by adding a     module-info.java in the source root) with minimal fuss - no custom     gradle logic is required by the subproject, beyond a couple of     subproject specific compiler lint suppressions.          The inference in the plugin is driven by walking the project     dependencies, searching for the presence of a module-info.java,     afterwhich all subprojects will be put on the module path. Again, this     supports "bottom up" modularization.          Co-authored-by: ChrisHegarty <christopher.hegarty@elastic.co>     Co-authored-by: Mark Vieira <portugee@gmail.com>     Co-authored-by: Ryan Ernst <ryan@iernst.net>     Co-authored-by: Rene Groeschke <rene@breskeby.com>||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Expand jar hell to include modules (#86622)          Expands jar hell to include modules from the system class loader.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 12, 0]||||0||||0||||0
Fix the test framework codebase name (#86777)          A side effect of https://github.com/elastic/elasticsearch/pull/86706 was     unintentionally renaming the test framework jar. This commit reverts the     jar name to the horrible named "framework", and adjusts the test     security manager bootstrap to account for the name.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Suppress ExtrasFS in plugins utils tests (#86763)          We suppress ExtraFS in the class from which these tests were copied, so     we need to suppress them here as well.          See also: 5c8d5677a4691afcf06b9717cf8e9fb6d252c727||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Primary system indices should be write indices for system aliases (#85977)          Whenever we create a system index whose descriptor     has an alias, we add the alias. If the system index is the primary     index, we make it the write index for the alias.          Co-authored-by: Elastic Machine <elasticmachine@users.noreply.github.com>||||[0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 26, 1, 1, 4, 0]||||0||||0||||0
More cleanup on reaper tests (#86762)          - Remove duplicate files.     - Move to build-tools||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Reindex support for TSDB creating indices (#86704)          This teaches reindex to infer if the destination index is a tsdb index     if it doesn't yet exist. It looks at the templates that apply to the     index and checks what settings they use. So you should be able to     reindex into a non-existant index and automatically get the tsdb     support.||||[0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 6, 0, 0, 2, 0]||||0||||0||||0
Mute PluginsUtilsTests     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] Autoscaling fixes and additional debug logging (#86590)          Fixes the following problems in autoscaling:          1. Divide by zero error when scaling up from zero     2. Given JVM size rounding, we'd sometimes choose a node that     was 1-3MB bigger than necessary, potentially leading to an     unnecessarily large scale-up     3. The per-node overhead was being added to required size twice     4. Improve the reason when a cluster with no ML nodes decides     it still needs no ML nodes     5. Now consider free memory at current scale when scaling up          Also adds more debug logging so we can get visibility of     what happens in deployed Cloud clusters when necessary.          Followup to #86399||||[0, 0, 0, 0, 5, 2, 0, 1, 0, 0, 0, 4, 29, 0, 9, 4, 0, 0, 2, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 44, 68, 8, 7, 82, 0]||||0||||0||||0
Remove accidentally added files not in use yet     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use pipes for spawned controllers (#86709)          Controller processes currently inherit stdout/stderr streams from     the main Elasticsearch process. This isn't horrible when we run in the     foreground, but when we daemonize, the open pipe causes the underlying     file descriptor to stay open, even though we have closed the stream     within Elasticsearch.          This commit changes the controller spawner to pipe stdout/stderr, and     creates pump threads.          relates #85758||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 0, 0, 3, 0]||||0||||0||||0
TokenService decode JWTs, change warn to debug (#86498)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Add annotation for disabling security manager in tests (#86706)          The Elasticsearch test framework initializes a test security manager, so     that tests run in a similar environment to that which we run in     production. However, some tests need to run without security manager     because they do "evil" things, like setting adding and removing jvm wide     shutdown hooks. Currently these tests must exist in separate projects,     mostly under qa/evil-tests, so that the security manager can be disabled     for the entire jvm with the tests.security.manager system property. The     separation between these tests and the other tests for the server makes     development of these tests more difficult, especially the inability to run     these within IntelliJ without manually adding additional sysprops.          This commit adds a new mechanism to disable security manager for these     tests. A new `@NoSecurityManager` annotation can be added to a test     suite. ESTestCase detects this annotation and removes the security     manager for the duration of that test suite. We could potentially allow     this per test as well, but I started with the simple suite wide     strategy. One example test is converted. The rest will be converted in     followups.||||[0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Correctly calculate disk usage for frozen data tier telemetry (#86580)          The telemetry for data tiers was using the size in bytes, however, for     the frozen tier using searchable snapshots, this was the disk usage     rather than the size of the actual data.          This commit changes the telemetry to use `total_data_set_size` as     introduced in #70625 so that the telemetry is correct.          Resolves #86055||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0]||||0||||0||||0
Move static plugin loading methods from PluginsService to util class (#86701)          * Move static plugin loading methods to util class          We had a set of utility methods in PluginsService that were public and     static so that the plugin cli tool could use them. Here, we move those     methods to a utility class so that the plugin CLI doesn't need to import     PluginsService. For the same reason, we also move     "PluginsService.Bundle" to a top-level class called "PluginBundle."     Finally, we move tests to the appropriate test classes.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 4, 31, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 0]||||0||||0||||0
[ML] Express lane inference (#86571)          Adds an (internal) option to prioritise certain inference requests over others     allowing those requests to skip the queue. Ordering is handled by a PriorityQueue.||||[0, 0, 0, 0, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 5, 0, 0, 10, 0]||||0||||0||||0
User Profile - add caching for hasPrivileges check (#86543)          This PR adds a new cache for hasPrivileges checks so that the same check     for the same role is short-circuited for performance. The new cache is     attached to Role. Since role itself is cached, we avoid having to manage     the new cache lifecyle separately, e.g. exposing new clear cache     endpoint etc.          As discussed, the cache is currently only applied to simple named roles,     i.e. it works for regular users but not API keys. This is acceptable for     now since API keys cannot have user profiles.     ||||[0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0]||||0||||0||||0
Grants `kibana_system` reserved role access to Endpoint event streams. (#86702)          * Grants  reserved role access ep event streams.          * Fix test for over permissions.          * Add an additional test.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0]||||0||||0||||0
Make InternalTestArtifactBasePlugin rely on JavaBase plugin explicit (#86719)          The InternalTestArtifactBasePlugin relies on the javabase plugin as it     requires SourceSets and JavaBaseExtensions when in use. This change     makes this explicit allowing using the plugin without any other plugin     applied||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Fix javadoc plugin func tests on windows (#86674)          Handle special javadoc options path format||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0]||||0||||0||||0
Simplify reaper tests to use spock (#86721)          related to #86720||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Port QA projects to use javaRestTest and yamlRestTest (#86703)          Do not use deprecated elasticsearch.rest-test plugin||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Move DataStreamMetadata update code into DatastreamMetadata class (#86718)          Follow up to #86673 hiding the immutable open map implementation details from the public interface     of this class.||||[0, 0, 0, 0, 3, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 42, 2, 0, 2, 5, 0]||||0||||0||||0
Enhance the migrate to tiers action message (#86573)          This instructs the users to first stop ILM before calling the     migrate to tiers API.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Simplify entry creation (#86430)          Replace AbstractMap.SimpleEntry with a factory call that creates an     immutable entry.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Remove remaining single arg ParameterizedMessages (#86715)          This commit removes the remaining ParameterizedMessages that take a     single argument, this time where the argument contains method calls.     This was again done almost entirely through find/replace with regex in     IntelliJ.          relates #86549||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 139, 0]||||0||||0||||0
Role APIs allow internal role names (#86604)          Internal users have internal role names associated with them (e.g.,     _system and _xpack). Currently, these role names are "reserved" in     that end-users can't create roles with clashing names. This PR removes     this restriction. The reasoning is similar to #86326:          For one, internal role names are not directly used during     authorization. Authorization for internal users follows a separate     path, leveraging the role descriptor that each internal user defines     directly. As such, internal roles and end-user defined roles do not     interfere with each other.          By removing the restriction, the PR decouples the implementation     details of internal users from our end-user APIs, which allows us to     evolve these details without introducing breaking changes.          Closes #86480||||[0, 0, 0, 0, 11, 0, 2, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 96, 22, 2, 11, 24, 0]||||0||||0||||0
Use ImmutableOpenMap for DatastreamMetadata to speed up DS operations (#86673)          This is orders of magnitude faster than the immutable JDK map operations.||||[0, 0, 0, 0, 0, 4, 1, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 22, 0]||||0||||0||||0
[Test] Ensure all requests are scheduled before testing cancellation (#86653)          The shard search request can sometimes be slow. If it is stuck before it     is even scheduled by the task manage, the subsequent cancellation gets     stuck too. This PR adjust the assertions so that it fails earlier in     this situation rather than later which results into a more confusing     error message. It also double the wait time to help the sometimes slow     test suites.          Resolves: #86565||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Convert most single arg parameterized message to direct strings (#86649)          This commit converts most ParameterizedMessages which take one argument     to direct logging messages. This was done with regex search/replace in     IntelliJ. It does omits if those single arguments have any parenthesis     (cast or method call). Those will be done in a followup.          relates #86549||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 1, 210, 0]||||0||||0||||0
TSDB: Initial reindex fix  (#86647)          It turns out that there is a fairly simple recipe for reindexing to a     `time_series` index:     1. If you are reindexing from a time series index to a time series index     and *not* changing the `@timestamp` or dimensions it "just     works"(TM).     2. If you are reindexing from a standard index with a standard random     `_id` you should clear it on reindex.     3. If you are reindexing from tsdb index to a tsdb index and modifying a     dimension or `@timestamp` then you should clear the `_id`.          This is not pleasant to have to remember. But it doesn't crash!          * TSDB: Initial reindex fix          This teaches reindex the smallest thing that it needs to know about     tsdb: `_id` is automatically generated. Armed with that knowledge     reindex now doesn't attempt to copy the `_id` when writing to a tsdb     index.          Important: If the index doesn't yet exist it will *assume* that the     index will be created in `standard` mode. We can detect what mode it     *should* be created with in a follow up change.     ||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Port all remaining xpack plugin projects away from deprecated rest-test plugin (#86626)          - Use internal java rest test or internal yaml rest test plugin instead          This is part of https://github.com/elastic/elasticsearch/pull/85491/||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Avoid breaking add/clear voting exclusions (#86657)          Adding and clearing voting exclusions is part of the steps an operator/orchestration     will take to change topology of a cluster. It is therefore important that as much as     possible these do not fail, and we therefore now bypass the circuit breaker for the     associated rest and transport actions.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
[ML] Make autoscaling and task assignment use same memory staleness definition (#86632)          Previously autoscaling used a staleness definition of ~7 minutes     and task assignment used a staleness definition of ~90seconds.          This could lead to the assignment explanation of tasks not being     "awaiting lazy assignment" at the moment when autoscaling ran,     thus preventing an autoscaling decision being made.          The solution is to always use the same definition of staleness in     the memory tracker. This is set to the maximum of what the two     interested parties suggest.          Fixes #86616||||[0, 0, 0, 0, 4, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 4, 0, 0, 10, 0]||||0||||0||||0
Add master_timeout support to voting config exclusions APIs (#86670)          Today the add/clear voting config exclusions APIs route a request to the     master node but do not expose the usual `?master_timeout` parameter     allowing to change the timeout for this phase of execution. This commit     adds the missing parameter.||||[0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 5, 0]||||0||||0||||0
Reroute after migrating to data tiers routing (#86574)          ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]||||0||||0||||0
[ML] Fix max_model_memory_limit reported by _ml/info with autoscaling (#86660)          Previously the _ml/info endpoint took account of lazy nodes that     were not added to the cluster, but didn't take account of the     possibility of lazy nodes already in the cluster being able to     scale up to a larger size. This meant that the UI could incorrectly     cap the model_memory_limit that could be configured for new jobs     in autoscaling Cloud clusters where the tier limit meant only one     node per availability zone was possible. This PR fixes that case.          Fixes elastic/kibana#131954||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0]||||0||||0||||0
Use TaskCancelledException in TMNA (#86659)          In #72157 we made it so that cancelling the task that a     `TransportMasterNodeAction` was executing causes the action to fail with     a `java.util.concurrent.CancellationException`. This exception is     treated as a `500 Internal Server Error` which results in `WARN`-level     logs, but cancelling a task is normal and expected behaviour and should     not be logged (see #73524).          This commit fixes this by using a `TaskCancelledException` instead,     since this exception maps to a `400 Bad Request` and generates no logs.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0]||||0||||0||||0
Port gradle docs test plugin to use internal yaml rest test plugin (#86598)          Remove usage of deprecated elasticsearch.rest-test in DocsTestPlugin          we keep some files in src/test in docs projects as moving them would require more changes     in build-docs project outside this repository||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Get hidden indices stats in `GET _cat/shards` (#86601)          Passes a permissive `IndicesOptions` to the indices stats request used     within `GET _cat/shards` so that it retrieves stats for hidden indices     by default.          Also passes the same `IndicesOptions` to the cluster state request so     that the two requests get consistent sets of indices.          Also parallelises the two requests since there's no dependency between     them.          Closes #84656          Also relates #32238 since the more permissive `IndicesOptions` used here     permits closed indices, which means `GET _cat/shards` will not throw an     exception in security-enabled clusters containing closed indices behind     aliases.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0]||||0||||0||||0
Convert no arg parameterized message to direct strings (#86631)          This commit converts all ParameterizedMessages which take no arguments     to direct logging messages. There is no need for lazy evaluation since     these strings are static.          relates #86549||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0]||||0||||0||||0
Refactor code to avoid JDK bug: JDK-8285835 (#86614)          Refactor code in DateHistogramAggregator$FromDateRange::adapt     to avoid OpenJDK C2 compiler crash with JDK 18.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 0]||||0||||0||||0
Update painless lookup for modules (#86625)          When we move to modules, public lookup has only access to public members     of exported packages. For painless itself this is not sufficient to     lookup public members within its own module, since painless need not     export all of the packages that it requires access too.          The solution is to use a lookup that holds the MODULE mode for self     introspection.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0]||||0||||0||||0
Remove ImmutableOpenMap from GetIndexResponse (#86624)          This commit converts the maps exposed from GetIndexResponse to Map.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 7, 0]||||0||||0||||0
[ML] Rename threading params in _start trained model deployment API (#86597)          When starting a trained model deployment the user can tweak performance     by setting the `model_threads` and `inference_threads` parameters.     These parameters are hard to understand and cause confusion.          This commit renames these as well as the fields where their values are     reported in the stats API.          - `model_threads` => `number_of_allocations`     - `inference_threads` => `threads_per_allocation`          Now the terminology is as follows.          A model deployment starts with a requested `number_of_allocations`.     Each allocation means the model gets another thread for executing     parallel inference requests. Thus, more allocations should increase     throughput. In its turn, each allocation is may be using a number     of threads to parallelize each individual inference request.     This is the `threads_per_allocation` setting and increases inference     speed (which might also result in improved throughput).||||[0, 0, 0, 0, 11, 12, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 4, 10, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 10, 0, 0, 0, 0, 0, 0, 22, 22, 4, 0, 48, 0]||||0||||0||||0
Hide ImmutableOpenMap in IndexMetadata (#86589)          IndexMetadata has several ImmutableOpenMaps in its implementation.     However, the getters for those members expose ImmutableOpenMap when Map     works just fine. This commit changes the return types of these methods     from IndexMetadata, so that the IndexMetadata implementation can be     changed independently.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Synthetic source (#85649)          This attempts to shrink the index by implementing a "synthetic _source" field.     You configure it by in the mapping:     ```     {     "mappings": {     "_source": {     "synthetic": true     }     }     }     ```          And we just stop storing the `_source` field - kind of. When you go to access     the `_source` we regenerate it on the fly by loading doc values. Doc values     don't preserve the original structure of the source you sent so we have to     make some educated guesses. And we have a rule: the source we generate would     result in the same index if you sent it back to us. That way you can use it     for things like `_reindex`.          Fetching the `_source` from doc values does slow down loading somewhat. See     numbers further down.          ## Supported fields     This only works for the following fields:     * `boolean`     * `byte`     * `date`     * `double`     * `float`     * `geo_point` (with precision loss)     * `half_float`     * `integer`     * `ip`     * `keyword`     * `long`     * `scaled_float`     * `short`     * `text` (when there is a `keyword` sub-field that is compatible with this feature)               ## Educated guesses          The synthetic source generator makes `_source` fields that are:     * sorted alphabetically     * as "objecty" as possible     * pushes all arrays to the "leaf" fields     * sorts most array values     * removes duplicate text and keyword values          These are mostly artifacts of how doc values are stored.          ### sorted alphabetically     ```     {     "b": 1,     "c": 2,     "a": 3     }     ```     becomes     ```     {     "a": 3,     "b": 1,     "c": 2     }     ```          ### as "objecty" as possible     ```     {     "a.b": "foo"     }     ```     becomes     ```     {     "a": {     "b": "foo"     }     }     ```          ### pushes all arrays to the "leaf" fields     ```     {     "a": [     {     "b": "foo",     "c": "bar"     },     {     "c": "bort"     },     {     "b": "snort"     }     }     ```     becomes     ```     {     "a" {     "b": ["foo", "snort"],     "c": ["bar", "bort"]     }     }     ```          ### sorts most array values     ```     {     "a": [2, 3, 1]     }     ```     becomes     ```     {     "a": [1, 2, 3]     }     ```          ### removes duplicate text and keyword values     ```     {     "a": ["bar", "baz", "baz", "baz", "foo", "foo"]     }     ```     becomes     ```     {     "a": ["bar", "baz", "foo"]     }     ```     ## `_recovery_source`          Elasticsearch's shard "recovery" process needs `_source` *sometimes*. So does     cross cluster replication. If you disable source or filter it somehow we store     a `_recovery_source` field for as long as the recovery process might need it.     When everything is running smoothly that's generally a few seconds or minutes.     Then the fields is removed on merge. This synthetic source feature continues     to produce `_recovery_source` and relies on it for recovery. It's *possible*     to synthesize `_source` during recovery but we don't do it.          That means that synethic source doesn't speed up writing the index. But in the     future we might be able to turn this on to trade writing less data at index     time for slower recovery and cross cluster replication. That's an area of     future improvement.          ## perf numbers          I loaded the entire tsdb data set with this change and the size:          ```     standard -> synthetic     store size  31.0 GB ->  7.0 GB  (77.5% reduction)     _source  24695.7 MB -> 47.6 MB  (99.8% reduction - synthetic is in _recovery_source)     ```          A second _forcemerge a few minutes after rally finishes should removes the     remaining 47.6MB of _recovery_source.          With this fetching source for 1,000 documents seems to take about 500ms. I     spot checked a lot of different areas and haven't seen any different hit. I     *expect* this performance impact is based on the number of doc values fields     in the index and how sparse they are.     ||||[0, 0, 0, 4, 102, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 11, 0, 0, 2, 0]||||0||||0||||0
Disable get API on legacy indices (#86594)          The get API relies under the hood on accessing postings to lookup the _id and retrieve the corresponding document.     Guaranteeing this access via postings is not something we would like to guarantee on archive indices. While we are     adding "text field support" for archive indices, we reserve the flexibility to eventually swap that out with a "runtime-text     field" variant, and hence only provide those capabilities that can be emulated via a runtime field. Doing the same for     "get" would mean doing a full scan of the index (using stored fields), which is counterintuitive to what the get API is     meant to be used for (quick lookup of document). We would therefore rather not have the API accessible on archive     indices.          Relates #81210||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Support geo label position as runtime field (#86154)          We do this differently for each geometry type:          * For points we return the point     * For multipoint the centroid is unlikely to be one of the points,     so we choose a point closest to the middle of the bounding box.     * For linestring we choose the first line-segment in the triangle tree, and return its center.     * For polygons we choose the centroid, but check if it is contained within the polygon.     If not, we choose the first triangle in the triangle tree and return its center (average point)          The use of the first entry in the triangle tree is a technique to get a likely approximate center,     while also being high performance.||||[0, 0, 0, 2, 31, 1, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 27, 0, 0, 7, 0]||||0||||0||||0
Refactor ParameterizedMessage usages in action/admin/cluster/* to use message supplier #86576          relates #86549          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0]||||0||||0||||0
Make embedded class loader module aware (#86355)          This change adds support to embedded class loader to load the provider     and implmentation dependencies as modules - within their own module     layer - when the caller itself is a named module. Currently, this code     is not yet triggered during deployment, since the caller is always an     unnamed module, but the caller will be moularized in a subsequent     change.||||[0, 0, 0, 0, 4, 7, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 3, 0, 1, 2, 0]||||0||||0||||0
Port javadoc configuration logic into a binary plugin (#86471)          Also adding test coverage and fixing certain issues we stumbled into          when resolving project dependencies of compileClasspath we need to use allDependencies instead of dependencies as usually no dependencies are added directly to compileClasspath but via implementation, compileonly and api and friends     Fixed javadoc setup for projects using shadowed dependencies via shadow plugin     Fixed dealing with skipped javadoc tasks in referenced dependent projects.     In general this PR only fixes expected javadoc generation as it was intended before this PR.          This also contains some tweaks to our gradle integration test fixtures for setting up and debugging test projects||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
simplify immutable map creation (#86547)          This commit replaces the static block that wraps map with immutable     wrapper with immutable map collector.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Port xpack plugins projects away from elasticsearch rest test gradle plugin (#86562)          This deprecates the elasticsearch.rest-test plugin and elasticsearch.standalone-rest-test and ports     all usages of them in x-pack/plugins. Other usages will be removed in a few upcoming PRs to not have one >300file PR          When all usages have been addressed we're going to remove those gradle plugins from the codebase.          This PR is a subset of #85491 which got just too big to handle IMO||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0]||||0||||0||||0
Removing extra spaces from message (#86584)          Some messages in the ShardsAvailabilityHealthIndicatorService had an     extra space. This commit removes them.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
QL: Cleanup BWC tests for unsupported version (#86336)          Since the jump to 8.x we no longer need some of the version switches in     the bwc tests because we no longer test against version before 7.17.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 16, 0]||||0||||0||||0
Adding potential impacts to remaining health indicators (#86197)          The ability to add impacts to indicators was added in #84899, but     impacts for all indicators other than shards availability were left     empty. This commit adds potential impacts for the other indicators.||||[0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 7, 0]||||0||||0||||0
Switch to OpenJDK and upgrade to 18.0.1 (#86554)          Adoptium releases are very slow to release across multiple platforms.     Switch back to Oracle's OpenJDK releases and upgrade.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
[ML] fix distribution change check for change_point aggregation (#86423)          There are certain scenarios where using apache math's built in ksTest check fails.          When strict is true, it requires the probability to be expressed as an inequality and typically causes 0 to be the pvalue calculated. This is most likely due to numerical resolution problems.          switching to strict: false fixes this. We only want to return that a change point is a distribution change if no only change type could be found or other change type pValues were large.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Include error message and stack trace. (#86569)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Add time series related information to get data stream API (#86395)          In case if a data stream is a time series data stream then include time series information.     This includes the continuous temporal ranges a time series data stream encapsulates.     This is computed based on combing the index.time_series.start_time and index.time_series.end_time     ranges of all backing indices of a time series data stream          Closes #83518||||[0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 9, 0, 0, 1, 0]||||0||||0||||0
[ML] Upgrade ojalgo to 51.2.0 (#86566)          Ojalgo 51.2.0 brings significant improvements to memory utilization     and speed for the linear solver we use to determine assignment plans     for trained models.          In addition to updating the library, we now make use of the ability     to use the solver in sparse mode which uses much less memory at the cost     of speed. Thus we determine an intermediate threshold where we switch     from dense to sparse solver.          Testing showed a significant decrease in memory use. In particular,     the worse cases regardless of dense/sparse solving should now not be using     more than ~40MB which is much less than what we allowed previously.          The dense solver is faster than before. Even when switching to the sparse solver,     it is not much slower than what the dense solver achieved previously.          Relates #86496||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 7, 0]||||0||||0||||0
Health API explain query param (#86410)          The health API has a notion of details within each health indicator that is returned. These details can sometimes be     expensive to compute or transfer. This change allows a user to specify whether the details are generated and     returned. By default now all details are generated and returned (previously this was only the case if a component     was specified in the request). This behavior can be changed with the explain query param.     Closes #86215||||[0, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 3, 0, 2, 2, 0, 0, 0, 1, 0, 0, 9, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 9, 0, 0, 22, 0]||||0||||0||||0
Cleanup+Speed-up DataStream Metadata handling (#86470)          No need to copy maps so often, this was quite slow in many-shards     benchmarking which uses lots of datastreams.     ||||[0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 6, 1, 4, 11, 0]||||0||||0||||0
Remove Redundant IndexComponent Interface (#86538)          This interface is pointless as it's effectively only inherited by `AbstractIndexComponent` in practice.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 7, 0]||||0||||0||||0
Change aggregation path element errors to be 400s (#86532)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Fix bounded hexagonal grids when they contain the bin on one of the poles (#86460)          This commit adds a special handle for those cases.||||[0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 1, 0, 0]||||0||||0||||0
Do not apply StandaloneRestTestPlugin in StandaloneTestPlugin (#86400)          As we are moving away from StandaloneRestTestPlugin (see https://github.com/elastic/elasticsearch/pull/85491) we want to reduce the surface of that plugin.     If rest tests are used a rest test related plugin should be applied||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 3, 0]||||0||||0||||0
Faster GET _cluster/settings API (#86405)          The existing API to retrieve the cluster settings relies on     pulling in the full cluster state, which can be very expensive.          This change adds a dedicated cluster settings API, avoiding     serializing the full cluster state.          Co-authored-by: David Turner <david.turner@elastic.co>||||[0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 7, 0, 0, 4, 0]||||0||||0||||0
Add getResolution method to H3 (#86519)          ||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0]||||0||||0||||0
Disable template cleanup in MultiVersionRepositoryAccessIT to fix it in older versions (#86358)          I could not find a clean way of making the template cleanup work with very old versions.     I found that it's also disabled in other tests dealing with old versions (full cluster restart tests)     so I'm disabling it here as well to finally make these important tests functional again.          closes #82569||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove CSTL#onNoLongerMaster (#83420)          Implementations of `ClusterStateTaskListener#onNoLongerMaster` almost     universally do the same thing as `CSTL#onFailure` except for differences     in logging. In most cases for logging purposes we should treat not being     the master the same as failing to commit the cluster state, but we don't     do so and this can generate a lot of log noise on a master failure. In     other places we rely on the default implementation of `onNoLongerMaster`     and react to the type of the exception in the `onFailure` handler as     needed.          To simplify the situation, this commit combines `onNoLongerMaster` and     `onFailure` everywhere and harmonises the logging behaviour for     `FailedToCommitClusterStateException` and `NotMasterException`.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0]||||0||||0||||0
Require index.mode=time_series for creating time series data streams (#86441)          Prior to this change the `index.routing_path` was required in order for     data streams to be created in time series mode.          This commit changes that by also requiring `index.mode` index setting to     be set to `time_series`. The `index.routing_path` remains a required setting,     but it is no longer used to determine whether a data stream should be created     in time series mode.          The `index.mode` index setting will no longer automatically be added backing indices.     This was done by the `DataStreamIndexSettingsProvider` class and this class will not only     automatically add the `index.time_series.start_time` and `index.time_series.end_time`     index settings.          Relates #74660||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 0, 2, 8, 0]||||0||||0||||0
Remove failing test which mocked now sealed InetAddress class (#86490)          Fixes #86418||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Allow to sort search results by VERSION value returned by Painless script (#85990)               Version field types have specific semantics in terms of ordering, ie. SemVer.     This fix adds a new "version" type for script sorting (in addition to the existing "number" and "string" options)     to specify SemVer ordering semantics.||||[0, 0, 0, 1, 4, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 4, 5, 0, 1, 2, 0]||||0||||0||||0
AbstractAnalyzerProvider does not need to extend AbstractIndexComponent (#86537)          Remove the inheritance here to make instances smaller and speed up many-shards benchmarks a little.     Did not remove the dead arguments from the constructors in this PR as that would have been a     very noisy change.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 54, 0]||||0||||0||||0
Complete listener on rejection in FollowersChecker (#86259)          In #83576 we made it so that forking off the transport thread when     handling a follower check might be rejected if we're shutting down. In     that case we don't pass the rejection exception back out and instead     rely on the transport connection's close to notify the caller. We also     manipulate the transport channel directly which misses some exception     cases. This commit adjusts the implementation to fix these things.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Block joins while applier is busy (#84919)          Certain cluster appliers perform I/O or other heavy computations and in     extreme circumstances may take a significant amount of time to apply a     cluster state. The master considers a node to be unhealthy if it takes     too long to apply a cluster state. Nodes that time out like this are     removed from the cluster, but they will carry on with the slow cluster     state application regardless. If the application takes long enough then     there may be time for the node to rejoin the cluster, time out applying     the state resulting from the rejoin, and be removed again. This can     happen repeatedly and is disruptive to the rest of the cluster.          There is no point in trying to rejoin the cluster while the applier is     busy. With this commit we send the join request from the applier thread,     ensuring that it is not occupied with other work and will therefore be     available to apply the joining state. The commit also adds periodic     logging of the status of ongoing joins to help clarify why it is taking     longer than expected to rejoin the cluster.||||[0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 4, 0]||||0||||0||||0
Log cluster.initial_master_nodes at startup (#86101)          We continue to see occasional cases of clusters with inappropriate     bootstrap config. It can be quite hard to diagnose these cases because     we don't report the bootstrap config anywhere in the logs. This commit     adds that missing logging to simplify the diagnostic process.||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0]||||0||||0||||0
AwaitsFix for #86530     ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use cluster health API in validateClusterFormed (#85454)          Since #76884 in `InternalTestCluster#validateClusterFormed` we wait for     a correctly-sized cluster state to be applied before entering the     `assertBusy()` loop to wait for the cluster state to be exactly right     everywhere. Today we do this by injecting a cluster state observer into     one of the nodes which waits for a cluster state containing a master and     the right number of nodes. With this commit we move to using the cluster     health API which can do the same thing.          By this point any extra nodes have stopped, but there might still be a     stale join request for one of those nodes in the master's queue. This     commit addresses this by also waiting for the master queue to be empty.          Closes #81830||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]||||0||||0||||0
Make the ILM and SLM history_index_enabled settings dynamic (#86493)          ||||[2, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 17, 0, 7, 16, 0]||||0||||0||||0
Remove isMeta check during rewrite field-caps responses (#86522)          This check is no longer needed because 8.3+ won't handle index     field-caps responses from 7.13 or before.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 9, 0]||||0||||0||||0
fixing unit test (#86520)          ShardLimitValidatorTests was accidentally broken as part of #85967     because the new assertions in that class were not taking the type of     nodes into account ("normal" or "frozen"). This is a simple change to     take that into account.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Adding a view of master history (#85941)          This commit adds the notion of an in-memory MasterHistory of which nodes have been master for the last 30 minutes that is maintained in memory on each node. It is exposed via the MasterHistoryService. This commit also has a transport action so that you can fetch the master history from any node in the cluster, represented as a List of NodeClients. The list is an ordered list of nodes that have been seen as master for the last 30 minutes, with the oldest first. This action is used by the MasterHistoryService exposed for use via the MasterHistoryService. The local and remote master history representations will be used to determine if the master has been stable as part of the health API.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]||||0||||0||||0
Fix JWT realm generate test (#86484)          Add missing SharedSecret scheme to ES-Client-Authentication hearer when printing headers for JWT realm example requests.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Fix plugin command tests newline assertions (#86500)          This commit fixes an edge case that fails on windows where extra     newlines do not match because of the difference in line endings.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Adding a deprecation info API check for too many shards (#85967)          This commit makes sure that there is enough room in a cluster to add a small number of shards during an upgrade. The information is exposed in the deprecation info API as a cluster configuration check.     Closes #85702||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 2, 0]||||0||||0||||0
[Test] Replace all mock authentication with concrete objects (#86424)          Changes in this PR enables marking the Authentication class to final in     a future PR as part of the overall plan for closing down Authentication.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 96, 59, 0, 0, 25, 0]||||0||||0||||0
[ML] fix question answering config update test apply (#86489)          closes #86487||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
Make AllocationDecider canRemain loop tighter (#86503)          No need to collect a multi decision here (which is surprisingly prominent in the profiling)     when we're not using it in the end anyway.||||[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 0, 0]||||0||||0||||0
User Profile - Request cancellation for SuggestProfiles on HTTP disconnect (#86332)          This PR adds support for automatic request cancellation on HTTP     connection drop for the SuggestProfiles API. Both the Suggest     request itself and its child Search requests are cancelled once the     incominng HTTP connection is closed.     ||||[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0]||||0||||0||||0
[ML] Lower memory threshold for running LP in assignment planner (#86504)          After test failures in CI I retested how much memory is used in the heap     when the assignment planner runs on the limits of the memory threshold.     In this PR we lower the memory threshold before switching to bin-packing     so that the solver should never user more than ~100MB. Previously it could     use up to ~200MB.          Closes #86496||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0]||||0||||0||||0
Better failure for source-only snapshots of partially/fully mounted indices (#86207)          Taking a snapshot of a partially or fully mounted index in a source-only     repository is not supported and stops the data node by throwing an     AssertionError.          Instead of throwing such an error, this change simply fails the snapshot     of searchable snapshot shards in source-only repository and report a     better snapshot failure.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 0]||||0||||0||||0
Disabling users includes realm in same-user validation  (#86473)          A validation check prevents users from disabling themselves. The check     is incorrect since it does not factor in realms. Users can have     overlapping usernames across realms, and should be able to disable     same-named users in other realms, authorization provided. This PR tweaks     the validation check to account for the source realm.||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 4, 0, 0, 6, 0]||||0||||0||||0
Fix Windows EmbeddedImplClassLoaderTests (#86413)          Fix Windows EmbeddedImplClassLoaderTests. Remove use of openStream in favor of getResourceAsStream.          Co-authored-by: Ryan Ernst <ryan@iernst.net>||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
[s3-repository] Support generating AWS role session name in case it's not provided (#86255)          The AWS SDK actually doesn't require the session name to be set and generates one if     it's not provided via the AWS_ROLE_SESSION_NAME environment variable.          See #52625||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0]||||0||||0||||0
Fix min node version before state recovery (#86482)          We use the minimum node version in the cluster state to make decisions     about backwards compatibility (e.g. to choose newer actions in the REST     layer only if all nodes will support it). Once the cluster is fully     formed we reject attempts by older nodes to join the cluster so that the     minimum node version only ever increases, which makes     backwards-compatibility decisions safe.          However, it's possible that the REST layer will make decisions about     backwards compatibility before the cluster is fully formed. In this     state, older nodes may still join the cluster and may therefore see     actions that they do not understand.          With this commit we report no nodes to the REST layer until the cluster     is fully-formed, and change the minimum node version in an empty cluster     to be the minimum compatible version. This means the REST layer will     operate in a maximally-compatible mode until the cluster is formed.          Relates #86405||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0]||||0||||0||||0
Has privileges API for profiles (#85898)          This introduces a new Security API `_security/profile/_has_privileges`     that can be used to verify which Users have the requested privileges,     given their associated User Profiles. Multiple profile uids can be specified     in a single has privileges request.          This is analogous to the existing Has privileges API. It also uses the same     format for specifying the privileges to be checked, and should be used in     the same situations (ie to run an authorization preflight check or to verify     privileges over application resources). However, unlike the existing     has privilege API, this can be used to check the privileges of multiple     users (not only of the currently authenticated one), but the users must     have an existing profile, and the response is binary only (either it has or     it does not have the requested privileges).     Calling this API requires the `manage_user_profile` cluster privilege.||||[0, 0, 0, 0, 6, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 8, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 24, 49, 1, 1, 18, 0]||||0||||0||||0
Set serverAuth extended key usage for generated certificates and CSRs. (#86311)          This commit extends `CertGenUtils` to allow configuring     `ExtendedKeyUsage` extension for generated certificates     and adds `id_kp_serverAuth` (1.3.6.1.5.5.7.3.1) key usage     to places where we know that the certificate is meant only     to be used for server authentication.          Closes #81067||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 2, 0]||||0||||0||||0
Don't require WWW-Authenticate in OIDC UserInfo (#86031)          The OpenIDConnect authenticator attempts to handle errors in the     UserInfo endpoint, and will consult the WWW-Authenticate header if it     exists, in order to provide diagnostic information.          However, there was a bug where it assumed that the WWW-Authenticate     header would always exist. This change fixes this incorrect     assumption.||||[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0]||||0||||0||||0
Clean up and better document JvmOptionsParser (#86448)          This change preparse the JvmOptionsParser for #85758 by moving the shell     specific behavior, like printing output, to the main method, and making     the main function take in all its parameters. Additionally the main     method to determine the jvm options is documented a bit.          relates #85758||||[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 4, 0, 0, 4, 0]||||0||||0||||0
[ML] mute qa update test apply issue #86487 (#86488)          related: https://github.com/elastic/elasticsearch/issues/86487||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Unmute some monitoring tests (#86483)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]||||0||||0||||0
[ML] add new trained_models/{model_id}/_infer endpoint for all supervised models and deprecate deployment infer api (#86361)          This commit adds a new `_ml/trained_models/{model_id}/_infer` API. This api works for both native NLP models and supervised models trained via Data Frame analytics.          The format of the API is the same as the old `_ml/trained_models/{model_id}/deployment/_infer`. Taking a `docs` and an `inference_config` parameter.          This PR also deprecates the old experimental `_ml/trained_models/{model_id}/deployment/_infer` API.          The biggest difference is that the response now nests all results under an "inference_results" object.          closes: https://github.com/elastic/elasticsearch/issues/86032||||[0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 6, 3, 0, 0, 40, 0]||||0||||0||||0
Add preflight checks to Health API to ensure health is obtainable (#86404)          This PR introduces an idea of preflight health indicator services to the new health service. Preflight indicators are     structurally identical to regular indicators, but they are executed first when calculating health and conditionally block     downstream indicators from running on an unstable or unknown cluster state.||||[0, 0, 0, 0, 8, 7, 0, 2, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 18, 0, 0, 16, 0]||||0||||0||||0
Remove LegacyCTRAL from MetadataIndexTemplateService (#86459)          Relates #83784, #86017||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Upgrade to Lucene 9.2 snapshot efa5d6f4d43 (#86227)          Notable changes include:          count implementations for MultiRangeQuery and IndexSortedNumericDocValuesRangeQuery, which may speed up certain aggregations     more efficient decoding of docids in BKD reader||||[0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0]||||0||||0||||0
Remove ImmutableOpenIntMap (#86447)          All uses of the class have been removed, so this commit now removes the     tests and the class itself.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Move cli shutdown hook to CliToolLauncher (#86412)          Each Command subclass can implement close() so that resources will be     cleaned up on exceptional exit like SIGINT. This is implemented through     a shutdown hook added in the superclass constructor. However, this hook     makes testing difficult because the hook cannot be added in normal     tests, so a flag must be overriden when testing Command classes.          This commit moves the shutdown hook handling into the CliToolLauncher     that creates the command. It also adds non-evil tests that check how the     hook runs, in place of the old evil tests that actually registered a     real shutdown hook.          relates #85758||||[0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 0, 0, 0, 0, 0, 0, 5, 6, 0, 0, 2, 0]||||0||||0||||0
User APIs allow use of internal usernames (#86398)          This PR removes API restrictions that prevent user-related actions     (PutUser, DeleteUser, etc.) to be performed on users with names     clashing with internal users (e.g., _system). Internal users are used     for issuing requests within the cluster and not accessible at the REST     layer; they are conceptually and practically separate from users     created through the API (they do not belong to the same realm and     follow different authentication flows). As such it's safe to remove the     current restriction. By removing, we are more consistent with how     usernames are treated across other realms (name re-use is allowed), and     ease evolving internal users without interfering with end-user     experience.          Closes #86326||||[0, 0, 0, 0, 13, 0, 6, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 179, 9, 0, 4, 1, 0]||||0||||0||||0
Faster RoutingTable Builder (#86465)          Copying the map one by one gets very expensive for large tables     => leveraging the faster copy constructor that clones the map     internally gives a non-trivial speedup to many shards benchmark     bootstrapping.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0]||||0||||0||||0
[ML] Tests of the named writable registry for inference updates (#85870)          ||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0]||||0||||0||||0
[ML] Adjust automatic JVM heap sizing for dedicated ML nodes (#86399)          Previously the JVM heap size on dedicated ML nodes was as follows     when automatic JVM heap sizing was used:          - 40% of memory if total memory < 2GB     - 25% of memory for total memory between 2GB and 8GB     - 2GB if total memory > 8GB          This formula had two major drawbacks:          1. There was no way to increase the ML node JVM size beyond 2GB.     If for some reason 2GB wasn't enough (e.g. a huge cluster state)     then there was no workaround.     2. The formula was not reversible - there are JVM heap sizes that     could arise from 2 different total memory sizes. This complicated     autoscaling calculations.          This PR switches to a simpler formula that does not suffer these     drawbacks. The new formula is:          JVM heap size = 40% of total memory up to 16GB     + 10% of total memory over 16GB          This is always rounded down to the next lower whole megabyte to     match what's done for other node types.          It's now possible to increase the JVM heap size on dedicated ML nodes     indefinitely by increasing the node size. And there are no nasty     discontinuities in the formula that make the inverse hard to calculate.||||[0, 0, 0, 0, 2, 14, 0, 3, 7, 0, 0, 19, 88, 10, 14, 16, 0, 0, 4, 0, 1, 4, 1, 5, 0, 5, 3, 0, 0, 0, 0, 0, 0, 0, 2, 6, 0, 0, 0, 0, 0, 0, 45, 151, 14, 30, 236, 0]||||0||||0||||0
[ML] Update the number of allocations per nlp process (#86277)          Adds a method to DeploymentManager to update the number of     allocations per process as implemented in elastic/ml-cpp#2258.          ||||[0, 0, 0, 0, 10, 2, 1, 0, 2, 2, 0, 5, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 5, 0, 0, 0, 1, 0, 0, 2, 3, 5, 0, 0, 0, 0, 0, 0, 23, 8, 0, 8, 49, 0]||||0||||0||||0
Batch reroute in TransportClusterUpdateSettingsAction (#86451)          There's no need for the followup reroute task to wait for acks from all     nodes (indeed it sometimes reports `acknowledged: true` even if the     update fails). Dropping the acking reduces this task to a simple     reroute, which can then be batched. This commit does that.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]||||0||||0||||0
Remove LegacyCTRAL from IngestService (#86446)          Relates #83784, #86017||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Cleanup SnapshotInProgressAllocationDecider a little (#86457)          We already have a stream here, lets not make this needlessly slow via the iterator     when we can have the stream iterate much faster when used directly.     Also, looks nicer this way.     ||||[0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 12, 4, 0, 2, 1, 0]||||0||||0||||0
[ML] Muting trained model upgrade tests (#86453)          These tests also fail before the Java side of     https://github.com/elastic/ml-cpp/pull/2258     is merged.||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Remove remaining ImmutableOpen maps from shard stores response (#86427)          The IndicesShardStoresResponse had ImmutableOpenInt map removed, but its     use accidentally remained in serialization. Thankfully the format for     immutable open maps are interchangable with read java Map. This commit     switches to using the new readImmutableMap to read the store statuses.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0
Use HashMap for IndexMetadata.inSyncAllocationIds (#86403)          The in sync allocation ids is a mapping from shard to the set of ids     currently being processed. When being built, the metadata uses a sparse     map, only filling a value for a shard as they are put into the builder.     When the final metadata is built, the map is made dense.          This commit converts to using a HashMap instead of ImmutableOpenIntMap.     The boxed keys should not cause allocations, as long as number of shards     is lower than 128. Long term the map itself should become an array, as     we know the number of shards (much like the dense primaryTerms array     here). However, that change will be a little trickier to make, since we     will need to be backward compatible with how diffs are built, currently     using Map differences.          relates #86239||||[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]||||0||||0||||0